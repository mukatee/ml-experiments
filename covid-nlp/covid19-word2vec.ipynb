{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID19 Word2Vec generator\n",
    "\n",
    "This notebook creates a (Gensim) word2vec model and saves it as a dataset for future use. You could use it for things like looking up synonyms of words in the original documents. It uses my [preprocessed COVID NLP dataset](https://www.kaggle.com/donkeys/covid-nlp-preprocess) as input and produces the [word2vec dataset](https://www.kaggle.com/donkeys/covid-word2vec) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import kaggle_uploader\n",
    "kaggle_uploader.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class COVDoc:\n",
    "    def __init__(self):\n",
    "        self.filepath_proc = None\n",
    "        self.filepath_orig = None\n",
    "        self.text_proc = None\n",
    "        self.text_orig = None\n",
    "        self.tokenized_proc = None\n",
    "        self.doc_type = None\n",
    "    \n",
    "    #this function allows me to lazy-load the original text to save memory\n",
    "    def load_orig(self):\n",
    "            with open(doc.filepath_orig) as f:\n",
    "                d = json.load(f)\n",
    "                body = \"\"\n",
    "                for idx, paragraph in enumerate(d[\"body_text\"]):\n",
    "                    body += f\" {paragraph}\"\n",
    "                self.text_orig = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, json\n",
    "\n",
    "paragraphs = []\n",
    "\n",
    "def load_docs(base_path, doc_type):\n",
    "    file_paths = glob.glob(base_path)\n",
    "    file_names = [os.path.basename(path) for path in file_paths]\n",
    "    for filepath in file_paths:\n",
    "        with open(filepath) as f:\n",
    "            d = json.load(f)\n",
    "#            print(d)\n",
    "            for paragraph in d[\"body_text\"]:\n",
    "                paragraphs.append(paragraph[\"text\"])\n",
    "#                paragraphs.append(\" \".join(paragraph[\"text\"]).lower())\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/covid-nlp-preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001418189999fea7f7cbe3e82703d71c85a6fe5.json\r\n",
      "00016663c74157a66b4d509d5c4edffd5391bbe0.json\r\n",
      "002c9e9bed0d874c169d9f77a135f12e41b733ee.json\r\n",
      "01213acdd86020357259f2a1094bc43f9bb79796.json\r\n",
      "0131ce11f9dbeac6ad5f732ab5d268674da53290.json\r\n",
      "014fcb209d3870dce737d4d50e3ec85044cfd2f6.json\r\n",
      "01626763ff19226d69dedacfe5fa22f2f0dd0018.json\r\n",
      "018fb5e62fbbcae07d57d94d29ac630dcc4dccf9.json\r\n",
      "019d4817c1bb20299f7bcd20248bd85ad0f59a2e.json\r\n",
      "01b1b409f426cc712ba8e1876d0ac34bab8689e1.json\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/covid-nlp-preprocess/output/paragraphs/biorxiv_medrxiv | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '/kaggle/input/covid-nlp-preprocess/output/paragraphs/biorxiv_medrxiv/00340eea543336d54adda18236424de6a5e91c9d.json' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head /kaggle/input/covid-nlp-preprocess/output/paragraphs/biorxiv_medrxiv/00340eea543336d54adda18236424de6a5e91c9d.json | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2087"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_docs = load_docs(\"/kaggle/input/covid-nlp-preprocess/output/paragraphs/biorxiv_medrxiv/*.json\", \"medx\")\n",
    "len(med_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8682"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comuse_docs = load_docs(\"/kaggle/input/covid-nlp-preprocess/output/paragraphs/comm_use_subset/*.json\", \"comuse\")\n",
    "len(comuse_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncom_docs = load_docs(\"/kaggle/input/covid-nlp-preprocess/output/paragraphs/noncomm_use_subset/*.json\", \"noncom\")\n",
    "len(noncom_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27073"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_docs = load_docs(\"/kaggle/input/covid-nlp-preprocess/output/paragraphs/custom_license/*.json\", \"custom\")\n",
    "len(custom_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec \n",
    "\n",
    "model = Word2Vec(paragraphs, size=300, window=5, min_count=5, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab\n",
    "word_vectors = model.wv\n",
    "#del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('child', 0.6941933035850525),\n",
       " ('inpatient', 0.6390001773834229),\n",
       " ('subject', 0.6166149377822876),\n",
       " ('hsct_recipient', 0.6060119867324829),\n",
       " ('outpatient', 0.6017776727676392),\n",
       " ('hct_recipient', 0.5964309573173523),\n",
       " ('person', 0.5931017398834229),\n",
       " ('admitted_icu', 0.580216646194458),\n",
       " ('woman', 0.5711398124694824),\n",
       " ('infant', 0.5692756175994873),\n",
       " ('icu', 0.5690579414367676),\n",
       " ('case', 0.5645661354064941),\n",
       " ('nursing_home_resident', 0.5591453313827515),\n",
       " ('survivor', 0.5534113645553589),\n",
       " ('hcws', 0.5507948398590088),\n",
       " ('outpatient_clinic', 0.5468251705169678),\n",
       " ('admission', 0.540906548500061),\n",
       " ('boy', 0.538764238357544),\n",
       " ('casepatients', 0.536649227142334),\n",
       " ('hcw', 0.5299692153930664),\n",
       " ('episode', 0.5295727252960205),\n",
       " ('febrile_neutropenia', 0.5291351079940796),\n",
       " ('participant', 0.5226424932479858),\n",
       " ('newonset', 0.5219123363494873),\n",
       " ('emergency_department_ed', 0.5217392444610596),\n",
       " ('pregnant_woman', 0.5201883912086487),\n",
       " ('hospitalized', 0.5180360078811646),\n",
       " ('girl', 0.5148604512214661),\n",
       " ('bmt_recipient', 0.5131189823150635),\n",
       " ('lt_recipient', 0.5124093294143677),\n",
       " ('individual', 0.5123444199562073),\n",
       " ('healthcare_worker', 0.5120639801025391),\n",
       " ('icu_admission', 0.5089720487594604),\n",
       " ('sot_recipient', 0.50481116771698),\n",
       " ('pcp', 0.5032349228858948),\n",
       " ('dvt', 0.5030484199523926),\n",
       " ('haematological_malignancy', 0.5029246807098389),\n",
       " ('newly_diagnosed', 0.5022547841072083),\n",
       " ('altered_mental_status', 0.5009838938713074),\n",
       " ('symptomatic', 0.5008430480957031),\n",
       " ('emergency_department', 0.5006405115127563),\n",
       " ('bedridden', 0.4995824098587036),\n",
       " ('allohsct_recipient', 0.4947948753833771),\n",
       " ('requiring_hospitalization', 0.49445533752441406),\n",
       " ('vrti', 0.4942328929901123),\n",
       " ('pediatric', 0.4936751127243042),\n",
       " ('people', 0.49135297536849976),\n",
       " ('hsct', 0.49109387397766113),\n",
       " ('physician', 0.4910697638988495),\n",
       " ('renal_transplant_recipient', 0.4886530041694641)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(\"patient\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir upload_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"upload_dir/word2vec.pickle\", \"wb\") as f:\n",
    "    pickle.dump(word_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"upload_dir/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/kaggle/working/upload_dir\n",
      "/kaggle/working/upload_dir\n",
      "running cmd:['kaggle', 'datasets', 'version', '-p', '/kaggle/working/upload_dir', '-m', '\"new version\"']\n",
      "Starting upload for file word2vec.model\n",
      "Upload successful: word2vec.model (16MB)\n",
      "Starting upload for file word2vec.model.wv.vectors.npy\n",
      "Upload successful: word2vec.model.wv.vectors.npy (261MB)\n",
      "Starting upload for file word2vec.pickle\n",
      "Upload successful: word2vec.pickle (537MB)\n",
      "Starting upload for file word2vec.model.trainables.syn1neg.npy\n",
      "Upload successful: word2vec.model.trainables.syn1neg.npy (261MB)\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/donkeys/covid-word2vec\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'COVID Word2Vec',\n",
       " 'id': 'donkeys/covid-word2vec',\n",
       " 'licenses': [{'name': 'CC0-1.0'}],\n",
       " 'resources': [{'path': '/kaggle/working/upload_dir/word2vec.pickle',\n",
       "   'description': 'pickled word2vec for covid19 dataset'},\n",
       "  {'path': '/kaggle/working/upload_dir/word2vec.model',\n",
       "   'description': 'gensim saved word2vec for covid19 dataset'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kaggle_uploader\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "api_secret = user_secrets.get_secret(\"kaggle api key\")\n",
    "\n",
    "kaggle_uploader.resources = []\n",
    "kaggle_uploader.init_on_kaggle(\"donkeys\", api_secret)\n",
    "kaggle_uploader.base_path = \"./upload_dir\"\n",
    "kaggle_uploader.title = \"COVID Word2Vec\"\n",
    "kaggle_uploader.dataset_id = \"covid-word2vec\"\n",
    "kaggle_uploader.user_id = \"donkeys\"\n",
    "kaggle_uploader.add_resource(\"word2vec.pickle\", \"pickled word2vec for covid19 dataset\")\n",
    "kaggle_uploader.add_resource(\"word2vec.model\", \"gensim saved word2vec for covid19 dataset\")\n",
    "#kaggle_uploader.create()\n",
    "kaggle_uploader.update(\"new version\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
