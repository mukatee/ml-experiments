{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2656498b",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Kaggle AMEX dataset\n",
    "\n",
    "https://www.kaggle.com/competitions/amex-default-prediction/data\n",
    "\n",
    "This competition had some random looking data where no information on columns was given. This notebook performs some basic data pre-processing on those. Mainly it uses preprocessing code posted by users on the Kaggle competition. These are used as inputs in some other notebooks in this repo, demonstrating Optune hyperparameter optimizations for this dataset.\n",
    "\n",
    "This dataset contained 1-13 rows of time-series data per customer. Goal was to predict likelihood of default in the next timeframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd51f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f848a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b22a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36efef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_in_day = 60*60*24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decc3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2\n",
    "from typing import List\n",
    "\n",
    "def optimize_floats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    floats = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast='float')\n",
    "    return df\n",
    "\n",
    "def optimize_ints(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ints = df.select_dtypes(include=['int64']).columns.tolist()\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast='integer')\n",
    "    return df\n",
    "\n",
    "#this does not seem to work for this dataset, customer id's got duplicated\n",
    "def optimize_objects(df: pd.DataFrame, datetime_features: List[str]) -> pd.DataFrame:\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        if col not in datetime_features:\n",
    "            if not (type(df[col][0])==list):\n",
    "                num_unique_values = len(df[col].unique())\n",
    "                num_total_values = len(df[col])\n",
    "                if float(num_unique_values) / num_total_values < 0.5:\n",
    "                    df[col] = df[col].astype('category')\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "def optimize(df: pd.DataFrame, datetime_features: List[str] = []):\n",
    "    return optimize_floats(optimize_ints(df))\n",
    "    #optimize objects was causing categoricals to create extra rows\n",
    "    #return optimize_floats(optimize_ints(optimize_objects(df, datetime_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9f7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    seconds = int(seconds)\n",
    "    minutes = seconds // 60\n",
    "    hours = minutes // 60\n",
    "    minutes = minutes % 60\n",
    "    seconds = seconds % 60\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h, {minutes}m, {seconds}s\"\n",
    "    if minutes > 0:\n",
    "        return f\"{minutes}m, {seconds}s\"\n",
    "    return f\"{seconds}s\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aef7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_cat_cols(df_from):\n",
    "    new_cat_cols = []\n",
    "    for cat_col in cat_cols:\n",
    "        new_cat_cols.extend([col for col in df_from.columns if col.startswith(cat_col)])\n",
    "    return new_cat_cols\n",
    "\n",
    "def label_cat_cols(df1, df2, cat_cols):\n",
    "    for cat_col in cat_cols:\n",
    "        encoder = preprocessing.OrdinalEncoder() #or LabelEncoder\n",
    "        df1[cat_col] = encoder.fit_transform(df1[cat_col]) #TODO: try all cat cols in one call?\n",
    "        df2[cat_col] = encoder.transform(df2[cat_col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08960011",
   "metadata": {},
   "source": [
    "# Outlier Removal\n",
    "\n",
    "## Normal Distribution\n",
    "\n",
    "with z-scores\n",
    "\n",
    "## Abnormal Distributions\n",
    "\n",
    "with tukey method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b22fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_thresholds_high = {}\n",
    "outlier_thresholds_low = {}\n",
    "\n",
    "#assuming the data is normally distributed, this removes outliers using the \"three sigma\" rule.\n",
    "#that is 3*std from mean is expected to contain the 0.03% of smallest/highest values.\n",
    "#those are replaced with the min/mam here (actually just max in this implementation)\n",
    "def remove_outliers_normal(df, col):\n",
    "    upper = df[col].mean()+3*df[col].std()\n",
    "    #even variable outlier_thresholds does not exist in this code, since this method variant was not used by me in the end\n",
    "    #however, should be trivial to fix both min/max and thresholding\n",
    "    if col in outlier_thresholds:\n",
    "        upper = outlier_thresholds[col]\n",
    "    else:\n",
    "        outlier_thresholds[col] = upper\n",
    "    mask = np.abs(df[col] - df[col].mean()) > (3*df[col].std())\n",
    "    df.loc[mask, col] = upper\n",
    "    #TODO: fix this version\n",
    "    \n",
    "#tukey outlier removal should work for any distribution, not just normal.\n",
    "#the normal version above is just perhaps more focused for normal distributions\n",
    "def remove_outliers_tukey(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3-q1\n",
    "    upper = q3 + iqr*2 #tukey default uses 1.5 multiplier, using *2 here to get more extreme outliers\n",
    "    lower = q1 - iqr*2 #*3 gave std up to 5.5x, lets see 2*\n",
    "\n",
    "    if col in outlier_thresholds_high:\n",
    "        upper = outlier_thresholds_high[col]\n",
    "        lower = outlier_thresholds_low[col]\n",
    "    else:\n",
    "        outlier_thresholds_high[col] = upper\n",
    "        outlier_thresholds_low[col] = lower\n",
    "        \n",
    "    high_mask = np.abs(df[col] > upper)\n",
    "    low_mask = np.abs(df[col] < lower)\n",
    "\n",
    "    if iqr < 1 and sum(high_mask) > 0:\n",
    "        upper = df[col].quantile(0.99)\n",
    "        #IQR = inter-quantile range\n",
    "#        print(f\"capping high scaling of '{col}' due low IQR: {iqr}. New IQR: {upper} vs {lower}\")\n",
    "\n",
    "    if iqr < 1 and sum(low_mask) > 0:    \n",
    "        lower = df[col].quantile(0.1)\n",
    "#        print(f\"capping low scaling of '{col}' due low IQR: {iqr}. New IQR: {upper} vs {lower}\")\n",
    "    \n",
    "    #print(sum(mask))\n",
    "    df.loc[high_mask, col] = upper\n",
    "\n",
    "    #print(sum(mask))\n",
    "    df.loc[low_mask, col] = lower\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a7c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remote_df_outliers(df):\n",
    "    for col in tqdm(num_cols):\n",
    "        #note that in its current implementation remove_outliers_tukey does not work across multiple dataframes\n",
    "        #if the outlier threshold is updated by a latter dataframe, the earlier ones used a different one\n",
    "        remove_outliers_tukey(df, col)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07ed07",
   "metadata": {},
   "source": [
    "# Data Scaling\n",
    "\n",
    "Scale the data to be between 0-1 for numerical columns. Otherwise Keras might give funny results.\n",
    "Using min-max scaler here to get 0-1 instead of Standardscaler that would produce values distributed around 0.\n",
    "With min-max of 0-1, we can use -1 to represent NaN as a numerical values.\n",
    "Mostly because Keras chokes on NaN values but -1 works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865808ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 4 µs, total: 9 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def scale_df_minmax(df, cols):\n",
    "    max_map = {}\n",
    "\n",
    "    for col in tqdm(cols):\n",
    "        #sc = StandardScaler() #standardscaler gives high numbers to 1 if most are 0, so trying with minmax\n",
    "        sc = MinMaxScaler()\n",
    "        #requireset selecting via [[col]] to get 2d array for standardscaler\n",
    "        df[col] = sc.fit_transform(df[[col]])\n",
    "        max_map[col] = df_all[col].max()\n",
    "    return max_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93d81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_na_and_inf(df):\n",
    "    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc39110",
   "metadata": {},
   "source": [
    "# Add FakeSplitter to Enable Multi-Column Stratified Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae971e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"train.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bc8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(\"test.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7271538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d9507e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11363762, 190)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aad45086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.485466e+06\n",
       "mean     6.563343e-01\n",
       "std      2.446494e-01\n",
       "min     -4.589548e-01\n",
       "25%      4.803307e-01\n",
       "50%      6.942950e-01\n",
       "75%      8.648159e-01\n",
       "max      1.010000e+00\n",
       "Name: P_2, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"P_2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "242c263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"fake_splitter\"] = df_train[\"P_2\"] > 0.695\n",
    "df_test[\"fake_splitter\"] = df_test[\"P_2\"] > 0.695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea35a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/roberthatch/exponential-averages-amex-feature-engineering\n",
    "def count_payments(df):\n",
    "    for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
    "        for pcol in ['P_2','P_3']:\n",
    "            if bcol in df.columns:\n",
    "                result = df[bcol] - df[pcol]\n",
    "                df[f'{bcol}-{pcol}'] = result.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c06cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_payments(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "042ee753",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_payments(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "069588c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 205)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1daa197d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11363762, 205)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31938114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_splitter = df_train\n",
    "df_test_splitter = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b0bf659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('train_splitter.parquet')\n",
    "df_test.to_parquet('test_splitter.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72882f40",
   "metadata": {},
   "source": [
    "# Deloitte features from Kaggle\n",
    "\n",
    "https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24215dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training set\n",
      "feature processing it\n",
      "shape after engineering (458913, 993)\n",
      "loading test set\n",
      "feature processing it\n",
      "shape after engineering (924621, 993)\n"
     ]
    }
   ],
   "source": [
    "def deloitte_process_and_feature_engineer(df):\n",
    "    # FEATURE ENGINEERING FROM \n",
    "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "\n",
    "    #this groupby produces columns that look like this (if printed):\n",
    "    #MultiIndex([(  'P_2', 'mean'),\n",
    "    #            (  'P_2',  'std'),\n",
    "    #            (  'P_2',  'min'),\n",
    "    #            (  'P_2',  'max'),\n",
    "    #            (  'P_2', 'last'),\n",
    "    #            ( 'D_39', 'mean'),\n",
    "    #            ( 'D_39',  'std'),\n",
    "    #            ( 'D_39',  'min'),\n",
    "    #            ( 'D_39',  'max'),\n",
    "    #            ( 'D_39', 'last'),\n",
    "    # also, these groupby results appear to be actual dataframes in this case (guess because it call .agg() on them)\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    #and this line just joins the two parts together for column names such as P_2_mean\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def deloitte_process_all_data():\n",
    "    global df_train, df_test\n",
    "    print(\"loading training set\")\n",
    "    if 'df_train' in vars() or 'df_train' in globals():\n",
    "        pass\n",
    "    else:\n",
    "        df_train = pd.read_parquet(\"deloitte-data/train.parquet\", engine=\"pyarrow\")\n",
    "    df_train[\"S_2\"] = pd.to_datetime( df_train[\"S_2\"] )\n",
    "    df_train = df_train.fillna(-127)\n",
    "    print(\"feature processing it\")\n",
    "    df_train = deloitte_process_and_feature_engineer(df_train)\n",
    "    print(\"loading test set\")\n",
    "\n",
    "    if 'df_test' in vars() or 'df_test' in globals():\n",
    "        pass\n",
    "    else:\n",
    "        df_test = pd.read_parquet(\"deloitte-data/test.parquet\", engine=\"pyarrow\")\n",
    "    df_test[\"S_2\"] = pd.to_datetime( df_test[\"S_2\"] )\n",
    "    df_test = df_test.fillna(-127)\n",
    "    print(\"feature processing it\")\n",
    "    df_test = deloitte_process_and_feature_engineer(df_test)\n",
    "    return df_train, df_test\n",
    "\n",
    "def deloitte_process_and_feature_engineer_large(df):\n",
    "    # FEATURE ENGINEERING FROM \n",
    "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    cat_features = find_new_cat_cols()\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std'])\n",
    "    #and this line just joins the two parts together for column names such as P_2_mean\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    df = pd.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def deloitte_process_large_data():\n",
    "    print(\"loading training set\")\n",
    "    df_train = pd.read_parquet(\"train_large.parquet\", engine=\"pyarrow\")\n",
    "#    df_train = pd.read_parquet(\"large_train.parquet\", engine=\"pyarrow\")\n",
    "    print(\"feature processing it\")\n",
    "    df_train = deloitte_process_and_feature_engineer_large(df_train)\n",
    "    print(\"loading test set\")\n",
    "    df_test = pd.read_parquet(\"test_large.parquet\", engine=\"pyarrow\")\n",
    "#    df_test = pd.read_parquet(\"large_test.parquet\", engine=\"pyarrow\")\n",
    "    print(\"feature processing it\")\n",
    "    df_test = deloitte_process_and_feature_engineer_large(df_test)\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = deloitte_process_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4f6bf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_2_mean           0\n",
       "P_2_std         5120\n",
       "P_2_min            0\n",
       "P_2_max            0\n",
       "P_2_last           0\n",
       "                ... \n",
       "D_66_last          0\n",
       "D_66_nunique       0\n",
       "D_68_count         0\n",
       "D_68_last          0\n",
       "D_68_nunique       0\n",
       "Length: 993, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b856f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>D_39_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>458913.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "      <td>453793.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "      <td>458913.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.929136</td>\n",
       "      <td>1.831865</td>\n",
       "      <td>-4.569654</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>-0.190504</td>\n",
       "      <td>4.987931</td>\n",
       "      <td>5.725742</td>\n",
       "      <td>0.214001</td>\n",
       "      <td>16.754258</td>\n",
       "      <td>6.680637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.019608</td>\n",
       "      <td>9.666892</td>\n",
       "      <td>25.097486</td>\n",
       "      <td>9.279095</td>\n",
       "      <td>10.236442</td>\n",
       "      <td>5.605566</td>\n",
       "      <td>5.302279</td>\n",
       "      <td>2.092028</td>\n",
       "      <td>16.100298</td>\n",
       "      <td>13.672650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>-127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.447584</td>\n",
       "      <td>0.022928</td>\n",
       "      <td>0.356957</td>\n",
       "      <td>0.547550</td>\n",
       "      <td>0.444149</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.669836</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.745587</td>\n",
       "      <td>0.679398</td>\n",
       "      <td>3.538462</td>\n",
       "      <td>5.547002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.854136</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>0.796134</td>\n",
       "      <td>0.906379</td>\n",
       "      <td>0.861351</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>8.166536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.009993</td>\n",
       "      <td>90.515988</td>\n",
       "      <td>1.009993</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>1.009998</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>103.944697</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            P_2_mean        P_2_std        P_2_min        P_2_max  \\\n",
       "count  458913.000000  453793.000000  458913.000000  458913.000000   \n",
       "mean       -0.929136       1.831865      -4.569654       0.039117   \n",
       "std        11.019608       9.666892      25.097486       9.279095   \n",
       "min      -127.000000       0.000000    -127.000000    -127.000000   \n",
       "25%         0.447584       0.022928       0.356957       0.547550   \n",
       "50%         0.669836       0.038433       0.594695       0.745587   \n",
       "75%         0.854136       0.067619       0.796134       0.906379   \n",
       "max         1.009993      90.515988       1.009993       1.010000   \n",
       "\n",
       "            P_2_last      D_39_mean       D_39_std       D_39_min  \\\n",
       "count  458913.000000  458913.000000  453793.000000  458913.000000   \n",
       "mean       -0.190504       4.987931       5.725742       0.214001   \n",
       "std        10.236442       5.605566       5.302279       2.092028   \n",
       "min      -127.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.444149       0.500000       0.960769       0.000000   \n",
       "50%         0.679398       3.538462       5.547002       0.000000   \n",
       "75%         0.861351       7.692308       8.166536       0.000000   \n",
       "max         1.009998     156.000000     103.944697     151.000000   \n",
       "\n",
       "            D_39_max      D_39_last  \n",
       "count  458913.000000  458913.000000  \n",
       "mean       16.754258       6.680637  \n",
       "std        16.100298      13.672650  \n",
       "min         0.000000       0.000000  \n",
       "25%         2.000000       0.000000  \n",
       "50%        16.000000       0.000000  \n",
       "75%        23.000000       9.000000  \n",
       "max       183.000000     170.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.columns[:10]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "effbabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#S2 column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2daf4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0253bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(\"train_labels.csv\")\n",
    "df_train = df_train.merge(df_target, on = 'customer_ID', how = 'left')\n",
    "df_train[\"target\"] = df_train[\"target\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5286c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_ID', 'target']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df_train.columns if col not in df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5fe24a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>6.743468</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.878454</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.904482</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.598969</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>3.017046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.805045</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 995 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean   P_2_std  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.933824  0.024194   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.899820  0.022119   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.878454  0.028911   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  0.598969  0.020107   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  0.891679  0.042325   \n",
       "\n",
       "    P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  ...  \\\n",
       "0  0.868580  0.960384  0.934745   0.230769  0.832050         0         3  ...   \n",
       "1  0.861109  0.929122  0.880519   7.153846  6.743468         0        19  ...   \n",
       "2  0.797670  0.904482  0.880875   0.000000  0.000000         0         0  ...   \n",
       "3  0.567442  0.623392  0.621776   1.538462  3.017046         0         9  ...   \n",
       "4  0.805045  0.940382  0.871900   0.000000  0.000000         0         0  ...   \n",
       "\n",
       "   D_64_count  D_64_last  D_64_nunique  D_66_count  D_66_last  D_66_nunique  \\\n",
       "0          13          0             1          13         -1             1   \n",
       "1          13          0             1          13         -1             1   \n",
       "2          13          2             1          13         -1             1   \n",
       "3          13          0             1          13         -1             1   \n",
       "4          13          0             1          13          1             1   \n",
       "\n",
       "   D_68_count  D_68_last  D_68_nunique  target  \n",
       "0          13          6             1       0  \n",
       "1          13          6             1       0  \n",
       "2          13          6             1       0  \n",
       "3          13          3             3       0  \n",
       "4          13          6             1       0  \n",
       "\n",
       "[5 rows x 995 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ec9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f6c8ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.601387</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.568930</td>\n",
       "      <td>0.631315</td>\n",
       "      <td>0.568930</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>3.527668</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.862166</td>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.794469</td>\n",
       "      <td>0.913501</td>\n",
       "      <td>0.841177</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>6.034091</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.748955</td>\n",
       "      <td>0.061456</td>\n",
       "      <td>0.673112</td>\n",
       "      <td>0.835114</td>\n",
       "      <td>0.697522</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.474728</td>\n",
       "      <td>0.028856</td>\n",
       "      <td>0.428457</td>\n",
       "      <td>0.514222</td>\n",
       "      <td>0.513186</td>\n",
       "      <td>15.846154</td>\n",
       "      <td>4.355957</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.049865</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>0.425764</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>11.846154</td>\n",
       "      <td>6.681394</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 994 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean   P_2_std  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...  0.601387  0.020190   \n",
       "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...  0.862166  0.031436   \n",
       "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...  0.748955  0.061456   \n",
       "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...  0.474728  0.028856   \n",
       "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...  0.324100  0.049865   \n",
       "\n",
       "    P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  ...  \\\n",
       "0  0.568930  0.631315  0.568930   2.222222  3.527668         0         8  ...   \n",
       "1  0.794469  0.913501  0.841177   5.076923  6.034091         0        17  ...   \n",
       "2  0.673112  0.835114  0.697522   6.000000  9.000000         0        23  ...   \n",
       "3  0.428457  0.514222  0.513186  15.846154  4.355957         7        23  ...   \n",
       "4  0.254478  0.425764  0.254478  11.846154  6.681394         1        26  ...   \n",
       "\n",
       "   D_63_nunique  D_64_count  D_64_last  D_64_nunique  D_66_count  D_66_last  \\\n",
       "0             1           9          3             2           9         -1   \n",
       "1             1          13          0             1          13         -1   \n",
       "2             1          13          3             2          13          1   \n",
       "3             1          13          2             1          13         -1   \n",
       "4             1          13          2             2          13         -1   \n",
       "\n",
       "   D_66_nunique  D_68_count  D_68_last  D_68_nunique  \n",
       "0             1           9          6             2  \n",
       "1             1          13          6             1  \n",
       "2             1          13          4             2  \n",
       "3             1          13          5             1  \n",
       "4             1          13          5             2  \n",
       "\n",
       "[5 rows x 994 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "307efd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('train_deloitte.parquet')\n",
    "df_test.to_parquet('test_deloitte.parquet')\n",
    "#df_train.to_parquet('train_deloitte_large.parquet')\n",
    "#df_test.to_parquet('test_deloitte_large.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf5902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "859ae35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 995)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a88d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "658b7bfa",
   "metadata": {},
   "source": [
    "# Lagged Features from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62bd8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/thedevastator/lag-features-are-all-you-need\n",
    "#0.790\n",
    "\n",
    "def read_preprocess_data():\n",
    "    global df_train, df_test\n",
    "    if 'df_train_splitter' in vars() or 'df_train_splitter' in globals():\n",
    "        train = df_train_splitter\n",
    "        test = df_test_splitter\n",
    "    else:\n",
    "        train = pd.read_parquet('train_splitter.parquet')\n",
    "        test = pd.read_parquet('test_splitter.parquet')\n",
    "    strat = train[\"fake_splitter\"]\n",
    "    features = train.drop(['customer_ID'], axis = 1).columns.to_list()\n",
    "    num_cols = [col for col in features if col not in cat_cols+[\"fake_splitter\"]]\n",
    "    #print(num_cols)\n",
    "\n",
    "    seconds_in_day = 60*60*24\n",
    "    seconds_in_day\n",
    "\n",
    "    train[\"S_2\"] = pd.to_datetime(train[\"S_2\"])\n",
    "    #https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    train[\"S_2\"] = train[\"S_2\"].values.astype(np.int64) // 10 ** 9 // seconds_in_day\n",
    "    test[\"S_2\"] = pd.to_datetime(test[\"S_2\"])\n",
    "    #https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "    test[\"S_2\"] = test[\"S_2\"].values.astype(np.int64) // 10 ** 9 // seconds_in_day\n",
    "    \n",
    "    print(\"aggregating categoricals\")\n",
    "    for cat_col in tqdm(cat_cols):\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "        \n",
    "    print(\"rounding numericals\")\n",
    "    for col in tqdm(num_cols):\n",
    "        #print(col)\n",
    "        train[col] = train[col].round(2)\n",
    "        test[col] = test[col].round(2)\n",
    "        \n",
    "    # Train FE\n",
    "    print('Starting train feature extraction')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_cols].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    # Lag Features\n",
    "    print(\"lagging cols\")\n",
    "    for col in tqdm(train_num_agg):\n",
    "        if 'last' in col and col.replace('last', 'first') in train_num_agg:\n",
    "            train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
    "            train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
    "\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_cols].agg(['count', 'first', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    train_labels = pd.read_csv('train_labels.csv')\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    print('Train shape: ', train.shape)    \n",
    "    del train_num_agg, train_cat_agg        \n",
    "    gc.collect()\n",
    "    \n",
    "    # Test FE\n",
    "    print('Starting test feature extraction')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_cols].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "\n",
    "    # Lag Features\n",
    "    print(\"lagging cols\")\n",
    "    for col in tqdm(test_num_agg):\n",
    "        if 'last' in col and col.replace('last', 'first') in test_num_agg:\n",
    "            test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
    "            test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
    "\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_cols].agg(['count', 'first', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    print('Test shape: ', test.shape)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    train[\"fake_splitter\"] = strat\n",
    "    train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    test.replace([np.inf, -np.inf], np.nan,inplace=True)    \n",
    "    \n",
    "    # Save files to disk\n",
    "    train.to_parquet('train_lagged.parquet')\n",
    "    test.to_parquet('test_lagged.parquet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb51086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('train_splitter.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b11bbd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2793669\n",
       "True     2737782\n",
       "Name: fake_splitter, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"fake_splitter\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4897cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregating categoricals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounding numericals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 192/192 [00:47<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train feature extraction\n",
      "lagging cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                        | 0/458913 [00:00<?, ?it/s]/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 493/458913 [00:00<01:33, 4907.89it/s]/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "  0%|▏                                                                                           | 984/458913 [00:00<01:39, 4598.59it/s]/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                          | 1153/458913 [00:00<01:39, 4604.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (458913, 1582)\n",
      "Starting test feature extraction\n",
      "lagging cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                        | 0/924621 [00:00<?, ?it/s]/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 355/924621 [00:00<04:22, 3527.33it/s]/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "  0%|                                                                                            | 708/924621 [00:00<04:34, 3364.35it/s]/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "  0%|                                                                                           | 1045/924621 [00:00<04:45, 3234.40it/s]/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
      "/tmp/ipykernel_279/3119241109.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 1153/924621 [00:00<04:39, 3305.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape:  (924621, 1581)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279/3119241109.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[\"fake_splitter\"] = strat\n"
     ]
    }
   ],
   "source": [
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc9aa5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    train = pd.read_parquet('train_lagged.parquet')\n",
    "    test = pd.read_parquet('test_lagged.parquet')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b29aadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ea04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04d5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0308eb06",
   "metadata": {},
   "source": [
    "# Large set\n",
    "\n",
    "This one simply creates a DF where each target entity is assumed to have 13 rows of data, and all those 13 are pivoted to one row. So someting like this:\n",
    "\n",
    "- Customer 1: row1 (10 values) (time step1 for customer 1)\n",
    "- Customer 1: row2 (10 values) (time step2 for customer 1)\n",
    "- ,,,, until row 13 for customer 1\n",
    "\n",
    "becomes something like this:\n",
    "\n",
    "- C1: A_0, A_1, A_2, ... A_12, B_0, B_1, B_2, ...\n",
    "\n",
    "So all data per a customer is put into a single row for each customer. No data for a time step/customer results in NaN values in that dataframe slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b3e19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
       "\n",
       "   D_39       B_1       B_2       R_1       S_3  D_41       B_3  ...  D_136  \\\n",
       "0     0  0.008724  1.006838  0.009228  0.124035   0.0  0.004709  ...     -1   \n",
       "1     0  0.004923  1.000653  0.006151  0.126750   0.0  0.002714  ...     -1   \n",
       "2     3  0.021655  1.009672  0.006815  0.123977   0.0  0.009423  ...     -1   \n",
       "3     0  0.013683  1.002700  0.001373  0.117169   0.0  0.005531  ...     -1   \n",
       "4     0  0.015193  1.000727  0.007605  0.117325   0.0  0.009312  ...     -1   \n",
       "\n",
       "   D_137  D_138  D_139  D_140  D_141  D_142  D_143     D_144  D_145  \n",
       "0     -1     -1      0      0    0.0    NaN      0  0.000610      0  \n",
       "1     -1     -1      0      0    0.0    NaN      0  0.005492      0  \n",
       "2     -1     -1      0      0    0.0    NaN      0  0.006986      0  \n",
       "3     -1     -1      0      0    0.0    NaN      0  0.006527      0  \n",
       "4     -1     -1      0      0    0.0    NaN      0  0.008126      0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if 'df_train' in vars() or 'df_train' in globals():\n",
    "#    pass\n",
    "#else:\n",
    "#    df_train = pd.read_parquet(\"train.parquet\", engine=\"pyarrow\")\n",
    "df_train = pd.read_parquet(\"train.parquet\", engine=\"pyarrow\")\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41d579f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = find_new_cat_cols(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4f11509",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in df_train.columns if col not in cat_cols if col != \"customer_ID\" and col != \"fake_splitter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3910c1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>0.631315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.814497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0.587042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.810848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>0.609056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>1.004620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>0.614911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.816549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>0.591673</td>\n",
       "      <td>8</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.810456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-02-19  0.631315   \n",
       "1  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-03-25  0.587042   \n",
       "2  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-04-25  0.609056   \n",
       "3  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-05-20  0.614911   \n",
       "4  00000469ba478561f23a92a868bd366de6f6527a684c9a...  2019-06-15  0.591673   \n",
       "\n",
       "   D_39       B_1       B_2  R_1       S_3  D_41       B_3  ...  D_136  D_137  \\\n",
       "0     0  0.010728  0.814497  0.0  0.168651   0.0  0.002347  ...     -1     -1   \n",
       "1     0  0.011026  0.810848  0.0  0.241389   0.0  0.009132  ...     -1     -1   \n",
       "2     0  0.016390  1.004620  0.0  0.266976   0.0  0.004192  ...     -1     -1   \n",
       "3     0  0.021672  0.816549  0.0  0.188947   0.0  0.015325  ...     -1     -1   \n",
       "4     8  0.015923  0.810456  0.0  0.180035   0.0  0.011281  ...     -1     -1   \n",
       "\n",
       "   D_138  D_139  D_140  D_141  D_142  D_143     D_144  D_145  \n",
       "0     -1     -1      0    NaN    NaN     -1  0.008281     -1  \n",
       "1     -1      0      0    0.0    NaN      0  0.003753      0  \n",
       "2     -1      0      0    0.0    NaN      0  0.002156      0  \n",
       "3     -1      0      0    0.0    NaN      0  0.005206      0  \n",
       "4     -1      0      0    0.0    NaN      0  0.007421      0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if 'df_test' in vars() or 'df_test' in globals():\n",
    "#    pass\n",
    "#else:\n",
    "#    df_test = pd.read_parquet(\"test.parquet\", engine=\"pyarrow\")\n",
    "#df_test = df_test.reset_index()\n",
    "df_test = pd.read_parquet(\"test.parquet\", engine=\"pyarrow\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3a9639c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11363762, 190)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9fd9169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16895213, 190)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([df_train, df_test], axis=0)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74be7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "808bcd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5531451"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = df_train.shape[0]\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee677153",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_cols = find_new_cat_cols(df_all)\n",
    "cat_cols = new_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "929bb70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c40e3892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[cat_cols].dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "91e20cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "for cat_col in tqdm(cat_cols):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df_all[cat_col] = le.fit_transform(df_all[cat_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e5a20",
   "metadata": {},
   "source": [
    "## Convert Date to Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27423234",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_in_day = 60*60*24\n",
    "seconds_in_day\n",
    "\n",
    "df_all[\"S_2\"] = pd.to_datetime(df_all[\"S_2\"])\n",
    "#https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "df_all[\"S_2\"] = df_all[\"S_2\"].values.astype(np.int64) // 10 ** 9 // seconds_in_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675acfb6",
   "metadata": {},
   "source": [
    "# Check Value Distributions to Select Outlier Removal Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4442b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.9.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (4.34.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2022.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1752, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1390, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 245, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1368, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 148, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 237, in pip_self_version_check\n",
      "    logger.info(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1446, in info\n",
      "    self._log(INFO, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.1.2', new='22.2.2'),)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "279943d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7bf5e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='D_50', ylabel='Density'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.distplot(df_all[\"D_50\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741edd5d",
   "metadata": {},
   "source": [
    "Hard to say from above if it is normal distributed or not but I will try Tukey first to be sure (works in all cases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f318e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023464027"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"D_50\"].quantile(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84f76938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0716107"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"D_50\"].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cfa1ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [08:28<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "#remove_outliers_tukey(df_all, \"D_50\")\n",
    "for col in tqdm(num_cols):\n",
    "    remove_outliers_tukey(df_all, col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a0c0284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='D_50', ylabel='Density'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.distplot(df_all[\"D_50\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f2e88b",
   "metadata": {},
   "source": [
    "So it was not normally distributed (see above) and Tukey was a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea18b3b",
   "metadata": {},
   "source": [
    "# Min-Max Scale the Data\n",
    "\n",
    "First check categorial data types before trying the scaler (categoricals should remain as are as they are not to be scaled):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "836fadad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[cat_cols].dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72842e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [05:55<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 3min, total: 5min 50s\n",
      "Wall time: 5min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S_2': 1.0,\n",
       " 'P_2': 1.0,\n",
       " 'D_39': 1.0,\n",
       " 'B_1': 1.0,\n",
       " 'B_2': 1.0,\n",
       " 'R_1': 1.0,\n",
       " 'S_3': 1.0000001,\n",
       " 'D_41': 1.0,\n",
       " 'B_3': 1.0,\n",
       " 'D_42': 0.99999994,\n",
       " 'D_43': 1.0,\n",
       " 'D_44': 1.0,\n",
       " 'B_4': 1.0,\n",
       " 'D_45': 1.0,\n",
       " 'B_5': 1.0,\n",
       " 'R_2': 1.0,\n",
       " 'D_46': 1.0,\n",
       " 'D_47': 0.99999994,\n",
       " 'D_48': 0.99999994,\n",
       " 'D_49': 1.0,\n",
       " 'B_6': 0.9999999,\n",
       " 'B_7': 1.0,\n",
       " 'B_8': 1.0,\n",
       " 'D_50': 1.0,\n",
       " 'D_51': 1.0,\n",
       " 'B_9': 1.0,\n",
       " 'R_3': 1.0,\n",
       " 'D_52': 0.99999994,\n",
       " 'P_3': 1.0,\n",
       " 'B_10': 1.0,\n",
       " 'D_53': 1.0,\n",
       " 'S_5': 1.0,\n",
       " 'B_11': 1.0,\n",
       " 'S_6': 1.0,\n",
       " 'D_54': 0.0,\n",
       " 'R_4': 1.0,\n",
       " 'S_7': 0.99999994,\n",
       " 'B_12': 1.0,\n",
       " 'S_8': 1.0,\n",
       " 'D_55': 1.0,\n",
       " 'D_56': 0.99999994,\n",
       " 'B_13': 1.0,\n",
       " 'R_5': 1.0,\n",
       " 'D_58': 1.0,\n",
       " 'S_9': 1.0,\n",
       " 'B_14': 1.0,\n",
       " 'D_59': 0.9999999999999999,\n",
       " 'D_60': 1.0,\n",
       " 'D_61': 0.99999994,\n",
       " 'B_15': 1.0,\n",
       " 'S_11': 1.0,\n",
       " 'D_62': 1.0,\n",
       " 'D_63': 1.0,\n",
       " 'D_64': 1.0,\n",
       " 'D_65': 1.0,\n",
       " 'B_16': 1.0,\n",
       " 'B_17': 1.0,\n",
       " 'B_18': 1.0000001,\n",
       " 'B_19': 1.0,\n",
       " 'D_66': 1.0,\n",
       " 'B_20': 1.0,\n",
       " 'D_68': 1.0,\n",
       " 'S_12': 1.0,\n",
       " 'R_6': 1.0,\n",
       " 'S_13': 1.0,\n",
       " 'B_21': 1.0,\n",
       " 'D_69': 1.0,\n",
       " 'B_22': 1.0,\n",
       " 'D_70': 1.0,\n",
       " 'D_71': 1.0,\n",
       " 'D_72': 1.0,\n",
       " 'S_15': 1.0,\n",
       " 'B_23': 0.99999994,\n",
       " 'D_73': 1.0,\n",
       " 'P_4': 1.0,\n",
       " 'D_74': 1.0,\n",
       " 'D_75': 1.0,\n",
       " 'D_76': 1.0,\n",
       " 'B_24': 1.0,\n",
       " 'R_7': 1.0,\n",
       " 'D_77': 1.0,\n",
       " 'B_25': 1.0000001,\n",
       " 'B_26': 1.0,\n",
       " 'D_78': 1.0,\n",
       " 'D_79': 1.0,\n",
       " 'R_8': 1.0,\n",
       " 'R_9': 1.0,\n",
       " 'S_16': 1.0,\n",
       " 'D_80': 1.0,\n",
       " 'R_10': 1.0,\n",
       " 'R_11': 1.0,\n",
       " 'B_27': 1.0,\n",
       " 'D_81': 1.0,\n",
       " 'D_82': 1.0,\n",
       " 'S_17': 1.0,\n",
       " 'R_12': 0.0,\n",
       " 'B_28': 1.0,\n",
       " 'R_13': 0.0,\n",
       " 'D_83': 1.0,\n",
       " 'R_14': 1.0,\n",
       " 'R_15': 1.0,\n",
       " 'D_84': 1.0,\n",
       " 'R_16': 1.0,\n",
       " 'B_29': 1.0,\n",
       " 'B_30': 1.0,\n",
       " 'S_18': 1.0,\n",
       " 'D_86': 1.0,\n",
       " 'D_87': 0.0,\n",
       " 'R_17': 0.0,\n",
       " 'R_18': 0.0,\n",
       " 'D_88': 1.0,\n",
       " 'B_31': 0.0,\n",
       " 'S_19': 1.0,\n",
       " 'R_19': 1.0,\n",
       " 'B_32': 1.0,\n",
       " 'S_20': 1.0,\n",
       " 'R_20': 1.0,\n",
       " 'R_21': 1.0,\n",
       " 'B_33': 1.0,\n",
       " 'D_89': 0.0,\n",
       " 'R_22': 0.0,\n",
       " 'R_23': 0.0,\n",
       " 'D_91': 1.0,\n",
       " 'D_92': 1.0,\n",
       " 'D_93': 0.0,\n",
       " 'D_94': 1.0,\n",
       " 'R_24': 1.0,\n",
       " 'R_25': 0.0,\n",
       " 'D_96': 1.0,\n",
       " 'S_22': 1.0,\n",
       " 'S_23': 1.0,\n",
       " 'S_24': 1.0,\n",
       " 'S_25': 1.0,\n",
       " 'S_26': 1.0,\n",
       " 'D_102': 1.0,\n",
       " 'D_103': 1.0,\n",
       " 'D_104': 0.99999994,\n",
       " 'D_105': 1.0,\n",
       " 'D_106': 1.0,\n",
       " 'D_107': 1.0,\n",
       " 'B_36': 0.99999994,\n",
       " 'B_37': 1.0,\n",
       " 'R_26': 1.0,\n",
       " 'R_27': 0.99999994,\n",
       " 'B_38': 1.0,\n",
       " 'D_108': 0.0,\n",
       " 'D_109': 0.0,\n",
       " 'D_110': 1.0,\n",
       " 'D_111': 0.0,\n",
       " 'B_39': 1.0,\n",
       " 'D_112': 1.0,\n",
       " 'B_40': 1.0,\n",
       " 'S_27': 0.99999994,\n",
       " 'D_113': 1.0,\n",
       " 'D_114': 1.0,\n",
       " 'D_115': 1.0,\n",
       " 'D_116': 0.0,\n",
       " 'D_117': 1.0,\n",
       " 'D_118': 0.99999994,\n",
       " 'D_119': 0.99999994,\n",
       " 'D_120': 1.0,\n",
       " 'D_121': 0.9999999,\n",
       " 'D_122': 1.0,\n",
       " 'D_123': 1.0,\n",
       " 'D_124': 1.0,\n",
       " 'D_125': 1.0,\n",
       " 'D_126': 1.0,\n",
       " 'D_127': 1.0,\n",
       " 'D_128': 1.0,\n",
       " 'D_129': 1.0,\n",
       " 'B_41': 1.0,\n",
       " 'B_42': 1.0,\n",
       " 'D_130': 1.0,\n",
       " 'D_131': 1.0,\n",
       " 'D_132': 1.0000001,\n",
       " 'D_133': 1.0,\n",
       " 'R_28': 0.0,\n",
       " 'D_134': 0.99999994,\n",
       " 'D_135': 1.0,\n",
       " 'D_136': 1.0,\n",
       " 'D_137': 1.0,\n",
       " 'D_138': 1.0,\n",
       " 'D_139': 1.0,\n",
       " 'D_140': 1.0,\n",
       " 'D_141': 1.0,\n",
       " 'D_142': 1.0,\n",
       " 'D_143': 1.0,\n",
       " 'D_144': 1.0,\n",
       " 'D_145': 1.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scale_df_minmax(df_all, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5b6ba",
   "metadata": {},
   "source": [
    "Above is good to check that the outlier removal resulted in reasonable results. In this case all max values are about 1 so it is ok.\n",
    "\n",
    "In another case we might also want to check min values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af9afcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9839c",
   "metadata": {},
   "source": [
    "# Optimize Memory Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff22fa",
   "metadata": {},
   "source": [
    "Optimize for memory use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "297259f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.9 s, sys: 37.5 s, total: 1min 10s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_all = optimize(df_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d2d667",
   "metadata": {},
   "source": [
    "Check the categoricals still unchanged as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d61895ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[cat_cols].dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76b6e3",
   "metadata": {},
   "source": [
    "# One-Hot Encode Categoricals as Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc841b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embeddings = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fbfa4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 731 ms, sys: 730 ms, total: 1.46 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not create_embeddings:\n",
    "    #one-hot encode all categorical data if not using embeddings in later phase\n",
    "    onehot = pd.get_dummies(df_all[cat_cols].astype(str))\n",
    "    print(onehot.dtypes)\n",
    "    print(onehot.shape)\n",
    "    df_all_hot = pd.concat([df_all, onehot], axis=1)\n",
    "    print(df_all_hot.shape)\n",
    "    del df_all\n",
    "    df_all_hot = df_all_hot.drop(cat_cols, axis=1)\n",
    "    print(df_all_hot.shape)\n",
    "    new_cat_cols = find_new_cat_cols(df_all_hot)\n",
    "    gc.collect()\n",
    "    remove_na_and_inf(df_all_hot)\n",
    "    print(df_all_hot[new_cat_cols].dtypes.value_counts())\n",
    "    df_train = df_all_hot[:train_size].copy()\n",
    "    df_test = df_all_hot[train_size:].copy()\n",
    "    del df_all_hot\n",
    "    del onehot\n",
    "else:\n",
    "    #if using embeddings, leave data as is (later Keras model will learn from this the mapping)\n",
    "    df_train = df_all[:train_size].copy()\n",
    "    df_test = df_all[train_size:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7f17fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2db2e1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11363762, 190)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc90dc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458913"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"customer_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbddc3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  target\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...       0\n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...       0\n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0\n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...       0\n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...       0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.read_csv(\"train_labels.csv\")\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09c54621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(['customer_ID', 'S_2'])\n",
    "df_test = df_test.sort_values(['customer_ID', 'S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "408472bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.sort_values([\"customer_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045a97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3378766a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[new_cat_cols].dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3de434f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       5120\n",
       "2       6098\n",
       "3       5778\n",
       "4       4673\n",
       "5       4671\n",
       "6       5515\n",
       "7       5198\n",
       "8       6110\n",
       "9       6411\n",
       "10      6721\n",
       "11      5961\n",
       "12     10623\n",
       "13    386034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_grouped = df_train.groupby('customer_ID')\n",
    "#df_train_grouped = df_train.sort_values('S_2').groupby('customer_ID')\n",
    "df_train_sizes = df_train_grouped.size()\n",
    "df_train_sizes.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97570e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...\n",
       "1         00000fd6641609c6ece5454664794f0340ad84dddce9a2...\n",
       "2         00001b22f846c82c51f6e3958ccd81970162bae8b007e8...\n",
       "3         000041bdba6ecadd89a52d11886e8eaaec9325906c9723...\n",
       "4         00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...\n",
       "                                ...                        \n",
       "458908    ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...\n",
       "458909    ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...\n",
       "458910    ffff9984b999fccb2b6127635ed0736dda94e544e67e02...\n",
       "458911    ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...\n",
       "458912    fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...\n",
       "Name: customer_ID, Length: 458913, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data should be sorted now by customer id + time, so collect unique customer ID's in correct order:\n",
    "customer_IDs = df_train_grouped.size().reset_index()[\"customer_ID\"]\n",
    "customer_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d346cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target[\"customer_ID\"].equals(customer_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789d1f8",
   "metadata": {},
   "source": [
    "# Pivot Data to all on Same Row per Customer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b9ec8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 189/189 [29:40<00:00,  9.42s/it]\n"
     ]
    }
   ],
   "source": [
    "#TODO: process in df_all? maybe sorting not possible? have to add train column?\n",
    "df_new = pd.DataFrame()\n",
    "old_cols = [col for col in df_train.columns if col != \"customer_ID\"]\n",
    "for col in tqdm(old_cols):\n",
    "    df_f = df_train_grouped[col].agg(lambda x: list(x))\n",
    "    new_cols = []\n",
    "    for x in range(13):\n",
    "        new_cols.append(f\"{col}_{x+1}\")\n",
    "    col_df = pd.DataFrame(df_f.tolist(), columns=new_cols)\n",
    "#    col_df = pd.DataFrame(df_f[col].tolist(), columns=new_cols)\n",
    "    col_df = optimize(col_df)\n",
    "    df_new = pd.concat([df_new, col_df], axis=1)\n",
    "    del col_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd1a6430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279/1654804753.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[\"customer_ID\"] = customer_IDs\n",
      "/tmp/ipykernel_279/1654804753.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[\"target\"] = df_target[\"target\"]\n"
     ]
    }
   ],
   "source": [
    "df_new[\"customer_ID\"] = customer_IDs\n",
    "df_new[\"target\"] = df_target[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f11253ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to fill na's here as the above groupby creates them, and Keras will choke on them\n",
    "remove_na_and_inf(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516cbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f14fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.rename(columns = {'fake_splitter_1':'fake_splitter'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0c7d42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fake_splitter_2',\n",
       " 'fake_splitter_3',\n",
       " 'fake_splitter_4',\n",
       " 'fake_splitter_5',\n",
       " 'fake_splitter_6',\n",
       " 'fake_splitter_7',\n",
       " 'fake_splitter_8',\n",
       " 'fake_splitter_9',\n",
       " 'fake_splitter_10',\n",
       " 'fake_splitter_11',\n",
       " 'fake_splitter_12',\n",
       " 'fake_splitter_13']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = [f\"fake_splitter_{col+2}\" for col in range(12)]\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "429a769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in df_new.columns if \"fake\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2b794f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ebc685a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix = \"\"\n",
    "if create_embeddings:\n",
    "    postfix = \"_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ca507c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'large_train_embeddings.parquet'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"large_train{postfix}.parquet\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1334b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7c9d7c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 2459)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c3026cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new[\"fake_splitter\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "905b524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_f\n",
    "del df_train\n",
    "del df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc914ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "05b0058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display.max_rows\")\n",
    "pd.reset_option(\"display.min_rows\")\n",
    "pd.reset_option(\"display.max_columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59eade95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d2ecf",
   "metadata": {},
   "source": [
    "# Same for Kaggle Test Set as Above for Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2a5f4983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8366.417182922363"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.memory_usage().sum() / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "73be5f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float32    189\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e80fbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.to_parquet(\"deloitte-data/keras_train.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fbb59cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = [col for col in df_test.columns if \"fake\" in col]\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8407fb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_ID'], dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a1b8fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb87b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sort_values(['customer_ID', 'S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0c6c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       5827\n",
       "2       8174\n",
       "3       7803\n",
       "4       8348\n",
       "5       8419\n",
       "6       8833\n",
       "7       9653\n",
       "8       9775\n",
       "9      10552\n",
       "10      9638\n",
       "11      9943\n",
       "12     16327\n",
       "13    811329\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_grouped = df_test.groupby('customer_ID')\n",
    "df_test_sizes = df_test_grouped.size()\n",
    "df_test_sizes.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d44b1f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         00000469ba478561f23a92a868bd366de6f6527a684c9a...\n",
       "1         00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...\n",
       "2         0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...\n",
       "3         00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...\n",
       "4         00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...\n",
       "                                ...                        \n",
       "924616    ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c...\n",
       "924617    ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3...\n",
       "924618    ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475...\n",
       "924619    ffffddef1fc3643ea179c93245b68dca0f36941cd83977...\n",
       "924620    fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61...\n",
       "Name: customer_ID, Length: 924621, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test[\"customer_ID\"].nunique()\n",
    "customer_IDs = df_test_grouped.size().reset_index()[\"customer_ID\"]\n",
    "customer_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "acb5078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                                | 1/189 [00:32<1:41:18, 32.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m old_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_test\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m tqdm(old_cols):\n\u001b[0;32m----> 4\u001b[0m     df_f \u001b[38;5;241m=\u001b[39m \u001b[43mdf_test_grouped\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     new_cols \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m13\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/generic.py:287\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# TODO: KeyError is raised in _python_agg_general,\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m#  see test_groupby.test_basic\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;66;03m# if this function is invalid for this dtype, we will ignore it.\u001b[39;00m\n\u001b[0;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1492\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/ops.py:981\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    978\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 981\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/ops.py:1003\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# equiv: splitter = self._get_splitter(obj, axis=0)\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m splitter \u001b[38;5;241m=\u001b[39m get_splitter(obj, ids, ngroups, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m-> 1003\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m   1004\u001b[0m     group \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39m__finalize__(obj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1005\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/ops.py:1233\u001b[0m, in \u001b[0;36mDataSplitter.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1230\u001b[0m starts, ends \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mgenerate_slices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslabels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(starts, ends):\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chop\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/groupby/ops.py:1248\u001b[0m, in \u001b[0;36mSeriesSplitter._chop\u001b[0;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[1;32m   1246\u001b[0m mgr \u001b[38;5;241m=\u001b[39m sdata\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mget_slice(slice_obj)\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;66;03m# __finalize__ not called here, must be applied by caller if applicable\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py:323\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    318\u001b[0m rdiv: Callable[[Series, Any], Series]\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Constructors\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    325\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    327\u001b[0m     dtype: Dtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    328\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    330\u001b[0m     fastpath: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager))\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     ):\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# GH#33357 called with just the SingleBlockManager\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         NDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "old_cols = [col for col in df_test.columns if col != \"customer_ID\"]\n",
    "for col in tqdm(old_cols):\n",
    "    df_f = df_test_grouped[col].agg(lambda x: list(x))\n",
    "    new_cols = []\n",
    "    for x in range(13):\n",
    "        new_cols.append(f\"{col}_{x+1}\")\n",
    "    col_df = pd.DataFrame(df_f.tolist(), columns=new_cols)\n",
    "#    col_df = pd.DataFrame(df_f[col].tolist(), columns=new_cols)\n",
    "    col_df = optimize(col_df)\n",
    "    df_new = pd.concat([df_new, col_df], axis=1)\n",
    "    del col_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to fill na's here as the above groupby creates them\n",
    "remove_na_and_inf(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcb4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_IDs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8cb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"customer_ID\"] = customer_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6959a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.rename(columns = {'fake_splitter_1':'fake_splitter'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa62ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = df_new.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2795389",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"large_test{postfix}.parquet\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34942bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587bbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd6259e",
   "metadata": {},
   "source": [
    "# For Keras Embedding\n",
    "\n",
    "The above \"large\" dataset also has option for embeddings type categorical data, this one does the same but for the original dataset (no derived statistics as above sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_train' in vars() or 'df_train' in globals():\n",
    "    print(\"df_train loaded, skipping load\")\n",
    "    pass\n",
    "else:\n",
    "    df_train = pd.read_parquet(\"train.parquet\", engine=\"pyarrow\")\n",
    "    print(\"loaded training data\")\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5abcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa311b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = find_new_cat_cols(df_train)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e923f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in df_train.columns if col not in cat_cols if col != \"customer_ID\" and col != \"fake_splitter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eadb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_test' in vars() or 'df_test' in globals():\n",
    "    print(\"df_test already loaded, skipping load\")\n",
    "    pass\n",
    "else:\n",
    "    df_test = pd.read_parquet(\"test.parquet\", engine=\"pyarrow\")\n",
    "    print(\"loaded test data\")\n",
    "#df_test = df_test.reset_index()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test], axis=0)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"S_2\"] = pd.to_datetime(df_all[\"S_2\"])\n",
    "#https://stackoverflow.com/questions/40881876/python-pandas-convert-datetime-to-timestamp-effectively-through-dt-accessor\n",
    "df_all[\"S_2\"] = df_all[\"S_2\"].values.astype(np.int64) // 10 ** 9 // seconds_in_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e2056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = df_train.shape[0]\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = df_all.nunique()\n",
    "small_count_cols = unique_counts[unique_counts < 10]\n",
    "small_count_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_count_cols = small_count_cols.drop(\"fake_splitter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_cols = find_new_cat_cols(df_all)\n",
    "cat_cols = new_cat_cols\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bfca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_count_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313adc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddables = set(cat_cols).union(set(small_count_cols.index))\n",
    "len(embeddables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"B_30\" in embeddables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = embeddables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in df_train.columns if col not in cat_cols if col != \"customer_ID\" and col != \"fake_splitter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bf23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_df_outliers(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_df_minmax(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_na_and_inf(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[:train_size].copy()\n",
    "df_test = df_all[train_size:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(\"train_labels.csv\")\n",
    "#df_train = pd.read_parquet('train_embedding.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb44a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_target, on = 'customer_ID', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('train_embedding.parquet')\n",
    "df_test.to_parquet('test_embedding.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc94bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9136d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd63363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1cd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffedc088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db8fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b3831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
