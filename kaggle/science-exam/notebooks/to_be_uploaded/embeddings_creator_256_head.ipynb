{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517a1ff1-42d0-4f40-a178-59358468a0ba",
   "metadata": {},
   "source": [
    "This notebook assumes a database of document chunks already exists. From those chunks it loads the first chunk of each document and creates an embdding for that chunk. Later I used a separate notebook to index all these embeddings into a vector database (FAISS in this case). This was simply a separate notebook and seaprate database to make it easier to experiment with creating the embeddings, storing them generally, and then trying them with different vector database implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96437392-b186-4753-90c3-88e61d88a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#embedding_model_path = \"/mystuff/llm/gte-base\"\n",
    "#embedding_model_path = \"/mystuff/llm/all-MiniLM-L12-v2\"\n",
    "#embedding_model_path = \"/mystuff/llm/bge-small-en\"\n",
    "embedding_model_path = \"/mystuff/llm/bge-base-en\"\n",
    "\n",
    "embedding_model = SentenceTransformer(embedding_model_path, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e235009-0002-4e89-8341-449801eda6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks(chunks_to_embed):\n",
    "    np_embeddings = embedding_model.encode(chunks_to_embed)\n",
    "    doc_embeddings = np_embeddings\n",
    "    return doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce25c99-e7a4-4a7f-a7b8-92db8075f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def fetch_documents(database_path):\n",
    "    connection = sqlite3.connect(database_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT DISTINCT document_id FROM documents ORDER BY document_id;\")\n",
    "    document_ids = cursor.fetchall()\n",
    "\n",
    "    for doc_id in document_ids:\n",
    "        doc_id = doc_id[0]  # Unpack the tuple\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT \n",
    "                d.document_id, d.document_title,\n",
    "                s.section_id, s.section_title,\n",
    "                tc.chunk_id, tc.content\n",
    "            FROM documents d\n",
    "            LEFT JOIN sections s ON s.document_id = d.document_id\n",
    "            LEFT JOIN text_chunks tc ON tc.document_id = d.document_id AND tc.section_id = s.section_id\n",
    "            WHERE d.document_id = ?\n",
    "            ORDER BY d.document_id, s.section_id, tc.chunk_id;\n",
    "        \"\"\", (doc_id,))\n",
    "\n",
    "        document = {\n",
    "            'id': doc_id,\n",
    "            'title': None,\n",
    "            'sections': {}\n",
    "        }\n",
    "\n",
    "        for row in cursor:\n",
    "            document_id, document_title, section_id, section_title, chunk_id, content = row\n",
    "\n",
    "            # Set the document title\n",
    "            document['title'] = document_title\n",
    "\n",
    "            # Add section if not already present\n",
    "            if section_id and section_id not in document['sections']:\n",
    "                document['sections'][section_id] = {\n",
    "                    'title': section_title,\n",
    "                    'chunks': {}\n",
    "                }\n",
    "\n",
    "            # Add chunk\n",
    "            if chunk_id:\n",
    "                document['sections'][section_id]['chunks'][chunk_id] = content\n",
    "\n",
    "        yield document  # Yield the document for processing\n",
    "\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b526a3-73e9-483c-9378-88d1b9b6496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15420445-cd5b-41ac-ae23-19c89a4cc307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while reading from the database: no such table: embeddings\n",
      "The last inserted ID is: 0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_last_inserted_id(db_path='embedding_vectors_256_head.db'):\n",
    "    # Connect to SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    last_id = None\n",
    "\n",
    "    try:\n",
    "        # Query to fetch the maximum ID value\n",
    "        cursor.execute(\"SELECT MAX(id) FROM embeddings\")\n",
    "        last_id = cursor.fetchone()[0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading from the database: {e}\")\n",
    "        return 0\n",
    "\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "    return last_id\n",
    "\n",
    "# Get the ID of the last inserted embedding\n",
    "last_inserted_id = get_last_inserted_id()\n",
    "if last_inserted_id is None:\n",
    "    last_inserted_id = 0\n",
    "print(f\"The last inserted ID is: {last_inserted_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77ae589-997a-4af0-a8f3-71b887bb18ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chunk found with the given Chunk ID 0.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def fetch_document_id_by_chunk_id(database_path, chunk_id):\n",
    "    # Establish the database connection\n",
    "    connection = sqlite3.connect(database_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare and execute the SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT d.document_id\n",
    "    FROM text_chunks tc\n",
    "    JOIN sections s ON tc.section_id = s.section_id\n",
    "    JOIN documents d ON tc.document_id = d.document_id\n",
    "    WHERE tc.chunk_id = ?;\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (chunk_id,))\n",
    "\n",
    "    # Fetch and process the result\n",
    "    row = cursor.fetchone()\n",
    "    if row:\n",
    "        document_id = row[0]\n",
    "        print(f\"Document ID corresponding to Chunk ID {chunk_id}: {document_id}\")\n",
    "        return document_id\n",
    "    else:\n",
    "        print(f\"No chunk found with the given Chunk ID {chunk_id}.\")\n",
    "        return 0\n",
    "\n",
    "    # Close the database connection\n",
    "    connection.close()\n",
    "\n",
    "# Usage example\n",
    "database_path = \"wikipedia_chunks_256.db\"\n",
    "chunk_id_to_query = last_inserted_id\n",
    "last_inserted_doc_id = fetch_document_id_by_chunk_id(database_path, chunk_id_to_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875a8149-0abe-4190-90cf-9b8a0c8c14f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d080eca2-8aa6-4239-8d33-4408c700b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_inserted_doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08d38391-2b26-4b0d-a28b-76ac50844b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = fetch_documents(database_path)\n",
    "doc = next(docs)\n",
    "del docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64269c9-3fd4-4738-8867-356142986107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "print(doc[\"sections\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb9a986-da0f-4896-8a47-499025bf61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_section = list(doc[\"sections\"].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3952eadf-beff-451d-bd16-7b10f8f52631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Introduction',\n",
       " 'chunks': {1: \"Introduction - '''Anarchism''' is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation states, and capitalism\",\n",
       "  2: '. Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations',\n",
       "  3: '. As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as the libertarian wing of the socialist movement (libertarian socialism).',\n",
       "  4: 'Humans have lived in societies without formal hierarchies long before the establishment of states, realms, or empires. With the rise of organised hierarchical bodies, scepticism toward authority also rose',\n",
       "  5: '. Although traces of anarchist ideas are found all throughout history, modern anarchism emerged from the Enlightenment',\n",
       "  6: \". During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers' struggles for emancipation\",\n",
       "  7: '. Various anarchist schools of thought formed during this period',\n",
       "  8: '. Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism',\n",
       "  9: '. In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more, growing in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements.',\n",
       "  10: 'Anarchists employ diverse approaches, which may be generally divided into revolutionary and evolutionary strategies; there is significant overlap between the two',\n",
       "  11: '. Evolutionary methods try to simulate what an anarchist society might be like, but revolutionary tactics, which have historically taken a violent turn, aim to overthrow authority and the state',\n",
       "  12: '. Many facets of human civilization have been influenced by anarchist theory, critique, and praxis.'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[\"sections\"][first_section]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd41793d-43f9-43e6-9dcb-420b6f79f625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Anarchism: Introduction: Introduction - '''Anarchism''' is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation states, and capitalism\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = sorted(list(doc[\"sections\"].keys()))\n",
    "first_section = keys[0]\n",
    "keys = sorted(list(doc[\"sections\"][first_section][\"chunks\"].keys()))\n",
    "first_chunk = keys[0]\n",
    "first_section_title = doc[\"sections\"][first_section][\"title\"]\n",
    "first_content = doc[\"sections\"][first_section][\"chunks\"][first_chunk]\n",
    "first_chunk = doc[\"title\"]+\": \"+first_section_title+\": \"+first_content\n",
    "first_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc9449b-7165-4c00-b206-ce33f583c7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac865cb2a0a4a528cfe1e193f9945bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28176378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "chunk_database_path = \"wikipedia_chunks_256.db\"\n",
    "vector_database_path = \"embedding_vectors_256_head_bge_base.db\"\n",
    "\n",
    "conn = sqlite3.connect(vector_database_path)\n",
    "cursor = conn.cursor()\n",
    "conn.execute(\"BEGIN TRANSACTION;\")\n",
    "\n",
    "embeddings = {}\n",
    "last_record = 0\n",
    "batch_size = 50\n",
    "chunk_ids = []\n",
    "chunks_to_embed = []\n",
    "for idx, doc in tqdm(enumerate(fetch_documents(chunk_database_path)), total=6082528):\n",
    "    if doc[\"id\"] <= last_inserted_doc_id:\n",
    "        #print(doc[\"id\"])\n",
    "        continue\n",
    "    try:\n",
    "        #print(doc[\"title\"])\n",
    "\n",
    "        keys = sorted(list(doc[\"sections\"].keys()))\n",
    "        #print(f\"section keys: {keys}\")\n",
    "        first_section = keys[0]\n",
    "        keys = sorted(list(doc[\"sections\"][first_section][\"chunks\"].keys()))\n",
    "        #print(f\"chunk keys: {keys}\")\n",
    "        first_section_title = doc[\"sections\"][first_section][\"title\"]\n",
    "        if len(keys) == 0:\n",
    "            first_content = \"\"\n",
    "        else:\n",
    "            first_chunk = keys[0]\n",
    "            first_content = doc[\"sections\"][first_section][\"chunks\"][first_chunk]\n",
    "        first_chunk = doc[\"title\"]+\": \"+first_section_title+\": \"+first_content\n",
    "\n",
    "        chunk_id = doc[\"id\"]\n",
    "        chunk_ids.append(chunk_id)\n",
    "        chunks_to_embed.append(first_chunk)\n",
    "        if chunk_id - last_record > batch_size:\n",
    "            last_record = chunk_id\n",
    "            doc_embeddings = embed_chunks(chunks_to_embed)\n",
    "            for chunk_id, chunk_embedding in zip(chunk_ids, doc_embeddings):\n",
    "                #print(f\"{chunk_id}: {chunk_embedding}\")\n",
    "                embedding_bytes = chunk_embedding.tobytes()\n",
    "                embeddings[chunk_id] = embedding_bytes\n",
    "            # Insert buffered vectors into the database and clear the buffer\n",
    "            cursor.executemany(\"INSERT INTO embeddings (id, vector) VALUES (?, ?)\", embeddings.items())\n",
    "            conn.commit()\n",
    "            #print(f\"Saved {chunk_id} embedding vectors to the database.\")\n",
    "            conn.execute(\"BEGIN TRANSACTION;\")\n",
    "            embeddings.clear()\n",
    "            chunk_ids.clear()\n",
    "            chunks_to_embed.clear()\n",
    "    except Exception as e:\n",
    "        #import traceback\n",
    "        #traceback.print_exc()\n",
    "        print(f\"An error occurred while processing doc: {doc['title']} : {e}\")\n",
    "        # Roll back any changes if an error occurs\n",
    "        conn.rollback()\n",
    "        conn.execute(\"BEGIN TRANSACTION;\")\n",
    "        #break\n",
    "\n",
    "# Commit any remaining transactions\n",
    "conn.commit()\n",
    "conn.close()\n",
    "# run 1 was at 246541 estimate 210h to finish\n",
    "# max chunk id at this time was 2513706\n",
    "# document id was 246541\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50315ac-f8a7-4ac0-a7ad-72dce0e69d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f08571-7270-47a9-b3dd-31cc290b17f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
