{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad363b12-19eb-41fc-8ebd-7db9e1b9b73b",
   "metadata": {},
   "source": [
    "This notebook just load a prebuilt FAISS index and trials using it to see the process works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa08c19-80cc-497b-9afb-8890159299ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#the GPU version seems to be only available on Anaconda, and various issues to build it myself. Oh well...\n",
    "!pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d5a72a-e79d-4b66-a869-2354b77ccbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss import write_index, read_index\n",
    "\n",
    "#this is the FAISS index created originally with the faiss_indexer notebook\n",
    "sentence_index = read_index(\"/mystuff/notebooks/faiss_index_512_flat_small.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5048738-9b24-4d29-b2b9-126105ea4193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mystuff/notebooks/to_be_uploaded\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e9dbfc-aaf1-4dfd-9da9-662c55b7592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "#embedding_model_path = \"/mystuff/llm/gte-base\"\n",
    "#embedding_model_path = \"/mystuff/llm/all-MiniLM-L12-v2\"\n",
    "embedding_model_path = \"/mystuff/llm/bge-small-en\"\n",
    "\n",
    "embedding_model = SentenceTransformer(embedding_model_path, device='cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f759c-51ad-4611-9ece-2f5c5da4440a",
   "metadata": {},
   "source": [
    "# Example question for embeddings search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed13f12-352e-410f-a126-296189067f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeddings = embedding_model.encode([\"What is the definition of anarchism?\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8a8c9c-3692-4b83-bcaa-0f69a997d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = sentence_index.search(q_embeddings, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f93130-434b-4e7c-a3a6-42ba759d2db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1054330, 1880579, 5809849]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I = id's of the found documents\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8caf998f-b9d6-49aa-b67c-7e8524b1ea06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.58313 , 19.57069 , 20.886288]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D = similarity scores of found documents, \n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2891cc7-1360-4106-9c5b-429f25673f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"/mystuff/science-exam/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de829560-8f28-4c40-b389-ff57a169d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(df, idx, options = ['A','B','C','D','E']):\n",
    "    preamble = \"You are a student taking an exam, and you need to work hard to answer \"\\\n",
    "               \"the multiple-choice questions correctly in order to get a higher score. \"\\\n",
    "               \"Please choose the most likely correct answer from the options provided below. \"\\\n",
    "               \"Your answer must be selected from the given options, and you can only respond with the letter of the choice.\"\n",
    "    postamble = \"Please respond with the letter of the option directly.\"\n",
    "\n",
    "    prompt = df.loc[idx, 'prompt']\n",
    "    answers = df.loc[idx,options].tolist()\n",
    "    correct_answer = None\n",
    "    if \"answer\" in df.columns:\n",
    "        correct_answer = df.loc[idx, 'answer']\n",
    "\n",
    "    options_text = \"\"\n",
    "    for option, answer in zip(options, answers):\n",
    "        options_text += (f\"{option}) {answer}\\n\")\n",
    "    \n",
    "    input_text = f\"{preamble}\\n\\nQuestion:\\n{prompt}\\n\\nOptions:\\n{options_text}\\n{postamble}\"\n",
    "    return input_text, correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781cba4-e39f-4251-927c-31c033074876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "549a5aba-e327-4409-8c72-c966f1319d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pick the prompt and its answer options from a dataframe row.\n",
    "# Not that interesting but simplifies a little:\n",
    "def collect_answer_options(df, idx, options = ['A','B','C','D','E']):\n",
    "    prompt = df.loc[idx, 'prompt']\n",
    "    answers = df.loc[idx,options].tolist()\n",
    "    correct_answer = None\n",
    "    if \"answer\" in df.columns:\n",
    "        correct_answer = df.loc[idx, 'answer']\n",
    "    \n",
    "    return prompt, answers, correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f95934-229f-4483-a424-1837c94816ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(df, idx, options = ['A','B','C','D','E']):\n",
    "    preamble = \"You are a student taking an exam, and you need to work hard to answer \"\\\n",
    "               \"the multiple-choice questions correctly in order to get a higher score. \"\\\n",
    "               \"Please choose the most likely correct answer from the options provided below. \"\\\n",
    "               \"Your answer must be selected from the given options, and you can only respond with the letter of the choice.\"\n",
    "    postamble = \"Please respond with the letter of the option directly.\"\n",
    "\n",
    "    prompt = df.loc[idx, 'prompt']\n",
    "    answers = df.loc[idx,options].tolist()\n",
    "    correct_answer = None\n",
    "    if \"answer\" in df.columns:\n",
    "        correct_answer = df.loc[idx, 'answer']\n",
    "\n",
    "    options_text = \"\"\n",
    "    for option, answer in zip(options, answers):\n",
    "        options_text += (f\"{option}) {answer}\\n\")\n",
    "    \n",
    "    input_text = f\"{preamble}\\n\\nQuestion:\\n{prompt}\\n\\nOptions:\\n{options_text}\\n{postamble}\"\n",
    "    return input_text, correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb3a440-2733-44ab-b49f-c84983ec438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a student taking an exam, and you need to work hard to answer the multiple-choice questions correctly in order to get a higher score. Please choose the most likely correct answer from the options provided below. Your answer must be selected from the given options, and you can only respond with the letter of the choice.\n",
      "\n",
      "Question:\n",
      "Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed \"missing baryonic mass\" discrepancy in galaxy clusters?\n",
      "\n",
      "Options:\n",
      "A) MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called \"fuzzy dark matter.\"\n",
      "B) MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.\n",
      "C) MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.\n",
      "D) MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2.\n",
      "E) MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter.\n",
      "\n",
      "Please respond with the letter of the option directly.\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "input_text, correct_answer = format_input(df_train, 0)\n",
    "print(input_text)\n",
    "print(correct_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50ce1686-3875-4a81-a43f-cb4017ae7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeddings = embedding_model.encode([input_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30e49fb-0294-4903-97c4-54c4ef0df121",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = sentence_index.search(q_embeddings, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be5a915f-1974-44af-b46d-c4543de8ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2407532, 3164010, 4896391]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a9f9b-7172-4b62-8b15-1342a91be59b",
   "metadata": {},
   "source": [
    "# SQLite functions to fetch documents based on FAISS id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ef92ce-5790-4b1d-934e-c149abe86305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def fetch_document_and_chunks_by_id(database_path, document_id):\n",
    "    # Establish the database connection\n",
    "    connection = sqlite3.connect(database_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare and execute the SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        d.document_id, d.document_title,\n",
    "        s.section_id, s.section_title,\n",
    "        tc.chunk_id, tc.content\n",
    "    FROM documents d\n",
    "    LEFT JOIN sections s ON s.document_id = d.document_id\n",
    "    LEFT JOIN text_chunks tc ON tc.document_id = d.document_id AND tc.section_id = s.section_id\n",
    "    WHERE d.document_id = ?\n",
    "    ORDER BY d.document_id, s.section_id, tc.chunk_id;\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (document_id,))\n",
    "\n",
    "    # Initialize an empty dictionary to hold the document and its chunks\n",
    "    # TODO: throw some error if this is not right\n",
    "    document = {\n",
    "        'id': document_id,\n",
    "        'sections': {}\n",
    "    }\n",
    "\n",
    "    # Fetch and process the result\n",
    "    for row in cursor:\n",
    "        #print(row)\n",
    "        _, document_title, section_id, section_title, chunk_id, content = row\n",
    "\n",
    "        # Set the document title\n",
    "        document['title'] = document_title\n",
    "\n",
    "        # Add section if not already present\n",
    "        if section_id and section_id not in document['sections']:\n",
    "            document['sections'][section_id] = {\n",
    "                'title': section_title,\n",
    "                'chunks': {}\n",
    "            }\n",
    "\n",
    "        # Add chunk\n",
    "        if chunk_id:\n",
    "            document['sections'][section_id]['chunks'][chunk_id] = content\n",
    "\n",
    "    # Close the database connection\n",
    "    connection.close()\n",
    "\n",
    "    return document\n",
    "\n",
    "# Usage example [1054330,       0, 1880579]\n",
    "chunk_database_path = \"../wikipedia_chunks_256.db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcad5ac6-7999-45e1-8c88-45b7469a36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_print_doc_by_id(document_id_to_query, print_all=False):\n",
    "#    document_id_to_query = 1880580 # Replace with the document ID you're interested in\n",
    "    document = fetch_document_and_chunks_by_id(chunk_database_path, document_id_to_query)\n",
    "    #print(document)\n",
    "    \n",
    "    # Print the document and its chunks\n",
    "    all_chunks = []\n",
    "    if print_all:\n",
    "        print(f\"Document ID: {document['id']}, Title: {document['title']}\")\n",
    "    for sec_id, sec_data in document['sections'].items():\n",
    "        #print(f\"  Section ID: {sec_id}, Title: {sec_data['title']}\")\n",
    "        for chunk_id, content in sec_data['chunks'].items():\n",
    "            if print_all:\n",
    "                print(f\"    Chunk ID: {chunk_id}, Content: {content[:50]}...\")  # Printing first 50 characters of each chunk\n",
    "                # this was used to estimate how well the search works, using the first question in the dataset\n",
    "                # if \"MOND\" in content:\n",
    "                #    print(\"FOUND MOND\")\n",
    "            all_chunks.append(content)\n",
    "    return document, all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3747efb4-e55f-466b-8088-b98c0b9bb456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2407533\n",
      "\n",
      "3164011\n",
      "\n",
      "4896392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "doc_chunks = []\n",
    "doc_chunks_flat = []\n",
    "for doc_id in I[0]:\n",
    "    print(doc_id+1)\n",
    "    doc, chunks = load_and_print_doc_by_id(int(doc_id+1))\n",
    "    print()\n",
    "    docs.append(doc)\n",
    "    doc_chunks.append(chunks)\n",
    "    doc_chunks_flat.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca3f0d2-5dd0-4887-99b3-0b50659ba6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''Modified Newtonian dynamics''' ('''MOND''') is a hypothesis that proposes a modification of Newton's law of universal gravitation to account for observed properties of galaxies. It is an alternative to the hypothesis of dark matter in terms of explaining why galaxies do not appear to obey the currently understood laws of physics.\n"
     ]
    }
   ],
   "source": [
    "print(doc_chunks[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b51d63-a640-4e45-a516-7fbf6c3f8687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''AQUAL''' is a theory of gravity based on Modified Newtonian Dynamics (MOND), but using a Lagrangian. It was developed by Jacob Bekenstein and Mordehai Milgrom in their 1984 paper, \"Does the missing mass problem signal the breakdown of Newtonian gravity?\". \"AQUAL\" stands for \"A QUAdratic Lagrangian\".\n",
      "\n",
      "The gravitational force law obtained from MOND, \n",
      "\n",
      ":\n",
      "has a serious defect: it violates Newton's third law of motion, and therefore fails to conserve momentum and energy. To see this, consider two objects with ; then we have:\n",
      "\n",
      ":\n",
      "\n",
      "but the third law gives  so we would get \n",
      "\n",
      ": \n",
      "\n",
      "even though  and  would therefore be constant, contrary to the MOND assumption that it is linear for small arguments.\n",
      "\n",
      "This problem can be rectified by deriving the force law from a Lagrangian, at the cost of possibly modifying the general form of the force law. Then conservation laws could then be derived from the Lagrangian by the usual means.\n"
     ]
    }
   ],
   "source": [
    "print(doc_chunks[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc55f57-f6e7-4e33-88c3-44a36b64458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cosmology, the '''missing baryon problem''' is an observed discrepancy between the amount of baryonic matter detected from shortly after the Big Bang and from more recent epochs. Observations of the cosmic microwave background and Big Bang nucleosynthesis studies have set constraints on the abundance of baryons in the early universe, finding that baryonic matter accounts for approximately 4.8% of the energy contents of the Universe. At the same time, a census of baryons in the recent observable universe has found that observed baryonic matter accounts for less than half of that amount. This discrepancy is commonly known as the missing baryon problem. The missing baryon problem is different from the dark matter problem, which is non-baryonic in nature.\n"
     ]
    }
   ],
   "source": [
    "print(doc_chunks[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516cb6d-e144-4983-982c-91afed813070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205071d-b419-419a-8ddf-72896032901b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
