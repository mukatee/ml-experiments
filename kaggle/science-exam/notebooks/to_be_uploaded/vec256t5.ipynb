{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the actual notebook to make the kaggle competition submisstion.\n",
    "Uses pre-built FAISS index for wikipedia, along with the pre-chunked documents in sqlite database.\n",
    "\n",
    "Find documents matching question + possible answers pairs from Wikipedia based on FAISS index.\n",
    "Find document chunks most similar to the query.\n",
    "Select answer using FlanT5 and in-context, RAG-based, Question Answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:47:49.752890494Z",
     "start_time": "2023-09-19T19:47:49.695733232Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "on_kaggle = False\n",
    "if os.path.exists(\"/kaggle/input\"):\n",
    "    on_kaggle = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some of the HuggingFace T5 configuration files have maximum token count of 512, it appears the model has been trained on 2048 tokens and actually has some kind of relative positional embeddings for theoretically unlimited input size:\n",
    "\n",
    "- https://github.com/huggingface/transformers/issues/5204\n",
    "- https://github.com/google-research/text-to-text-transfer-transformer/issues/273\n",
    "- https://huggingface.co/google/flan-t5-xxl/discussions/41\n",
    "\n",
    "Therefor, I tried with context length of up to 3000 tokens. Seemed to give slight increase, up to that context size, in score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:47:50.878536707Z",
     "start_time": "2023-09-19T19:47:50.794854398Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_CONTEXT = 3000\n",
    "MAX_CONTEXT_RAG = MAX_CONTEXT - 200\n",
    "\n",
    "CHUNK_SIZE = 256\n",
    "#better to load a little more chunks than that which fits into the max context. allows for selection by leaving some out.\n",
    "CHUNKS_TO_LOAD = int(MAX_CONTEXT / CHUNK_SIZE * 1.2) + 1\n",
    "print(CHUNKS_TO_LOAD)\n",
    "if CHUNK_SIZE == 512:\n",
    "    CHUNKS_TO_LOAD = 10\n",
    "if CHUNK_SIZE == 384:\n",
    "    CHUNKS_TO_LOAD = 13\n",
    "if CHUNK_SIZE == 256:\n",
    "    CHUNKS_TO_LOAD = 15\n",
    "CHUNKS_TO_LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:47:59.402585721Z",
     "start_time": "2023-09-19T19:47:59.385706551Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "\n",
    "#paths on kaggle are different, as well as some pip installs\n",
    "if on_kaggle:\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            pass\n",
    "            #print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:47:59.850127386Z",
     "start_time": "2023-09-19T19:47:59.821190882Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if on_kaggle:\n",
    "    !pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "else:\n",
    "    !pip install faiss-cpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:00.102450019Z",
     "start_time": "2023-09-19T19:48:00.073521562Z"
    }
   },
   "outputs": [],
   "source": [
    "if on_kaggle:\n",
    "    #sentence-transformers needs to build the wheel and write access to filesystem\n",
    "    !cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n",
    "    !pip install -U /kaggle/working/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:00.273894963Z",
     "start_time": "2023-09-19T19:48:00.251455093Z"
    }
   },
   "outputs": [],
   "source": [
    "if on_kaggle:\n",
    "    #https://www.kaggle.com/code/chesterx/llm-science-cut-fragment-length/notebook\n",
    "    #transformers is already at newer version\n",
    "    #!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n",
    "    !pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n",
    "    !pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n",
    "    !pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:00.485717826Z",
     "start_time": "2023-09-19T19:48:00.462526653Z"
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def print_stats():\n",
    "    # Getting % usage of virtual_memory ( 3rd field)\n",
    "    print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "    # Getting usage of virtual_memory in GB ( 4th field)\n",
    "    print('RAM Used (GB):', psutil.virtual_memory()[3]/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:00.683874134Z",
     "start_time": "2023-09-19T19:48:00.654179476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM memory % used: 9.8\n",
      "RAM Used (GB): 11.994046464\n"
     ]
    }
   ],
   "source": [
    "print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:00.893517462Z",
     "start_time": "2023-09-19T19:48:00.869618530Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if on_kaggle:\n",
    "    data_dir = \"/kaggle/input/kaggle-llm-science-exam\"\n",
    "    index_dir = \"/kaggle/input/faiss-512-wikipedia-202308/\"\n",
    "    embedding_dir = \"/kaggle/input/bge-small-en/bge-small-en\"\n",
    "    llm_dir = \"/kaggle/input/flan-t5/pytorch/xl/3\"\n",
    "    if CHUNK_SIZE == 256:\n",
    "        chunk_database_path = \"/kaggle/input/wikipedia-202308-chunks-256tk-sqlite/wikipedia_chunks_256.db\"\n",
    "    elif CHUNK_SIZE == 64:\n",
    "        chunk_database_path = \"/kaggle/input/wikipedia-202308-64tk/wikipedia_chunks_64.db\"\n",
    "else:\n",
    "    data_dir = \"/mystuff/science-exam\"\n",
    "    index_dir = \"..\"\n",
    "    embedding_dir = \"/mystuff/llm/bge-small-en\"\n",
    "    llm_dir = \"/mystuff/llm/flan-t5-xl\"\n",
    "#    llm_dir = \"/mystuff/llm/flan-ul2\"\n",
    "    chunk_database_path = f\"../wikipedia_chunks_{CHUNK_SIZE}.db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:01.165602743Z",
     "start_time": "2023-09-19T19:48:01.119850081Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{data_dir}/train.csv')\n",
    "df_test  = pd.read_csv(f'{data_dir}/test.csv')\n",
    "df_samp = pd.read_csv(f'{data_dir}/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:01.348994796Z",
     "start_time": "2023-09-19T19:48:01.320170995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM memory % used: 9.8\n",
      "RAM Used (GB): 11.997659136\n"
     ]
    }
   ],
   "source": [
    "print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:01.548618197Z",
     "start_time": "2023-09-19T19:48:01.503967224Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# for testing the processing limits on a test set of size 4k\n",
    "\n",
    "#df_test_orig = df_test.copy()\n",
    "#df_test = pd.concat([df_test, df_test], ignore_index=True) #400\n",
    "#df_test = pd.concat([df_test, df_test], ignore_index=True) #800\n",
    "#df_test = pd.concat([df_test, df_test], ignore_index=True) #1600\n",
    "#df_test = pd.concat([df_test, df_test], ignore_index=True) #3200\n",
    "#df_test = pd.concat([df_test, df_test_orig], ignore_index=True) #3400\n",
    "#df_test = pd.concat([df_test, df_test_orig], ignore_index=True) #3600\n",
    "#df_test = pd.concat([df_test, df_test_orig], ignore_index=True) #3800\n",
    "#df_test = pd.concat([df_test, df_test_orig], ignore_index=True) #4000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:01.749425922Z",
     "start_time": "2023-09-19T19:48:01.728343504Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:01.995766181Z",
     "start_time": "2023-09-19T19:48:01.970496072Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_answer_options(df, idx, options = ['A','B','C','D','E']):\n",
    "    prompt = df.loc[idx, 'prompt']\n",
    "    answers = df.loc[idx,options].tolist()\n",
    "    correct_answer = None\n",
    "    if \"answer\" in df.columns:\n",
    "        correct_answer = df.loc[idx, 'answer']\n",
    "    \n",
    "    return prompt, answers, correct_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the FAISS database into memory in a separate process, queries all prompt/answer pairs for nearest document ids.\n",
    "Those doc ids can be later used to load the actual docs and their chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:03.510917779Z",
     "start_time": "2023-09-19T19:48:02.205321950Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import faiss\n",
    "import numpy as np\n",
    "from faiss import write_index, read_index\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "def load_and_search_faiss(queue, df):\n",
    "    try:\n",
    "        start = time.time()\n",
    "\n",
    "        print(\"loading index\")\n",
    "        sentence_index = read_index(f\"{index_dir}/faiss_index_512_flat_small.index\", faiss.IO_FLAG_MMAP)\n",
    "        print(\"index loaded\")\n",
    "\n",
    "        print(\"loading embedding model\")\n",
    "        embedding_model_path = embedding_dir\n",
    "        embedding_model = SentenceTransformer(embedding_model_path, device=DEVICE)\n",
    "        print(\"model loaded\")\n",
    "\n",
    "        # collect full text for all prompt + answers in the df\n",
    "        full_texts = []\n",
    "        for idx in tqdm(range(df.shape[0])):\n",
    "            prompt, answers, correct_answer = collect_answer_options(df, idx)\n",
    "            full_text = prompt + \"\\n\".join(answers)\n",
    "            full_texts.append(full_text)\n",
    "\n",
    "        print(\"encoding\")\n",
    "        q_embeddings = embedding_model.encode(full_texts)\n",
    "        print(\"finished encoding\")\n",
    "\n",
    "        k = 6\n",
    "        print(\"searching index\")\n",
    "        D, I = sentence_index.search(q_embeddings, k)\n",
    "        print(\"search done\")\n",
    "        faiss_scores = D\n",
    "        faiss_doc_ids = I\n",
    "\n",
    "        # Put the results in the queue to send back to main process\n",
    "        print(\"putting results in queue\")\n",
    "        queue.put((faiss_scores, faiss_doc_ids))\n",
    "        end = time.time()\n",
    "        diff = end - start\n",
    "        print(f\"returning: {diff}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the subprocess: {e}\")\n",
    "        traceback.print_exc()\n",
    "        queue.put(None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:03.513075548Z",
     "start_time": "2023-09-19T19:48:03.497334992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "2   2  Which of the following statements accurately d...   \n",
       "3   3  What is the significance of regularization in ...   \n",
       "4   4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E answer  \n",
       "0  MOND is a theory that eliminates the observed ...      D  \n",
       "1  Dynamic scaling refers to the evolution of sel...      A  \n",
       "2  The triskeles symbol is a representation of th...      A  \n",
       "3  Regularizing the mass-energy of an electron wi...      C  \n",
       "4  The angular spacing of features in the diffrac...      D  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:03.513982709Z",
     "start_time": "2023-09-19T19:48:03.497720591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "2   2  Which of the following statements accurately d...   \n",
       "3   3  What is the significance of regularization in ...   \n",
       "4   4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E  \n",
       "0  MOND is a theory that eliminates the observed ...  \n",
       "1  Dynamic scaling refers to the evolution of sel...  \n",
       "2  The triskeles symbol is a representation of th...  \n",
       "3  Regularizing the mass-energy of an electron wi...  \n",
       "4  The angular spacing of features in the diffrac...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:03.514202353Z",
     "start_time": "2023-09-19T19:48:03.498389250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate Train + Test DataFrames for more efficient processing\n",
    "df_full = pd.concat([df_train, df_test]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, FAISS search is done in a separate process. This allows freeing memory as otherwise FAISS mem use seems very hard to control and free the memory after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:16.812050145Z",
     "start_time": "2023-09-19T19:48:03.737618697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading index\n",
      "getting value\n",
      "index loaded\n",
      "loading embedding model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4a147fe0864ca09feaa8053adb142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding\n",
      "finished encoding\n",
      "searching index\n",
      "search done\n",
      "putting results in queue\n",
      "returning: 8.586722373962402\n",
      "Best match document indices: 400\n",
      "join started\n",
      "join done\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "\n",
    "p = Process(target=load_and_search_faiss, args=(q,df_full))\n",
    "p.start()\n",
    "print(\"getting value\")\n",
    "#the get should block \n",
    "faiss_scores_full, faiss_doc_ids_full = q.get()\n",
    "print(\"Best match document indices:\", len(faiss_doc_ids_full))\n",
    "#but better to sleep and join anyway\n",
    "time.sleep(5)\n",
    "print(\"join started\")\n",
    "p.join()\n",
    "print(\"join done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:16.813268294Z",
     "start_time": "2023-09-19T19:48:16.810293164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the result list back to train and test since both were processed together\n",
    "split_index = len(df_train)\n",
    "faiss_scores_train = faiss_scores_full[:split_index]\n",
    "faiss_scores_test = faiss_scores_full[split_index:]\n",
    "faiss_doc_ids_train = faiss_doc_ids_full[:split_index]\n",
    "faiss_doc_ids_test = faiss_doc_ids_full[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:16.813523238Z",
     "start_time": "2023-09-19T19:48:16.810411748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM memory % used: 10.0\n",
      "RAM Used (GB): 12.198162432\n"
     ]
    }
   ],
   "source": [
    "print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:16.866672658Z",
     "start_time": "2023-09-19T19:48:16.811630442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings model to create embeddings for new document chunks as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:17.626640571Z",
     "start_time": "2023-09-19T19:48:16.811726951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedding_model_path = embedding_dir\n",
    "\n",
    "embedding_model = SentenceTransformer(embedding_model_path, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:17.630620346Z",
     "start_time": "2023-09-19T19:48:17.627050466Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:17.630711004Z",
     "start_time": "2023-09-19T19:48:17.627114247Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from transformers.generation import GenerationConfig\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:17.630798931Z",
     "start_time": "2023-09-19T19:48:17.627183447Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = llm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:17.630882017Z",
     "start_time": "2023-09-19T19:48:17.627241545Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(llm, local_files_only=True)\n",
    "#some of the talk on T5 model max length give these types instructions to try. I don't think it has a difference but why not:\n",
    "tokenizer.model_max_length=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mystuff/llm/flan-t5-xl'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.142638470Z",
     "start_time": "2023-09-19T19:48:17.627918673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4347a7ff222467ca75298bfaae5e9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm, device_map=DEVICE, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP calculation. Taken from some random Kaggle notebook, I seem to have forgot which one. Sorry about that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.148800169Z",
     "start_time": "2023-09-19T19:48:22.144648042Z"
    }
   },
   "outputs": [],
   "source": [
    "# MAP3 \n",
    "\n",
    "def calculate_MAP3(predictions, labels):\n",
    "    U = len(predictions)  # Number of questions in the test set\n",
    "    MAP3 = 0.0  # Mean Average Precision @ 3\n",
    "\n",
    "    for i in range(U):\n",
    "        n = len(predictions[i])  # Number of predictions per question\n",
    "        relevant_labels = set(labels[i])  # Correct labels for the current question\n",
    "        \n",
    "        precision_sum = 0.0\n",
    "        precision_at_k = 0.0\n",
    "        relevant_count = 0\n",
    "\n",
    "        for k in range(n):\n",
    "            if predictions[i][k] in relevant_labels:\n",
    "                relevant_count += 1\n",
    "                precision_at_k = relevant_count / (k + 1)\n",
    "                precision_sum += precision_at_k\n",
    "                relevant_labels.remove(predictions[i][k])\n",
    "\n",
    "            if relevant_count >= 3:\n",
    "                break\n",
    "\n",
    "        average_precision = precision_sum / min(len(labels[i]), 3)\n",
    "        MAP3 += average_precision\n",
    "    \n",
    "    MAP3 /= U\n",
    "    print(\"MAP@3 score:\", MAP3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load document with the given ID from the SQLite database.\n",
    "Includes all the document chunks in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.193780610Z",
     "start_time": "2023-09-19T19:48:22.148160287Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def fetch_document_and_chunks_by_id(database_path, document_id):\n",
    "    # Establish the database connection\n",
    "    connection = sqlite3.connect(database_path)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare and execute the SQL query\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        d.document_id, d.document_title,\n",
    "        s.section_id, s.section_title,\n",
    "        tc.chunk_id, tc.content\n",
    "    FROM documents d\n",
    "    LEFT JOIN sections s ON s.document_id = d.document_id\n",
    "    LEFT JOIN text_chunks tc ON tc.document_id = d.document_id AND tc.section_id = s.section_id\n",
    "    WHERE d.document_id = ?\n",
    "    ORDER BY d.document_id, s.section_id, tc.chunk_id;\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (document_id,))\n",
    "\n",
    "    # Initialize an empty dictionary to hold the document and its chunks\n",
    "    # TODO: throw some error if this is not right\n",
    "    document = {\n",
    "        'id': document_id,\n",
    "        'sections': {}\n",
    "    }\n",
    "\n",
    "    # Fetch and process the result\n",
    "    for row in cursor:\n",
    "        #print(row)\n",
    "        _, document_title, section_id, section_title, chunk_id, content = row\n",
    "\n",
    "        # Set the document title\n",
    "        document['title'] = document_title\n",
    "\n",
    "        # Add section if not already present\n",
    "        if section_id and section_id not in document['sections']:\n",
    "            document['sections'][section_id] = {\n",
    "                'title': section_title,\n",
    "                'chunks': {}\n",
    "            }\n",
    "\n",
    "        # Add chunk\n",
    "        if chunk_id:\n",
    "            document['sections'][section_id]['chunks'][chunk_id] = content\n",
    "\n",
    "    # Close the database connection\n",
    "    connection.close()\n",
    "\n",
    "    return document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a Wikipedia page with given ID, print it if asked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.194111224Z",
     "start_time": "2023-09-19T19:48:22.155649745Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_print_doc_by_id(document_id_to_query, print_all=False):\n",
    "#    document_id_to_query = 1880580 # Replace with the document ID you're interested in\n",
    "    document = fetch_document_and_chunks_by_id(chunk_database_path, document_id_to_query)\n",
    "    #print(document)\n",
    "    \n",
    "    # Print the document and its chunks\n",
    "    all_chunks = []\n",
    "    #print(f\"Document ID: {document['id']}, Title: {document['title']}\")\n",
    "    for sec_id, sec_data in document['sections'].items():\n",
    "        #print(f\"  Section ID: {sec_id}, Title: {sec_data['title']}\")\n",
    "        for chunk_id, content in sec_data['chunks'].items():\n",
    "            if print_all:\n",
    "                print(f\"    Chunk ID: {chunk_id}, Content: {content[:50]}...\")  # Printing first 50 characters of each chunk\n",
    "            all_chunks.append(content)\n",
    "    return document, all_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load given set of documents (Wikipedia pages) and return chunks for all of them as separate lists and as a single big list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.194287162Z",
     "start_time": "2023-09-19T19:48:22.159757021Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_doc_chunks(doc_ids, print_all=True):\n",
    "    docs = []\n",
    "    doc_chunks = []\n",
    "    doc_chunks_flat = []\n",
    "    for doc_id in doc_ids:\n",
    "        doc, chunks = load_and_print_doc_by_id(int(doc_id+1), print_all)\n",
    "        docs.append(doc)\n",
    "        doc_chunks.append(chunks)\n",
    "        doc_chunks_flat.extend(chunks)\n",
    "    return doc_chunks, doc_chunks_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_top_n_rag finds indices of top N largest values in the given np_array, and sorts them from largest to smallest.\n",
    "That is, in case of this notebook it is used to find the indices of documents with highest similarity to given prompt + answer options.\n",
    "\n",
    "If the code seems strange, I recommend copy-pasting it to ChatGPT with prompt \"what does this code do:\" or something similar :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.212799691Z",
     "start_time": "2023-09-19T19:48:22.162801555Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_top_n_rag(np_array, n):\n",
    "    ind = np.argpartition(np_array, -n)[-n:]\n",
    "    top_n = np_array[ind]\n",
    "    sorted_ind = ind[np.argsort(np_array[ind])]\n",
    "    return sorted_ind[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_bottom_n_rag(np_array, n):\n",
    "    ind = np.argpartition(np_array, n)[:n]  # Find indices of smallest n elements\n",
    "    sorted_ind = ind[np.argsort(np_array[ind])]  # Sort these indices\n",
    "    return sorted_ind  # Return sorted indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:22.747865403Z",
     "start_time": "2023-09-19T19:48:22.166291364Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef16e7b370c4932a748f7977e171d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding\n"
     ]
    }
   ],
   "source": [
    "q_full_promps = []\n",
    "# iterate all of df_train\n",
    "for idx in tqdm(range(df_train.shape[0])):\n",
    "    prompt, answers, correct_answer = collect_answer_options(df_train, idx)\n",
    "    full_text = prompt + \"\\n\".join(answers)\n",
    "    q_full_promps.append(full_text)\n",
    "\n",
    "print(\"encoding\")\n",
    "train_q_embeddings = embedding_model.encode(q_full_promps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:23.044757524Z",
     "start_time": "2023-09-19T19:48:22.747622727Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5a1f90f9ea4ab1a0e9bb31681395e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_full_promps = []\n",
    "# iterate all of df_test\n",
    "for idx in tqdm(range(df_test.shape[0])):\n",
    "    prompt, answers, correct_answer = collect_answer_options(df_test, idx)\n",
    "    full_text = prompt + \"\\n\".join(answers)\n",
    "    q_full_promps.append(full_text)\n",
    "\n",
    "test_q_embeddings = embedding_model.encode(q_full_promps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:23.051989708Z",
     "start_time": "2023-09-19T19:48:23.048255376Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# df = the dataframe to build contexts for, df_train or df_test in practice\n",
    "# faiss_doc_ids = top documents by embeddings similarity for each query prompt + answer pairs\n",
    "# for example, df_train[0] has a prompt and 5 answer options. faiss_doc_ids[0] has the set of most similar docs to these df_train[0] texts\n",
    "# q_embeddings the query embeddings for the dataframe rows, to allow for effective chunk selection from the doc chunks\n",
    "def build_contexts(df, faiss_doc_ids, q_embeddings):\n",
    "    contexts = []\n",
    "    doc_chunks_all = []\n",
    "\n",
    "    print(\"loading chunks\")\n",
    "    for idx in tqdm(range(df.shape[0])):\n",
    "        doc_ids = faiss_doc_ids[idx]\n",
    "        doc_chunks, doc_chunks_flat = get_doc_chunks(doc_ids, False)\n",
    "        # doc_chunks_all should then contain list of sublists where each doc has its chunks in a separate list\n",
    "        doc_chunks_all.append(doc_chunks_flat)\n",
    "        \n",
    "    print(\"flattening chunks\")\n",
    "    # flattening all chunks into a single list allows batch processing them more efficiently\n",
    "    flat_chunks_all = [item for sublist in doc_chunks_all for item in sublist]\n",
    "    print(\"embedding chunks\")\n",
    "    # due to flattened list, we can not encode all chunks at once in batches by encoding model\n",
    "    chunk_embeddings = embedding_model.encode(flat_chunks_all)\n",
    "    \n",
    "    embeddings_list_of_lists = []\n",
    "    start_idx = 0\n",
    "    print(\"splitting embeddings back\")\n",
    "    for sublist in doc_chunks_all:\n",
    "        # splitting embeddings from model back into sublists per doc/chunks\n",
    "        end_idx = start_idx + len(sublist)\n",
    "        embeddings_list_of_lists.append(chunk_embeddings[start_idx:end_idx])\n",
    "        start_idx = end_idx\n",
    "\n",
    "    print(\"finding top n for all prompts, building contexts\")\n",
    "    sim_scores_all = []\n",
    "    # for each prompt / answer pairs, find best matching doc chunks to use as RAG QA context\n",
    "    for idx in tqdm(range(df.shape[0])):\n",
    "        # q_embeddings[idx] is the embeddings for prompt + answers together as a question\n",
    "        # embeddings_list_of_lists is the embeddings for the chunks for closest docs\n",
    "        sim_scores = util.cos_sim(q_embeddings[idx], embeddings_list_of_lists[idx])\n",
    "        sim_scores_all.append(sim_scores)\n",
    "        search_n = CHUNKS_TO_LOAD\n",
    "        if len(sim_scores[0]) < search_n:\n",
    "            #some documents may not have enough chunks, so have to cap it if that is the case\n",
    "            search_n = len(sim_scores[0])\n",
    "        #find the ones that have highest similarity scores by embedding\n",
    "        top_n = find_top_n_rag(np.array(sim_scores)[0], search_n)\n",
    "\n",
    "        total_tokens = 0\n",
    "        total_tokens_prev = 0\n",
    "        context = \"\"\n",
    "        count = 0\n",
    "        #top_n should now be indices into the chunk list\n",
    "        for n in top_n:\n",
    "            chunk = doc_chunks_all[idx][n]\n",
    "            token_ids = tokenizer(chunk)[\"input_ids\"]\n",
    "            token_count = len(token_ids)\n",
    "            total_tokens_prev = total_tokens\n",
    "            total_tokens += token_count\n",
    "            if total_tokens > MAX_CONTEXT_RAG:\n",
    "                break\n",
    "            count += 1\n",
    "            context += \"\\n\"+chunk\n",
    "        # print(f\"{count}: {total_tokens_prev}\")\n",
    "        \n",
    "        contexts.append(context)\n",
    "    return contexts, doc_chunks_all, embeddings_list_of_lists, sim_scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:48:52.752309047Z",
     "start_time": "2023-09-19T19:48:23.051870657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a008d0668e44ad48e714c4288ba91c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening chunks\n",
      "embedding chunks\n",
      "splitting embeddings back\n",
      "finding top n for all prompts, building contexts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be522d79a5ea4614af71746327b024a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexts_train, train_chunks_1, train_emb_lists, train_sim_scores_1 = build_contexts(df_train, faiss_doc_ids_train, train_q_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:49:22.557120297Z",
     "start_time": "2023-09-19T19:48:52.752095354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading chunks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eaf861097d47f4bed7b91f4511bf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattening chunks\n",
      "embedding chunks\n",
      "splitting embeddings back\n",
      "finding top n for all prompts, building contexts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a59829492e24ddb808475e89182105a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexts_test, test_chunks_1, test_emb_lists, test_sim_scores_1 = build_contexts(df_test, faiss_doc_ids_test, test_q_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:49:22.557470465Z",
     "start_time": "2023-09-19T19:49:22.532409482Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:49:22.557616178Z",
     "start_time": "2023-09-19T19:49:22.536114199Z"
    }
   },
   "outputs": [],
   "source": [
    "#this creates the actual LLM input, also known as prompt or prompt with context\n",
    "def format_input_rag(df, idx, faiss_doc_ids, contexts, options = ['A','B','C','D','E']):\n",
    "    preamble = \"Answer the following multiple-choice question about wikipedia content with the correct answer. \"\\\n",
    "               \"Use the provided context to assist in the answer if useful. \"\\\n",
    "               \"Answer only with the letter of the choice.\"\n",
    "    postamble = \"\"\n",
    "\n",
    "    prompt = df.loc[idx, 'prompt']\n",
    "    context = contexts[idx]\n",
    "        \n",
    "    answers = df.loc[idx,options].tolist()\n",
    "    correct_answer = None\n",
    "    if \"answer\" in df.columns:\n",
    "        correct_answer = df.loc[idx, 'answer']\n",
    "\n",
    "    options_text = \"\"\n",
    "    for option, answer in zip(options, answers):\n",
    "        options_text += (f\"{option}) {answer}\\n\")\n",
    "    \n",
    "    input_text = f\"{preamble}\\n\\nQuestion:\\n{prompt}\\n\\nContext:\\n{context}\\nOptions:\\n{options_text}\\n{postamble}\"\n",
    "    return input_text, correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:49:22.557815343Z",
     "start_time": "2023-09-19T19:49:22.539037642Z"
    }
   },
   "outputs": [],
   "source": [
    "#this loops the prediction by asking the model to choose one of the options, removes the selected, and repeats 3 times to get top 3\n",
    "#if no selection, the choice is skipped (kaggle competition allowed max 3 choices per question but not required)\n",
    "def predict_choices_rag(tokenizer, model, df, faiss_doc_ids, contexts):\n",
    "    result = []\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        j = 1\n",
    "        ans = []\n",
    "        options = ['A', 'B', 'C', 'D', 'E']\n",
    "        while j<=3:\n",
    "            input_text, correct_answer = format_input_rag(df,i,faiss_doc_ids, contexts, options)\n",
    "            model_inputs = tokenizer(input_text, return_tensors='pt').to(DEVICE)\n",
    "            greedy_output = model.generate(**model_inputs, max_new_tokens=40)\n",
    "            response = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "\n",
    "            # sometimes the model does not answer with a letter..\n",
    "            # print(f\"{j}:{response}\")\n",
    "            if len(response) == 0:\n",
    "                print(\"empty response, skipping\")\n",
    "                j+=1\n",
    "                continue\n",
    "            opt = response[0] if response[0] in 'ABCDE' else 'C' # Choose C if cannot infer the answer;)\n",
    "            ans.append(opt)\n",
    "            try:\n",
    "                options.remove(opt)\n",
    "            except:\n",
    "                options = ['A', 'B', 'C', 'D', 'E']\n",
    "            j+=1\n",
    "        result.append(ans)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:55:11.947187578Z",
     "start_time": "2023-09-19T19:49:22.549846351Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4f92251284475aa697b5cd2a774a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3091 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "labels = [[x] for x in df_train['answer']]\n",
    "predictions_train = predict_choices_rag(tokenizer, model, df_train, faiss_doc_ids_train, contexts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T19:55:11.947841233Z",
     "start_time": "2023-09-19T19:55:11.946973293Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@3 score: 0.8725\n"
     ]
    }
   ],
   "source": [
    "calculate_MAP3(predictions_train, df_train[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.496586536Z",
     "start_time": "2023-09-19T19:55:11.947354627Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eead7c9e574a02ab8e63bcc25e519d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = predict_choices_rag(tokenizer, model, df_test, faiss_doc_ids_test, contexts_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.498920356Z",
     "start_time": "2023-09-19T20:01:03.495640812Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>A B C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id prediction\n",
       "0      0      A B C\n",
       "1      1      A B C\n",
       "2      2      A B C\n",
       "3      3      A B C\n",
       "4      4      A B C\n",
       "..   ...        ...\n",
       "195  195      A B C\n",
       "196  196      A B C\n",
       "197  197      A B C\n",
       "198  198      A B C\n",
       "199  199      A B C\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = df_samp\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.543219290Z",
     "start_time": "2023-09-19T20:01:03.496331074Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D E A', 'A B C', 'B A D', 'A C D', 'D B A']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_submissions = [\" \".join(x) for x in predictions_test]\n",
    "str_submissions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.544713387Z",
     "start_time": "2023-09-19T20:01:03.496923489Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@3 score: 0.8725\n"
     ]
    }
   ],
   "source": [
    "if df_train.shape[0] == df_test.shape[0]:\n",
    "    calculate_MAP3(predictions_test, df_train[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are some of the scores per combinations of different parameters.\n",
    "#mainly chunk size and max tokens to put in context, and the resulting MAP3 score\n",
    "# 512/3000: 0.84\n",
    "# 512/2000: 0.864\n",
    "# 512/1000: 0.836\n",
    "# 512/500:  0.743\n",
    "# 384/3000: 0.858\n",
    "# 384/2000: 0.848\n",
    "# 384/1000: 0.86\n",
    "# 384/500:  0.789\n",
    "# 256/3000: 0.8725, 0.8675\n",
    "# 256/2000: 0.852\n",
    "# 256/1000: 0.8425\n",
    "# 256/500:  0.8575\n",
    "# 192/3000: 0.868\n",
    "# 192/2000: 0.856\n",
    "# 192/1000: 0.8575\n",
    "# 192/500:  0.8233\n",
    "# 128/3000: 0.8525\n",
    "# 128/2000: 0.8466\n",
    "# 128/1000: 0.0.865\n",
    "# 128/500:  0.8425\n",
    "#  64/3000: 0.850\n",
    "#  64/2000: 0.863\n",
    "#  64/1000: 0.8625\n",
    "#  64/500:  0.8275\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.544860907Z",
     "start_time": "2023-09-19T20:01:03.497722793Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_submission[\"prediction\"] = str_submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.544944890Z",
     "start_time": "2023-09-19T20:01:03.498139702Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T20:01:03.802111703Z",
     "start_time": "2023-09-19T20:01:03.498544221Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,prediction\n",
      "0,D E A\n",
      "1,A B C\n",
      "2,B A D\n",
      "3,A C D\n",
      "4,D B A\n",
      "5,C B E\n",
      "6,A D B\n",
      "7,D B E\n",
      "8,C B C\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
