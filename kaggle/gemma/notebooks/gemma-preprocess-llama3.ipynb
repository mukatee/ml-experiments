{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma Summarizes Kaggle Competition Writeups\n",
    "\n",
    "How can we use Gemma to summarize Kaggle competition writeups, or can we? Well, lets see.\n",
    "\n",
    "This notebook is to trial Gemmas summarization skills on Kaggle competition writeups.\n",
    "\n",
    "- v1: first trials with summarization\n",
    "- v2: attempt at parsing the writeup placement for prioritization basis\n",
    "- v3: trying to summarize each writeup first, and from those all writeups per competition\n",
    "- v4: tuning prompt for better summary of key points, exploring Gemma's ability for overall summarization of multiple writeups across the competition, adding my own summary on Gemma learnings\n",
    "- v5: optimized by clipping context to 4k on Kaggle to avoid GPU OOM. runs on P100 now much faster than 2xT4\n",
    "- v6: after trialing these summaries as inputs with [a RAG notebook](https://www.kaggle.com/code/donkeys/qa-solutions-from-past-competitions), now added section on summarizing large writeup sets per competition in parts and learnings from that\n",
    "- v7: analysis of larger set of writeups and summaries for different subset sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary of (my) Gemma Learning\n",
    "\n",
    "- Gemma is a bit talkative, at least the instruction tuned version. It seems to wish to tell me more than I asked for.\n",
    "- Gemma does a decent job figuring out what position the solution described in a writeup finished in, if that information is in the writeup or its title. But can also miss it even if it is straight in the title.\n",
    "- Due to talkative nature and unreliable position identification it is a bit difficult to use for sorting the writeups by their competition scores\n",
    "- Gemma does not seem very good at distinguishing different parts of a longer prompt, such as competition description vs the solution writeup. It seems to mix potential approaches from the descriptions in the writeup.\n",
    "- With little information (e.g., almost empty writeups), summaries seem to hallucinate the competition description into the writeup summary. With large number of writeups, Gemma sticks to the \"facts\" much better.\n",
    "- When asked for a summary of key points, Gemma seems to want to always write its own extra opinion piece in the end about the summary.\n",
    "- Asking simply for a list of key points without \"summary\" works better to avoid this opinion piece. Perhaps it is something to do with its training in relation to summarization.\n",
    "- Gemma seems to produce summaries in the range of 200-300 tokens, regardless of the input context size. Again, perhaps something about how it has been trained?\n",
    "- When a good prompt format and approach is found, Gemma seems to give quite good summaries. Probably quite common for models this size.\n",
    "- When summarizing multiple parts, such as partial summaries of large writeup sets, subsections are needed or Gemma seems to lose it.\n",
    "- When re-summarizing larger numbers of subsets, Gemma seems to more easily lose it. Some ways to mitigate that should be considered if using such hierarchical summarization approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#have to update these first, or otherwise it seems the libraries might not update and load older versions\n",
    "!pip install -q -U transformers accelerate bitsandbytes lxml\n",
    "#flash attention does not work on Kaggle GPU's, too old\n",
    "#!pip install flash-attn --no-build-isolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "on_kaggle = False\n",
    "if os.path.exists(\"/kaggle/input\"):\n",
    "    on_kaggle = True\n",
    "\n",
    "if on_kaggle:\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 26 05:11:05 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:2D:00.0 Off |                  N/A |\n",
      "|  0%   45C    P8              21W / 370W |     22MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Gemma Model and Try it with Poetry Prompt\n",
    "\n",
    "The poetry prompt is actually taken from the [Huggingface Gemma page](https://huggingface.co/google/gemma-7b-it).\n",
    "\n",
    "I use it here just as a smoke test to see the code and model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: auto\n",
      "CUDA Version: 12.1\n",
      "Pytorch 2.2.0\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/minhsienweng/create-ai-generated-essays-gemma/notebook\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = \"auto\"\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"Pytorch {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: /mystuff/llm/Meta-Llama-3-8B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ed119e41844656b0658192f00735d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "if on_kaggle:\n",
    "    model_path = \"/kaggle/input/gemma/transformers/7b-it/1\"\n",
    "else:\n",
    "    model_path = \"/mystuff/llm/Meta-Llama-3-8B-Instruct\"\n",
    "#    model_path = \"/mystuff/llm/gemma-7b\"\n",
    "    \n",
    "print(f\"Model path: {model_path}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "g_model = AutoModelForCausalLM.from_pretrained(model_path, \n",
    "                                               device_map=DEVICE, \n",
    "                                               quantization_config=quantization_config,\n",
    "                                               #attn_implementation=\"flash_attention_2\",\n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So next to try the prompt from HF model page as the base smoke test on model working:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There you go. An interesting poem :) So the model now works, also on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Write me a poem about Machine Learning.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In silicon halls, where data reigns\n",
      "A new kind of wisdom, algorithms sustain\n",
      "Machine Learning's art, a wondrous game\n",
      "Where patterns hide, and secrets are claimed\n",
      "\n",
      "With each new input, a tale unfolds\n",
      "A story woven, of ones and zeroes told\n",
      "The machine learns, as data flows free\n",
      "A symphony of bits, a harmony to see\n",
      "\n",
      "In neural networks, nodes entwine\n",
      "A web of connections, a mind divine\n",
      "The algorithm whispers, \"I shall know\"\n",
      "As hidden truths, begin to glow\n",
      "\n",
      "Through backpropagation's gentle hand\n",
      "The machine refines, its understanding grand\n",
      "The errors dwindle, the accuracy grows\n",
      "As the model learns, the data it knows\n",
      "\n",
      "In reinforcement learning's realm of might\n",
      "The machine explores, through trial and night\n",
      "The rewards and penalties, a delicate dance\n",
      "As the agent learns, to take a chance\n",
      "\n",
      "In deep learning's labyrinthine depths\n",
      "The machine uncovers, hidden patterns' stealth\n",
      "The convolutional layers, a visual quest\n",
      "As images and sounds, are analyzed best\n",
      "\n",
      "In natural language processing's domain\n",
      "The machine converses, with human brain\n",
      "The words and meanings, a linguistic dance\n",
      "As the model learns, to understand the chance\n",
      "\n",
      "Machine Learning's art, a wondrous thing\n",
      "A fusion of math, and human ingenuity's ring\n",
      "A bridge between, the digital and the real\n",
      "Where data meets wisdom, and the future's revealed.<|eot_id|>\n",
      "CPU times: user 12.4 s, sys: 21 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "prompt = \"Write me a poem about Machine Learning.\"\n",
    "\n",
    "chat = [{'content': prompt, 'role': 'user'}]\n",
    "chat_tokens = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(g_model.device)\n",
    "\n",
    "#input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = g_model.generate(chat_tokens, max_new_tokens=1000, eos_token_id=terminators, pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets\n",
    "\n",
    "I use data from a set of Kaggle competition writeups, and competition descriptions.\n",
    "\n",
    "In this notebook, I try out Gemma as a summarizer for those writeups. And the descriptions are there to help build a bit of context for the writeups and their summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if on_kaggle:\n",
    "    df_writeups = pd.read_csv(f\"/kaggle/input/2023-kaggle-ai-report/kaggle_writeups_20230510.csv\")\n",
    "    df_comp_meta = pd.read_csv(f\"/kaggle/input/kaggles-all-completed-competition-dataset/kaggle comp_submission.csv\")\n",
    "else:\n",
    "    df_writeups = pd.read_csv(f\"/mystuff/data/kaggle_writeups_20230510.csv\")\n",
    "    df_comp_meta = pd.read_csv(f\"/mystuff/data/kaggle_comp_submission.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the writeups have a lot of HTML in them, causing the Gemma model sometimes to overflow its context window, and lose the text in the HTML markup. This shows in the Writeup column here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competition Launch Date</th>\n",
       "      <th>Title of Competition</th>\n",
       "      <th>Competition URL</th>\n",
       "      <th>Date of Writeup</th>\n",
       "      <th>Title of Writeup</th>\n",
       "      <th>Writeup</th>\n",
       "      <th>Writeup URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/18/2010 00:06:46</td>\n",
       "      <td>Released: my Source Code and Analysis</td>\n",
       "      <td>&lt;p&gt;I had a lot of fun with this competition an...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/20/2010 04:38:53</td>\n",
       "      <td>6th place(UriB) by Uri Blass</td>\n",
       "      <td>&lt;P&gt;I calculated rating for every player in mon...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Competition Launch Date                              Title of Competition  \\\n",
       "0     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "1     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "\n",
       "                 Competition URL      Date of Writeup  \\\n",
       "0  https://www.kaggle.com/c/2447  11/18/2010 00:06:46   \n",
       "1  https://www.kaggle.com/c/2447  11/20/2010 04:38:53   \n",
       "\n",
       "                        Title of Writeup  \\\n",
       "0  Released: my Source Code and Analysis   \n",
       "1           6th place(UriB) by Uri Blass   \n",
       "\n",
       "                                             Writeup  \\\n",
       "0  <p>I had a lot of fun with this competition an...   \n",
       "1  <P>I calculated rating for every player in mon...   \n",
       "\n",
       "                                    Writeup URL  \n",
       "0  https://www.kaggle.com/c/2447/discussion/185  \n",
       "1  https://www.kaggle.com/c/2447/discussion/192  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_writeups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `strip_html()` will remove HTML formatting from a writeup and only leave the actual text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "\n",
    "def strip_html(html_text):\n",
    "    tree = html.fromstring(html_text)\n",
    "    clean_text = tree.text_content()\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 writeups with NAN values, dropping them allows processing the column at once, and removes invalid rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Initial set of writeups: (3127, 7)\n",
      "After removing rows with nan for writeup: (3125, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"                 Initial set of writeups: {df_writeups.shape}\")\n",
    "df_writeups = df_writeups.dropna(subset=['Writeup'])\n",
    "print(f\"After removing rows with nan for writeup: {df_writeups.shape}\")\n",
    "# this shows there were 2 rows with nan writeup, 3127->3125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I tried simply apply `strip_html()` directly to the `Writeup` column for all rows. However, this made printing any example writeups in the notebook harder to read. So I added the stripped writeup as its own column `writeup_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_writeups.loc[:, \"Writeup\"] = df_writeups[\"Writeup\"].apply(strip_html)\n",
    "df_writeups[\"writeup_clean\"] = df_writeups[\"Writeup\"].apply(strip_html)\n",
    "df_writeups = df_writeups.rename(columns={'Writeup': 'writeup'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df_comp_meta` dataset contains competition metadata such as competition description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>comp_Reward</th>\n",
       "      <th>comp_link</th>\n",
       "      <th>teams</th>\n",
       "      <th>competitors</th>\n",
       "      <th>Entries</th>\n",
       "      <th>Tag</th>\n",
       "      <th>desc</th>\n",
       "      <th>code_link</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_year</th>\n",
       "      <th>final_date</th>\n",
       "      <th>final_month</th>\n",
       "      <th>final_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tabular Playground Series - Sep 2022</td>\n",
       "      <td>Swag</td>\n",
       "      <td>https://www.kaggle.com/competitions/tabular-pl...</td>\n",
       "      <td>1381</td>\n",
       "      <td>1447</td>\n",
       "      <td>13085</td>\n",
       "      <td>tabular data</td>\n",
       "      <td>The competing Kaggle merchandise stores we saw...</td>\n",
       "      <td>https://www.kaggle.com/code/elem3ntary/tps-sep...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI Village Capture the Flag @ DEFCON</td>\n",
       "      <td>25000</td>\n",
       "      <td>https://www.kaggle.com/competitions/ai-village...</td>\n",
       "      <td>668</td>\n",
       "      <td>668</td>\n",
       "      <td>4235</td>\n",
       "      <td>games</td>\n",
       "      <td>Help Henry Hacker get to Homecoming during DEF...</td>\n",
       "      <td>https://www.kaggle.com/code/tatamikenn/defcon3...</td>\n",
       "      <td>12</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              comp_name comp_Reward  \\\n",
       "0  Tabular Playground Series - Sep 2022        Swag   \n",
       "1  AI Village Capture the Flag @ DEFCON       25000   \n",
       "\n",
       "                                           comp_link  teams  competitors  \\\n",
       "0  https://www.kaggle.com/competitions/tabular-pl...   1381         1447   \n",
       "1  https://www.kaggle.com/competitions/ai-village...    668          668   \n",
       "\n",
       "   Entries           Tag                                               desc  \\\n",
       "0    13085  tabular data  The competing Kaggle merchandise stores we saw...   \n",
       "1     4235         games  Help Henry Hacker get to Homecoming during DEF...   \n",
       "\n",
       "                                           code_link  start_date start_month  \\\n",
       "0  https://www.kaggle.com/code/elem3ntary/tps-sep...           1        Sep    \n",
       "1  https://www.kaggle.com/code/tatamikenn/defcon3...          12        Aug    \n",
       "\n",
       "   start_year  final_date final_month  final_year  \n",
       "0        2022           1        Oct         2022  \n",
       "1        2022          12        Sep         2022  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp_meta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data stats\n",
    "\n",
    "There appear to be 310 different competitions in the writeup data. There are more writeups (3125) than competitions because multiple participants did a writeup on single competitions from their own perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_writeups[\"Title of Competition\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first writeup in the dataset appears to be for a chess rating competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chess ratings - Elo versus the Rest of the World'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions = df_writeups[\"Title of Competition\"].unique()\n",
    "comp0 = competitions[0]\n",
    "comp0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This competition appears to have 5 writeups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chess competition dataframe shape: (5, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competition Launch Date</th>\n",
       "      <th>Title of Competition</th>\n",
       "      <th>Competition URL</th>\n",
       "      <th>Date of Writeup</th>\n",
       "      <th>Title of Writeup</th>\n",
       "      <th>writeup</th>\n",
       "      <th>Writeup URL</th>\n",
       "      <th>writeup_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/18/2010 00:06:46</td>\n",
       "      <td>Released: my Source Code and Analysis</td>\n",
       "      <td>&lt;p&gt;I had a lot of fun with this competition an...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/185</td>\n",
       "      <td>I had a lot of fun with this competition and l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/20/2010 04:38:53</td>\n",
       "      <td>6th place(UriB) by Uri Blass</td>\n",
       "      <td>&lt;P&gt;I calculated rating for every player in mon...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/192</td>\n",
       "      <td>I calculated rating for every player in months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/23/2010 10:38:23</td>\n",
       "      <td>7th place - littlefish</td>\n",
       "      <td>I'm a little surprised I ended up in the top-1...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/194</td>\n",
       "      <td>I'm a little surprised I ended up in the top-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/20/2010 11:27:17</td>\n",
       "      <td>3rd place: Chessmetrics - Variant</td>\n",
       "      <td>&lt;p&gt;&lt;span id=\"post_text_content_1230\"&gt;&lt;div dir=...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/193</td>\n",
       "      <td>Dear all,it was a great competition, thanks a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/03/2010 00:00:00</td>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>https://www.kaggle.com/c/2447</td>\n",
       "      <td>11/18/2010 02:44:10</td>\n",
       "      <td>2nd place: TrueSkill Through Time</td>\n",
       "      <td>Wow, this is a surprise! I looked at this comp...</td>\n",
       "      <td>https://www.kaggle.com/c/2447/discussion/186</td>\n",
       "      <td>Wow, this is a surprise! I looked at this comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Competition Launch Date                              Title of Competition  \\\n",
       "0     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "1     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "2     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "3     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "4     08/03/2010 00:00:00  Chess ratings - Elo versus the Rest of the World   \n",
       "\n",
       "                 Competition URL      Date of Writeup  \\\n",
       "0  https://www.kaggle.com/c/2447  11/18/2010 00:06:46   \n",
       "1  https://www.kaggle.com/c/2447  11/20/2010 04:38:53   \n",
       "2  https://www.kaggle.com/c/2447  11/23/2010 10:38:23   \n",
       "3  https://www.kaggle.com/c/2447  11/20/2010 11:27:17   \n",
       "4  https://www.kaggle.com/c/2447  11/18/2010 02:44:10   \n",
       "\n",
       "                        Title of Writeup  \\\n",
       "0  Released: my Source Code and Analysis   \n",
       "1           6th place(UriB) by Uri Blass   \n",
       "2                 7th place - littlefish   \n",
       "3      3rd place: Chessmetrics - Variant   \n",
       "4      2nd place: TrueSkill Through Time   \n",
       "\n",
       "                                             writeup  \\\n",
       "0  <p>I had a lot of fun with this competition an...   \n",
       "1  <P>I calculated rating for every player in mon...   \n",
       "2  I'm a little surprised I ended up in the top-1...   \n",
       "3  <p><span id=\"post_text_content_1230\"><div dir=...   \n",
       "4  Wow, this is a surprise! I looked at this comp...   \n",
       "\n",
       "                                    Writeup URL  \\\n",
       "0  https://www.kaggle.com/c/2447/discussion/185   \n",
       "1  https://www.kaggle.com/c/2447/discussion/192   \n",
       "2  https://www.kaggle.com/c/2447/discussion/194   \n",
       "3  https://www.kaggle.com/c/2447/discussion/193   \n",
       "4  https://www.kaggle.com/c/2447/discussion/186   \n",
       "\n",
       "                                       writeup_clean  \n",
       "0  I had a lot of fun with this competition and l...  \n",
       "1  I calculated rating for every player in months...  \n",
       "2  I'm a little surprised I ended up in the top-1...  \n",
       "3  Dear all,it was a great competition, thanks a ...  \n",
       "4  Wow, this is a surprise! I looked at this comp...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp0 = df_writeups[df_writeups[\"Title of Competition\"]==comp0]\n",
    "print(f\"Chess competition dataframe shape: {df_comp0.shape}\")\n",
    "df_comp0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Writeup\n",
    "\n",
    "What does a writeup look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<P>I calculated rating for every player in months 101-105 and after having the rating I have a simple formula to calculate the expected result only based on the rating and the color.<BR>The tricks that I used were mainly in calculating the rating but I will start explaining the simple part.<BR><BR>The first part was calculating the bonus for white<BR><BR>I had the following formula for this part:<BR>bonus=maximum((white_rating+black_rating-3100)/40.0,50)<BR><BR>Diff=white_rating+bonus-black_rating&nbsp; <BR><BR>Expected_result=0.5+Diff/850 <BR>When I changed it to be not more than <FONT size=2>0.970588 and not less than 0.1(practically it had a very small effect&nbsp;<BR>because&nbsp;the result was always bigger than 0.1 and there was only one case when I needed to reduce it to 0.970588)</P>\r\n",
       "<P></FONT><BR>Now we go to the hard part that is how to calculate the rating for every player.<BR>For this purpose I admit that I used the future to predict the past(but I have also prediction based on a different model in the top 10 when I did not use the future to predict the past).<BR><BR>I used a function that I called repeat_strength_estimate<BR>The function get the following parameters:<BR>1)k that is the last month that is not missing.<BR>For the prediction of months 101-105 k=100 but for testing my parameters I used k=90,91,92,...99<BR>2)max_months(practically get the value 81 and I admit that it is not a good name)<BR>The meaning of max_months=81 is practically that I&nbsp;do not use the first 20 months to predict month 101 and that I do not use the first 21 months to predict month 102 and generally <BR>I do not use the first&nbsp;m-81 months to predict month number m.<BR><BR>3)<FONT size=2>big_dif=310<BR>big_dif was used to calculate performance rating and for some reason I found that small values give better results<BR>in my tests so I used this small value<BR><BR><FONT size=2>My formula for performance rating was</P>\r\n",
       "<P>performance_rating=avg_rating+((result-opponents)/opponents)*big_dif;<BR><BR>the value of the division can be at most 1 and at least -1 because result is practically weighted half points and is something between 0 and twice the weight of the opponent.<BR><BR>opponents in this formula mean the number of weight opponents(when the weight is based on the distance in month from&nbsp;the month to predict)&nbsp;&nbsp;<BR>This formula means that even if a player lost all the games against the opponents then he still got performance rating that is only 310 elo weaker than the average of the opponents because the result of the division is always between -1 for losing all games and 1 for winning all games.<BR></FONT></FONT><BR>I guess that it was good because not all games are included so person who played against strong opponents probably performed practically better than his real score and it is not good for the real world when games are not missing.<BR><BR>4)num_avg=5.9 similiar to chess metrics(I added 5.9 faked opponents with average rating)<BR><BR>5)num_weak=2.2(added 2.2 faked weak opponents)<BR><BR>6)<FONT size=2>value_weak=2210(rating of the weak opponents like chess metrics<BR><BR>7)<FONT size=2>unrated=2285(I think that practically had no effect because players always&nbsp;have games in the last 80 months)</P></FONT>\r\n",
       "<P></FONT><BR>8)<FONT size=2>minimal_game_finished=15(I reduce rating to players with less than 15 weighted games similiar to chess metrics)<BR><BR>9)reduction_per_game=12(the number that I reduce for less of experience for player without many weight games)<BR><BR>10)adding=39(the number that I add to rating of players after every iteration)<BR><BR>repeat_strength_estimate basically did 10 iterations for evaluating the strength of every player in every month.<BR></FONT>The evaluation of&nbsp;the strengh was based on 2 steps when step 1 was the function that calculate strength that is similiar to chess metrics but there are important differences and step 2 was deciding that place 50 has rating 2625 in the rating list that is exactly the same as chess metrics.<BR><BR><FONT size=2></P>\r\n",
       "<P>calc_strength_chess_metric is the missing function to understand the algorithm and it basically got 11 parameters(all the 10 parameters that repeat_strength_estimate got and another parameter that is the month that we calculate&nbsp;estimate for it).<BR><BR>Note that&nbsp;the&nbsp;estimate for month 50 of player 1 when months 101-105 are missing is important because if player 2 played with player 1 at month 50 <BR>then it is going to influence the rating of player 2&nbsp; at month 101-105 that is used to calculate the expected result.<BR><BR>I use the word estimate and not rating because rating by definition assume that we do not have future results.<BR><BR>I had basically 2 steps in<BR>calc_strength_chess_metric<BR><BR>The first step was a loop that calculated the estimate for strength for every player in the relevant month.<BR>The second step is a&nbsp;step that I used only when I needed to predict the strength in the missing months and it is practically unfair trick but not something that is forbidden in the competition because I used the information about games and not about the results in the supposed missing months to&nbsp;calculate changes in the rating estimate in these months.<BR></FONT><BR>I did not finish to explain my algorithm&nbsp;and I plan also to send code later but now I need only to explain the 2 steps of calc_strength_chess_metric to explain my algorithm and I will do it later in another post(this part of the program is only slightly more than 100 lines of code in C).<BR></P>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeup0=df_comp0.iloc[1][\"writeup\"]\n",
    "Markdown(writeup0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1 - Ask Gemma for a useful summary for a Kaggle learner:\n",
    "\n",
    "Try with the first writeup collected above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1394"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"Summarize the following Kaggle competition writeup.\" \\\n",
    " f\"Make it useful for someone trying to learn and apply a similar \" \\\n",
    " f\"approach in a different competition: {writeup0}\"\n",
    "chat = [{'content': prompt, 'role': 'user'}]\n",
    "chat_tokens = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(g_model.device)\n",
    "\n",
    "input_token_count = chat_tokens[0].shape[-1]\n",
    "input_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = g_model.generate(chat_tokens, max_new_tokens=1000, eos_token_id=terminators, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "#outputs = g_model.generate(, max_new_tokens=1000, do_sample=False, eos_token_id=terminators, pad_token_id=tokenizer.pad_token_id)\n",
    "new_tokens = outputs[0][input_token_count:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writeup Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n"
     ]
    }
   ],
   "source": [
    "print(len(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394\n"
     ]
    }
   ],
   "source": [
    "print(input_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The writeup describes a Kaggle competition entry that uses a rating system to predict the outcome of chess games. The author calculates a rating for each player in months 101-105 and uses a formula to calculate the expected result based on the rating and the color (white or black). The rating calculation involves a complex formula that takes into account various parameters, including the player's past performance, the number of games played, and the strength of the opponents.\n",
       "\n",
       "The key components of the algorithm are:\n",
       "\n",
       "1. The `repeat_strength_estimate` function, which calculates the rating for each player in each month. This function takes into account the player's past performance, the number of games played, and the strength of the opponents.\n",
       "2. The `calc_strength_chess_metric` function, which is used to calculate the estimate of the player's strength in the missing months. This function uses a loop to calculate the estimate for each player in the relevant month, and then uses an unfair trick to adjust the estimate based on the information about games in the supposed missing months.\n",
       "\n",
       "The author's approach involves using a combination of machine learning and chess metrics to predict the outcome of the games. The algorithm is complex and involves many parameters, but the author claims that it was effective in predicting the outcome of the games.\n",
       "\n",
       "For someone trying to learn and apply a similar approach in a different competition, here are some key takeaways:\n",
       "\n",
       "1. Use a combination of machine learning and domain-specific metrics to predict the outcome of the games.\n",
       "2. Calculate a rating for each player based on their past performance and the strength of their opponents.\n",
       "3. Use a formula to calculate the expected result based on the rating and the color.\n",
       "4. Consider using an unfair trick to adjust the estimate based on the information about games in the supposed missing months.\n",
       "5. Be prepared to iterate on your algorithm and adjust the parameters to improve the performance.\n",
       "\n",
       "Note that the author's algorithm is complex and may not be easily applicable to other competitions. However, the general approach of using a combination of machine learning and domain-specific metrics to predict the outcome of games may be useful in other competitions.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(new_tokens))\n",
    "summary1 = tokenizer.decode(new_tokens, skip_special_tokens=False)\n",
    "Markdown(summary1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Add more context to Gemma input\n",
    "\n",
    "The summary above seems a bit hard to figure out, since it does not say what players or months it refers to. Maybe Gemma can improve the summary with a bit of knowledge about what kind of competition the writeup is for.\n",
    "\n",
    "So trying here with adding writeup title, competition name, and competition description to the prompt. Lets see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Released: my Source Code and Analysis'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeup0_title = df_comp0[\"Title of Writeup\"].iloc[0]\n",
    "writeup0_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chess ratings - Elo versus the Rest of the World'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp0_name = df_comp0[\"Title of Competition\"].iloc[0]\n",
    "comp0_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "When predicting the outcome of chess games, you typically need two things; a rating system wherein the current ability of each player is estimated based on past results, and a model for estimating the expected score for each player, once you know their ratings.Most rating systems use some methodology to determine initial \"seed\" ratings for the pool of players, and then update those ratings based on ongoing results.  The most famous approach is the Elo approach, where the applied change to a player's rating is proportional to the amount by which they exceed their aggregate expected score across all their recent games.  The scaling factor is known as the \"K-factor\", and for the official ratings used throughout the world, the K-factor is highest for new players and lowest for topmost players.  But there are many other approaches: the Ken Thompson approach takes each player's most recent 100 games and calculates the rating that would be most likely to lead to that performance.  The Mark Glickman approach is similar to Elo but introduces additional parameters for each player, tracking the level of confidence and level of volatility for each player's rating, and then using these parameters to determine which K-factor to apply.The initial seed ratings are typically determined through a simultaneous calculation: a start rating is assumed for each player, then a \"performance rating\" is calculated for each player based on their results and the ratings of their opponents, and then those performance ratings are fed back into another iteration as the start ratings.  This is allowed to run until it converges upon a stable set of ratings.  This was the methodology used to calculate initial ratings for most major rating systems.  In fact this is the overall approach taken by the Jeff Sonas Chessmetrics rating calculation, and is used not just to calculate initial ratings but in fact to calculate all ratings.There is a general convention in chess rating systems whereby the difference in two ratings is used for calculating expected score when two players face each other.  Of course it could just as well be the ratio of the two ratings, or some other more complex relationship that depends on the magnitude of the ratings and not just their relative difference.Here are some links to articles existing on rating systems:Elo and Ken ThompsonGlickoChessmetricsMicrosoft TrueSkillJeff Moser has a C# implementation of Elo and TrueSkill on Github. has posted a Java implementation of Glicko on Github."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp0_desc = df_comp_meta[df_comp_meta[\"comp_name\"] == comp0_name][\"desc\"].values[0]\n",
    "Markdown(comp0_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first a helper method to avoid copy-pasting the generation code all the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3_generate(prompt, debug=False):\n",
    "    # trying to remove <|eot_id|> just in case Llama3 thinks the sequence ends in the middle\n",
    "    prompt = prompt.replace(\"<|eot_id|>\", \"\\n\")\n",
    "    #print(prompt)\n",
    "    \n",
    "    chat = [{'content': prompt, 'role': 'user'}]\n",
    "    chat_tokens = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(g_model.device)\n",
    "        \n",
    "    input_token_count = chat_tokens[0].shape[-1]\n",
    "\n",
    "#    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "#    input_token_count = len(input_ids[\"input_ids\"][0])\n",
    "\n",
    "    outputs = g_model.generate(chat_tokens, max_new_tokens=1000, eos_token_id=terminators, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    new_tokens = outputs[0][input_token_count:]\n",
    "    output_token_count = len(new_tokens)\n",
    "    if debug:\n",
    "        print(f\"input tokens: {input_token_count}, output tokens: {output_token_count}\")\n",
    "    \n",
    "    output = tokenizer.decode(new_tokens, skip_special_tokens=False)\n",
    "    output_md = Markdown(output)\n",
    "    return output, output_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, try to generate a writeup summary from the competition description + a writeup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"given the following kaggle competition description and solution writeup, \" \\\n",
    "         f\"summarize the solution for someone interested in applying a similar solution in a different context:\\n\\n\" \\\n",
    "         f\"description: {comp0_desc}\\n\\n\" \\\n",
    "         f\"writeup: {writeup0_title}: {writeup0}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 144 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The solution involves calculating a rating system for chess players based on their past results. The rating system uses a combination of Elo and Glicko approaches to estimate the current ability of each player. The solution also involves calculating the expected score for each player based on their ratings.\n",
       "\n",
       "The key components of the solution are:\n",
       "\n",
       "1. Calculating the initial seed ratings for each player using a simultaneous calculation approach.\n",
       "2. Updating the ratings based on ongoing results using the Elo and Glicko approaches.\n",
       "3. Calculating the expected score for each player based on their ratings using the difference in their ratings.\n",
       "\n",
       "The solution also involves using a function called `repeat_strength_estimate` to calculate the rating for each player. This function takes several parameters, including the last month that is not missing, the maximum number of months to consider, and the big difference value.\n",
       "\n",
       "The solution also involves using a function called `calc_strength_chess_metric` to calculate the strength of each player in a given month. This function takes 11 parameters, including the month to consider, the last month that is not missing, and the big difference value.\n",
       "\n",
       "The solution is implemented in C and is based on the Elo and Glicko approaches. The solution also involves using a combination of linear and non-linear calculations to estimate the current ability of each player.\n",
       "\n",
       "To apply a similar solution in a different context, you would need to:\n",
       "\n",
       "1. Identify the relevant parameters and variables in the new context.\n",
       "2. Determine the initial seed ratings for each player or entity in the new context.\n",
       "3. Update the ratings based on ongoing results using a similar approach to Elo and Glicko.\n",
       "4. Calculate the expected score for each player or entity based on their ratings.\n",
       "5. Use a function similar to `repeat_strength_estimate` to calculate the rating for each player or entity.\n",
       "6. Use a function similar to `calc_strength_chess_metric` to calculate the strength of each player or entity in a given month.\n",
       "\n",
       "Note that the specific implementation details may vary depending on the new context, but the general approach and principles should remain the same.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "summary2, summary2_md = llama3_generate(prompt)\n",
    "Markdown(summary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better but not great..\n",
    "\n",
    "The above summary seems better, but quite often when running this (assuming some variation if determinism is not 100% configured), Gemma confuses some of the competition description with the writeup, claiming the writeup solution uses some of the methods from the description (Elo rating etc). So next I tried to simplify the contest description a bit to avoid it polluting the writeup summary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3: Summarize the Description First\n",
    "\n",
    "As the details in the description seem to confuse Gemma vs the writeup itself, I decided to try to summarize the competition description first, to give basic context but with less details for Gemma to get confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Summarize the following kaggle competition description in a very concise way. \"\\\n",
    "         f\"Omit references to specific algorithms or known solutions, focus on overview of the contest topic and goals.\\n\\n\" \\\n",
    "         f\"description: {comp0_desc}\\n\\n\" \\\n",
    "         f\"summary: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a summary of the competition description itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Summarize the following kaggle competition description in a very concise way. Omit references to specific algorithms or known solutions, focus on overview of the contest topic and goals.\n",
       "\n",
       "description: When predicting the outcome of chess games, you typically need two things; a rating system wherein the current ability of each player is estimated based on past results, and a model for estimating the expected score for each player, once you know their ratings.Most rating systems use some methodology to determine initial \"seed\" ratings for the pool of players, and then update those ratings based on ongoing results.  The most famous approach is the Elo approach, where the applied change to a player's rating is proportional to the amount by which they exceed their aggregate expected score across all their recent games.  The scaling factor is known as the \"K-factor\", and for the official ratings used throughout the world, the K-factor is highest for new players and lowest for topmost players.  But there are many other approaches: the Ken Thompson approach takes each player's most recent 100 games and calculates the rating that would be most likely to lead to that performance.  The Mark Glickman approach is similar to Elo but introduces additional parameters for each player, tracking the level of confidence and level of volatility for each player's rating, and then using these parameters to determine which K-factor to apply.The initial seed ratings are typically determined through a simultaneous calculation: a start rating is assumed for each player, then a \"performance rating\" is calculated for each player based on their results and the ratings of their opponents, and then those performance ratings are fed back into another iteration as the start ratings.  This is allowed to run until it converges upon a stable set of ratings.  This was the methodology used to calculate initial ratings for most major rating systems.  In fact this is the overall approach taken by the Jeff Sonas Chessmetrics rating calculation, and is used not just to calculate initial ratings but in fact to calculate all ratings.There is a general convention in chess rating systems whereby the difference in two ratings is used for calculating expected score when two players face each other.  Of course it could just as well be the ratio of the two ratings, or some other more complex relationship that depends on the magnitude of the ratings and not just their relative difference.Here are some links to articles existing on rating systems:Elo and Ken ThompsonGlickoChessmetricsMicrosoft TrueSkillJeff Moser has a C# implementation of Elo and TrueSkill on Github. has posted a Java implementation of Glicko on Github.\n",
       "\n",
       "summary: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 s, sys: 42 ms, total: 3.12 s\n",
      "Wall time: 3.11 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here is a concise summary of the competition description:\n",
       "\n",
       "The goal is to develop a rating system that estimates the current ability of each player based on past results, and a model to predict the expected score for each player. The system should determine initial ratings and update them based on ongoing results, using a methodology that takes into account factors such as the player's performance and the ratings of their opponents.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "comp_summary, comp_summary_md = llama3_generate(prompt)\n",
    "Markdown(comp_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writeup Summary from Description Summary and the Writeup itself\n",
    "\n",
    "Now that we have the competition description summary, we can give it and the writeup to Gemma and see how well it manages to summarize them together (vs full competition description + writeup above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"you are to answer as a helpful assistant helping understand questions about \" \\\n",
    "         f\"a kaggle competition writeup, and the solutions the writeup describes. \" \\\n",
    "         f\"a short description of the competition and its goals, and a solution writeup follows. \" \\\n",
    "         f\"description: {comp_summary}\\n\\n\" \\\n",
    "         f\"writeup: {writeup0_title}:\\n {writeup0}\\n\\n\" \\\n",
    "         f\"question: summarize the solution in the above writeup, focusing on used data analysis methods. \" \\\n",
    "         f\"Focus on the key points of the solutions and how they might have helped achieving better score in the competition.\\n\\n\" \\\n",
    "         f\"answer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "you are to answer as a helpful assistant helping understand questions about a kaggle competition writeup, and the solutions the writeup describes. a short description of the competition and its goals, and a solution writeup follows. description: Here is a concise summary of the competition description:\n",
       "\n",
       "The goal is to develop a rating system that estimates the current ability of each player based on past results, and a model to predict the expected score for each player. The system should determine initial ratings and update them based on ongoing results, using a methodology that takes into account factors such as the player's performance and the ratings of their opponents.<|eot_id|>\n",
       "\n",
       "writeup: Released: my Source Code and Analysis:\n",
       " <P>I calculated rating for every player in months 101-105 and after having the rating I have a simple formula to calculate the expected result only based on the rating and the color.<BR>The tricks that I used were mainly in calculating the rating but I will start explaining the simple part.<BR><BR>The first part was calculating the bonus for white<BR><BR>I had the following formula for this part:<BR>bonus=maximum((white_rating+black_rating-3100)/40.0,50)<BR><BR>Diff=white_rating+bonus-black_rating&nbsp; <BR><BR>Expected_result=0.5+Diff/850 <BR>When I changed it to be not more than <FONT size=2>0.970588 and not less than 0.1(practically it had a very small effect&nbsp;<BR>because&nbsp;the result was always bigger than 0.1 and there was only one case when I needed to reduce it to 0.970588)</P>\r\n",
       "<P></FONT><BR>Now we go to the hard part that is how to calculate the rating for every player.<BR>For this purpose I admit that I used the future to predict the past(but I have also prediction based on a different model in the top 10 when I did not use the future to predict the past).<BR><BR>I used a function that I called repeat_strength_estimate<BR>The function get the following parameters:<BR>1)k that is the last month that is not missing.<BR>For the prediction of months 101-105 k=100 but for testing my parameters I used k=90,91,92,...99<BR>2)max_months(practically get the value 81 and I admit that it is not a good name)<BR>The meaning of max_months=81 is practically that I&nbsp;do not use the first 20 months to predict month 101 and that I do not use the first 21 months to predict month 102 and generally <BR>I do not use the first&nbsp;m-81 months to predict month number m.<BR><BR>3)<FONT size=2>big_dif=310<BR>big_dif was used to calculate performance rating and for some reason I found that small values give better results<BR>in my tests so I used this small value<BR><BR><FONT size=2>My formula for performance rating was</P>\r\n",
       "<P>performance_rating=avg_rating+((result-opponents)/opponents)*big_dif;<BR><BR>the value of the division can be at most 1 and at least -1 because result is practically weighted half points and is something between 0 and twice the weight of the opponent.<BR><BR>opponents in this formula mean the number of weight opponents(when the weight is based on the distance in month from&nbsp;the month to predict)&nbsp;&nbsp;<BR>This formula means that even if a player lost all the games against the opponents then he still got performance rating that is only 310 elo weaker than the average of the opponents because the result of the division is always between -1 for losing all games and 1 for winning all games.<BR></FONT></FONT><BR>I guess that it was good because not all games are included so person who played against strong opponents probably performed practically better than his real score and it is not good for the real world when games are not missing.<BR><BR>4)num_avg=5.9 similiar to chess metrics(I added 5.9 faked opponents with average rating)<BR><BR>5)num_weak=2.2(added 2.2 faked weak opponents)<BR><BR>6)<FONT size=2>value_weak=2210(rating of the weak opponents like chess metrics<BR><BR>7)<FONT size=2>unrated=2285(I think that practically had no effect because players always&nbsp;have games in the last 80 months)</P></FONT>\r\n",
       "<P></FONT><BR>8)<FONT size=2>minimal_game_finished=15(I reduce rating to players with less than 15 weighted games similiar to chess metrics)<BR><BR>9)reduction_per_game=12(the number that I reduce for less of experience for player without many weight games)<BR><BR>10)adding=39(the number that I add to rating of players after every iteration)<BR><BR>repeat_strength_estimate basically did 10 iterations for evaluating the strength of every player in every month.<BR></FONT>The evaluation of&nbsp;the strengh was based on 2 steps when step 1 was the function that calculate strength that is similiar to chess metrics but there are important differences and step 2 was deciding that place 50 has rating 2625 in the rating list that is exactly the same as chess metrics.<BR><BR><FONT size=2></P>\r\n",
       "<P>calc_strength_chess_metric is the missing function to understand the algorithm and it basically got 11 parameters(all the 10 parameters that repeat_strength_estimate got and another parameter that is the month that we calculate&nbsp;estimate for it).<BR><BR>Note that&nbsp;the&nbsp;estimate for month 50 of player 1 when months 101-105 are missing is important because if player 2 played with player 1 at month 50 <BR>then it is going to influence the rating of player 2&nbsp; at month 101-105 that is used to calculate the expected result.<BR><BR>I use the word estimate and not rating because rating by definition assume that we do not have future results.<BR><BR>I had basically 2 steps in<BR>calc_strength_chess_metric<BR><BR>The first step was a loop that calculated the estimate for strength for every player in the relevant month.<BR>The second step is a&nbsp;step that I used only when I needed to predict the strength in the missing months and it is practically unfair trick but not something that is forbidden in the competition because I used the information about games and not about the results in the supposed missing months to&nbsp;calculate changes in the rating estimate in these months.<BR></FONT><BR>I did not finish to explain my algorithm&nbsp;and I plan also to send code later but now I need only to explain the 2 steps of calc_strength_chess_metric to explain my algorithm and I will do it later in another post(this part of the program is only slightly more than 100 lines of code in C).<BR></P>\n",
       "\n",
       "question: summarize the solution in the above writeup, focusing on used data analysis methods. Focus on the key points of the solutions and how they might have helped achieving better score in the competition.\n",
       "\n",
       "answer: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 132 ms, total: 22.6 s\n",
      "Wall time: 22.6 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The solution writeup describes a rating system that estimates the current ability of each player based on past results. The system uses a combination of data analysis methods to calculate the rating and expected score for each player.\n",
       "\n",
       "Key points of the solution:\n",
       "\n",
       "1. **Rating calculation**: The solution uses a formula to calculate the rating for each player, which takes into account the player's performance and the ratings of their opponents. The formula is based on the concept of \"bonus\" for white, which is calculated as the maximum of the difference between the white and black ratings divided by 40, and 50.\n",
       "2. **Performance rating**: The solution uses a performance rating formula that takes into account the result of the game, the opponents, and the rating of the player. The formula is designed to give a performance rating that is not too sensitive to the result of a single game.\n",
       "3. **Repeat strength estimate**: The solution uses a function called \"repeat_strength_estimate\" to calculate the strength of each player in each month. The function takes into account the player's past performance, the ratings of their opponents, and the number of games played.\n",
       "4. **Calc_strength_chess_metric**: The solution uses a function called \"calc_strength_chess_metric\" to calculate the strength of each player in each month. The function takes into account the player's past performance, the ratings of their opponents, and the number of games played.\n",
       "\n",
       "Data analysis methods used:\n",
       "\n",
       "1. **Regression analysis**: The solution uses a regression-like formula to calculate the rating and expected score for each player.\n",
       "2. **Weighted average**: The solution uses a weighted average to calculate the performance rating, where the weights are based on the opponents and the result of the game.\n",
       "3. **Iterative calculation**: The solution uses an iterative calculation to calculate the strength of each player in each month, where the calculation is based on the player's past performance and the ratings of their opponents.\n",
       "\n",
       "How the solution might have helped achieving better score in the competition:\n",
       "\n",
       "1. **Accurate rating calculation**: The solution's rating calculation formula takes into account the player's performance and the ratings of their opponents, which might have resulted in more accurate ratings.\n",
       "2. **Robust performance rating**: The solution's performance rating formula is designed to give a performance rating that is not too sensitive to the result of a single game, which might have resulted in more robust ratings.\n",
       "3. **Effective use of data**: The solution uses a combination of data analysis methods to calculate the rating and expected score for each player, which might have resulted in more effective use of the available data.\n",
       "4. **Iterative calculation**: The solution's iterative calculation of the strength of each player in each month might have resulted in more accurate estimates of the player's strength.\n",
       "\n",
       "Overall, the solution's use of data analysis methods, such as regression analysis, weighted average, and iterative calculation, might have helped achieve better scores in the competition by providing more accurate ratings and expected scores.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "summary3, summary3_md = llama3_generate(prompt)\n",
    "Markdown(summary3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems better to me. But there are multiple writeups typically for a competition, so finding the best signal from the noise would be nice. That is, first to select which writeups to show first, or how to rank them for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to Rank the Solutions in a Competition\n",
    "\n",
    "Because it could be helpful to show someone who wants a competition solution writeup summary the best scoring solutions first.\n",
    "\n",
    "So, first a method to perform competition summarization all in once to apply across different competitions. See how I tried to trick people tend to give for prompting as an option, asking it to think step by step :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_writeup_ranking(title, print_prompt=False, n_process=None):\n",
    "    df_comp = df_writeups[df_writeups[\"Title of Competition\"]==title]\n",
    "    #display(df_comp)\n",
    "    for i in range(0, df_comp.shape[0]):\n",
    "        writeup_title = df_comp.iloc[i][\"Title of Writeup\"]\n",
    "        writeup = df_comp.iloc[i][\"writeup_clean\"]\n",
    "        prompt = f\"Given the following competition solution writeup, \" \\\n",
    "                 f\"what is the placement of the described solution in the competition? \"\\\n",
    "                 f\"Think step by step. First check if the title contains the placement, then check if the writeup does. \" \\\n",
    "                 f\"If you cannot find the placement, answer only with 'insufficient information'.\\n\\n\" \\\n",
    "                 f\"title: {writeup_title}:\\n\" \\\n",
    "                 f\"writeup: {writeup}\"\n",
    "        #prompt = f\"{writeup_title}:\\n\" \\\n",
    "        #         f\"{writeup}.\\n\\nBased on my analysis, the above write solution in the competition ranked at position: \"\n",
    "        if print_prompt:\n",
    "            print(prompt)\n",
    "        ranking, ranking_md = llama3_generate(prompt)\n",
    "        print(f\"--------------- {writeup_title} -------------------\")\n",
    "        display(ranking_md)\n",
    "        if n_process is not None and i >= n_process-1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chess ratings - Elo versus the Rest of the World'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp0 = competitions[0]\n",
    "comp0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From reading Kaggle writeups in the past, I recall seeing those mostly posted for high-ranking notebooks. The following shows how the title often states the ranking of the writeup solution in the competition, and how well Gemma does with identifying that information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Released: my Source Code and Analysis -------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Insufficient information.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 6th place(UriB) by Uri Blass -------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The title mentions \"6th place\" and the writeup does not provide any additional information about the placement. Therefore, the answer is:\n",
       "\n",
       "6th place<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 7th place - littlefish -------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The placement is explicitly mentioned in the title: \"7th place - littlefish\". Therefore, the described solution is in 7th place.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 3rd place: Chessmetrics - Variant -------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The title explicitly states that the solution is the 3rd place winner, so the answer is: **3rd place**.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 2nd place: TrueSkill Through Time -------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "According to the writeup, the author placed 2nd in the competition.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_writeup_ranking(comp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as the above shows, not all solutions are perfectly ranked with this. The model sometimes seems to lose its touch. For example, in my current run the last of the solutions above has a title of \"2nd place:...\". For some reason Gemma does not recognize this. The way Gemma expresses the ranking in its output varies a lot, making it a bit harder to parse it reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sidenote, some of the collected writeups in this dataset do now even seem to be actual solutions, just random looking forum posts that may have been caught \"by accident\" in the dataset, or that just refer to some notebook with a few words in the forum post.\n",
    "\n",
    "Well, I guess all datasets end up with random noise. Thats why data cleaning is such a big job.. \n",
    "\n",
    "Here is one example, it just seems to congratulate the winners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following competition solution writeup, what is the placement of the described solution in the competition? Think step by step. First check if the title contains the placement, then check if the writeup does. If you cannot find the placement, answer only with 'insufficient information'.\n",
      "\n",
      "title: Sharing Techniques Used:\n",
      "writeup: Congratulations to all the leaders in this contest!    Unfortunately, these forums have been pretty quiet during the contest, but now that it's over, I'm wondering if people are willing to disclose the techniques they used so others can learn something new.In a few emails with a couple contestants, I know there are a mix of techniques being used out there --- KNNs, neural-nets, SVDs, node metrics (like Adar/Adamic, Jaccard, number of common neighbors), and some graph-based techniques (shortest paths, edge-betweenness centrality, etc.).   So, what techniques did you use? What worked, and what didn't?  Thanks!\n",
      "--------------- Sharing Techniques Used -------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Insufficient information.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comp3 = competitions[3]\n",
    "find_writeup_ranking(comp3, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above also illustrates how Gemma has a tendency to get overly talkative. My prompt just asks it to find the placement, not to tell me about what it thinks are the solutions used. Yet it still lists a set of solutions, that have not even been used in the writeup. They are just given as examples of what the writer thought were used generally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 4: Summarize Multiple Solutions\n",
    "\n",
    "OK, so we have multiple writeups per competition, and automated ranking identification was so far not very successful. How about summarizing multiple writeups from the competition to give an idea of what was kind of solutions people generally used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with a single writeup first to experiment prompts\n",
    "\n",
    "This prompt still asks for summary with that exact word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_writeup_and_desc = \\\n",
    "         f\"you are to answer as a helpful assistant helping understand questions about \" \\\n",
    "         f\"a kaggle competition writeup, and the solutions the writeup describes. \" \\\n",
    "         f\"a short description of the competition and its goals, and a solution writeup follows. \" \\\n",
    "         f\"description: {comp_summary}\\n\\n\" \\\n",
    "         f\"writeup: {writeup0_title}:\\n {writeup0}\\n\\n\" \\\n",
    "         f\"question: summarize the solution in the above writeup, focusing on used data analysis methods. \" \\\n",
    "         f\"Focus on the key points of the solutions and how they might have helped achieving better score in the competition.\\n\\n\" \\\n",
    "         f\"answer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 156 ms, total: 22.8 s\n",
      "Wall time: 22.8 s\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The solution writeup describes a rating system that estimates the current ability of each player based on past results. The system uses a combination of data analysis methods to calculate the rating and expected score for each player.\n",
       "\n",
       "Key points of the solution:\n",
       "\n",
       "1. **Rating calculation**: The solution uses a formula to calculate the rating for each player, which takes into account the player's performance and the ratings of their opponents. The formula is based on the concept of \"bonus\" for white, which is calculated as the maximum of the difference between the white and black ratings divided by 40, and 50.\n",
       "2. **Performance rating**: The solution uses a performance rating formula that takes into account the result of the game, the opponents, and the rating of the player. The formula is designed to give a performance rating that is not too sensitive to the result of a single game.\n",
       "3. **Repeat strength estimate**: The solution uses a function called \"repeat_strength_estimate\" to calculate the strength of each player in each month. The function takes into account the player's past performance, the ratings of their opponents, and the number of games played.\n",
       "4. **Calc_strength_chess_metric**: The solution uses a function called \"calc_strength_chess_metric\" to calculate the strength of each player in each month. The function takes into account the player's past performance, the ratings of their opponents, and the number of games played.\n",
       "\n",
       "Data analysis methods used:\n",
       "\n",
       "1. **Regression analysis**: The solution uses a regression-like formula to calculate the rating and expected score for each player.\n",
       "2. **Weighted average**: The solution uses a weighted average to calculate the performance rating, where the weights are based on the opponents and the result of the game.\n",
       "3. **Iterative calculation**: The solution uses an iterative calculation to calculate the strength of each player in each month, where the calculation is based on the player's past performance and the ratings of their opponents.\n",
       "\n",
       "How the solution might have helped achieving better score in the competition:\n",
       "\n",
       "1. **Accurate rating calculation**: The solution's rating calculation formula takes into account the player's performance and the ratings of their opponents, which might have resulted in more accurate ratings.\n",
       "2. **Robust performance rating**: The solution's performance rating formula is designed to give a performance rating that is not too sensitive to the result of a single game, which might have resulted in more robust ratings.\n",
       "3. **Effective use of data**: The solution uses a combination of data analysis methods to calculate the rating and expected score for each player, which might have resulted in more effective use of the available data.\n",
       "4. **Iterative calculation**: The solution's iterative calculation of the strength of each player in each month might have resulted in more accurate estimates of the player's strength.\n",
       "\n",
       "Overall, the solution's use of data analysis methods, such as regression analysis, weighted average, and iterative calculation, might have helped achieve better scores in the competition by providing more accurate ratings and expected scores.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "summary3, summary3_md = llama3_generate(prompt_writeup_and_desc)\n",
    "Markdown(summary3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Prompt to Avoid \"Summarize\" term\n",
    "\n",
    "The above summary shows, similar to the previous ones, how Gemma actually likes to give its opinions at the end of a summary. In this case, I am not so interested in its opinion, especialle since it seems to get confused even with contest description vs solution writeup.\n",
    "\n",
    "So I tried to avoid this, by asking for the key points and avoiding the term \"summarize\". Lets see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_description(description):\n",
    "    #print(\"summarizing description\")\n",
    "    prompt = f\"Summarize the following kaggle competition description in a very concise way. \"\\\n",
    "         f\"Omit references to specific algorithms or known solutions, focus on overview of the contest topic and goals.\\n\\n\" \\\n",
    "         f\"description: {description}\\n\\n\" \\\n",
    "         f\"summary: \"\n",
    "    summary, summary_md = llama3_generate(prompt)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the modified summarization prompt. Here I do not use the term \"summarize\", but rather as Gemma to just list the key points (from datascience application viewpoint):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What a fascinating competition! As a helpful assistant, I'll extract the key points from a datascience application viewpoint for similar problem solving. Here are the key takeaways:\n",
       "\n",
       "1. **Rating system design**: The competition involves developing a rating system that estimates the current ability of each player based on past results. This requires designing a methodology that takes into account factors such as player performance and opponent ratings.\n",
       "2. **Formula-based approach**: The author used a formula-based approach to calculate the expected result, which is a simple and intuitive way to model the relationship between ratings and expected outcomes.\n",
       "3. **Rating calculation**: The author used a more complex formula to calculate the rating for each player, which involves predicting the past based on future data (a technique known as \"future to predict the past\"). This approach is not uncommon in datascience, where predicting the past can be a useful technique for modeling complex systems.\n",
       "4. **Parameter tuning**: The author used parameter tuning to optimize the performance of their rating system, which is a common practice in datascience. This involves adjusting parameters to find the optimal values that minimize errors or maximize performance.\n",
       "5. **Data augmentation**: The author used data augmentation techniques, such as adding fake opponents with average ratings, to improve the robustness of their rating system. This is a common technique in datascience, where adding noise or perturbations to the data can help improve model performance.\n",
       "6. **Iterative estimation**: The author used an iterative estimation approach to calculate the strength of each player, which involves repeating the estimation process multiple times to refine the estimates. This is a common technique in datascience, where iterative estimation can be used to improve the accuracy of model predictions.\n",
       "7. **Unfair trick**: The author used an \"unfair trick\" to predict the strength of players in missing months, which involves using information about games and not results in those months. While this may not be a conventional approach, it highlights the importance of creative thinking and outside-the-box solutions in datascience.\n",
       "\n",
       "Overall, this competition showcases the importance of designing a robust rating system that takes into account various factors, including player performance and opponent ratings. The use of formula-based approaches, parameter tuning, data augmentation, and iterative estimation are all important techniques in datascience that can be applied to similar problems.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 193 ms, total: 21.1 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def summarize_writeup_and_desc(df_comp_meta, comp_name, writeup_title, writeup):\n",
    "    comp_desc = df_comp_meta[df_comp_meta[\"comp_name\"] == comp_name][\"desc\"].values[0]\n",
    "    desc_summary = summarize_description(comp_desc)\n",
    "    prompt_writeup_and_desc = \\\n",
    "         f\"You are Gemma, a helpful assistant for Kaggle competitors to understand their datascience problems \" \\\n",
    "         f\"and propose approaches to solve them. \" \\\n",
    "         f\"Your points should have enough details to be useful for similar problem solving, \" \\\n",
    "         f\"but not excessively focused on the specific approach in writeup. \" \\\n",
    "         f\"More in the sense of overall application lessons for similar problems. \" \\\n",
    "         f\"here is a short summary of the competition now being analyzed: \" \\\n",
    "         f\"description: {desc_summary}\\n\\n\" \\\n",
    "         f\"following will be a writeup of someone who participated in this competition.\" \\\n",
    "         f\"list the key points of this from the datascience application viewpoint for similar problem solving.\\n\" \\\n",
    "         f\"writeup:\\n {writeup_title}:\\n {writeup}\\n\\n\" \\\n",
    "         f\"answer: \\n\"\n",
    "    final_summary, final_summary_md = llama3_generate(prompt_writeup_and_desc)\n",
    "    return final_summary, final_summary_md\n",
    "\n",
    "competitions = df_writeups[\"Title of Competition\"].unique()\n",
    "comp0 = competitions[0]\n",
    "df_comp0 = df_writeups[df_writeups[\"Title of Competition\"]==comp0]\n",
    "writeup0_title = df_comp0[\"Title of Writeup\"].iloc[0]\n",
    "comp0_name = df_comp0[\"Title of Competition\"].iloc[0]\n",
    "writeup0=df_comp0.iloc[1][\"writeup_clean\"]\n",
    "final_summary, final_summary_md = summarize_writeup_and_desc(df_comp_meta, comp0_name, writeup0_title, writeup0)\n",
    "display(final_summary_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the above, the Gemma opinion piece from the end of the \"summary\" is gone. And in general, I find the key points to represent this writeup quite well. \n",
    "\n",
    "This especially serves my purposes here better, since if I want to try using Gemma to summarize multiple writeups, I am not interested in Gemma trying to summarize multiples of its own opinion pieces. Rather I would prefer it to summarize the used solutions across those multiple writeups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to summarize competition writeups together\n",
    "\n",
    "To make it a bit quicker and concise, I summarize only a subset of the competitions here. First a set of helpers to summarize writeups for a competition together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions = df_writeups[\"Title of Competition\"].unique()\n",
    "writeup_summaries = []\n",
    "writeup_summaries_md = []\n",
    "overall_summaries = []\n",
    "processed_titles = set()\n",
    "processed_titles_list = []\n",
    "skipped_titles = set()\n",
    "skipped_titles_list = []\n",
    "overall_summary_prompts = []\n",
    "prompts = []\n",
    "writeups = []\n",
    "prompt_lengths = []\n",
    "writeup_lengths = []\n",
    "summary_lengths = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_competition_writeups(comps_to_summarize, df_writeups_here, model_tokenizer, max_comps=None):\n",
    "    skip_count = 0\n",
    "    for idx, competition in tqdm(enumerate(comps_to_summarize), total=len(comps_to_summarize)):\n",
    "        df_comp = df_writeups_here[df_writeups_here[\"Title of Competition\"] == competition]\n",
    "\n",
    "        comp_name = df_comp[\"Title of Competition\"].iloc[0]\n",
    "        # have to skip overly long writeups. luckily not too many of those\n",
    "        max_len = 8192 - 1001 #1000 here is requested count for max new tokens\n",
    "        if on_kaggle:\n",
    "            max_len = 4096 # Kaggle GPU seems unable to handle long sequence due to memory limit\n",
    "        memory_error_msg = \"skipped due to token limit (on Kaggle need shorter due to GPU memory limit)\"\n",
    "        #memory_skip = False\n",
    "\n",
    "        # list_idx is to print position in saved lists, to be able to pick one later\n",
    "        list_idx = len(overall_summaries)\n",
    "        print(f\"{list_idx}: competition {comp_name}, writeups {df_comp.shape[0]}\")\n",
    "        #here filter only the writeups for this competition\n",
    "        intermediate = df_comp_meta[df_comp_meta[\"comp_name\"] == comp_name]\n",
    "        if intermediate.shape[0] == 0:\n",
    "            # the two datasets I use here are not fully in sync, have to skip full mismatches\n",
    "            print(\"competition metadata not found, skipping\")\n",
    "            skipped_titles.add(competition)\n",
    "            skipped_titles_list.append(competition)\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        # on Kaggle it runs a bit slow at time, so had to implement some extra capping support\n",
    "        if max_comps is not None and idx - skip_count >= max_comps:\n",
    "            print(\"stopping due to maximum summaries reached\")\n",
    "            break\n",
    "\n",
    "        comp_desc = df_comp_meta[df_comp_meta[\"comp_name\"] == comp_name][\"desc\"].values[0]\n",
    "        desc_summary = summarize_description(comp_desc)\n",
    "\n",
    "        comp_writeup_summaries = []\n",
    "        comp_writeup_summaries_md = []\n",
    "        comp_prompts = []\n",
    "        comp_writeups = []\n",
    "        comp_prompt_lengths = []\n",
    "        comp_writeup_lengths = []\n",
    "        comp_summary_lengths = []\n",
    "        prompts.append(comp_prompts)\n",
    "        writeups.append(comp_writeups)\n",
    "        writeup_summaries.append(comp_writeup_summaries)\n",
    "        writeup_summaries_md.append(comp_writeup_summaries_md)\n",
    "        prompt_lengths.append(comp_prompt_lengths)\n",
    "        writeup_lengths.append(comp_writeup_lengths)\n",
    "        summary_lengths.append(comp_summary_lengths)\n",
    "\n",
    "        prompt_overall_summary = \\\n",
    "            f\"The following gives a summary of a Kaggle competition description, \" \\\n",
    "            f\"and a set of one or more writeups on solutions used in that competition, separated by ======.\\n\\n\" \\\n",
    "            f\"Use these to summarize a set of guidelines for ideas on how to approach \" \\\n",
    "            f\"a given Kaggle data science competition. \\n\\n\" \\\n",
    "            f\"Competition description summary: {desc_summary}\\n\\n\"\n",
    "\n",
    "        # loop all writeups for each competition\n",
    "        for i, row in tqdm(df_comp.iterrows(), total=df_comp.shape[0]):\n",
    "            writeup_title = row[\"Title of Writeup\"] \n",
    "            writeup = row[\"writeup_clean\"]\n",
    "            #print(i)\n",
    "\n",
    "            prompt_writeup_and_desc = \\\n",
    "                 f\"You are Gemma, a helpful assistant for Kaggle competitors to understand their datascience problems \" \\\n",
    "                 f\"and propose approaches to solve them. \" \\\n",
    "                 f\"Your points should have enough details to be useful for similar problem solving, \" \\\n",
    "                 f\"but not excessively focused on the specific approach in writeup. \" \\\n",
    "                 f\"More in the sense of overall application lessons for similar problems. \" \\\n",
    "                 f\"Here is a short summary of the competition now being analyzed:\\n\\n \" \\\n",
    "                 f\"description:\\n {desc_summary}\\n\\n\" \\\n",
    "                 f\"Following will be a writeup of someone who participated in this competition. \" \\\n",
    "                 f\"List the key points of this from the datascience application viewpoint for similar problem solving.\\n\" \\\n",
    "                 f\"Writeup:\\n {writeup_title}:\\n {writeup}\\n\\n\" \\\n",
    "                 f\"Answer: \\n\"\n",
    "\n",
    "            input_ids = model_tokenizer(prompt_writeup_and_desc, return_tensors=\"pt\")\n",
    "            prompt_len = len(input_ids[\"input_ids\"][0])\n",
    "\n",
    "            comp_prompts.append(prompt_writeup_and_desc)\n",
    "            comp_writeups.append(writeup)\n",
    "            comp_prompt_lengths.append(prompt_len)\n",
    "            input_ids = model_tokenizer(writeup_title+\":\\n\"+writeup, return_tensors=\"pt\")\n",
    "            writeup_len = len(input_ids[\"input_ids\"][0])\n",
    "            comp_writeup_lengths.append(writeup_len)\n",
    "            #print(f\"prompt length: {prompt_len}, writeup length: {writeup_len}\")\n",
    "\n",
    "            if prompt_len > max_len:\n",
    "                print(f\"skipping writeup {writeup_title} for competition {competition} due to too high length {prompt_len}.\")\n",
    "                #continue\n",
    "                summary, summary_md = memory_error_msg, memory_error_msg\n",
    "                memory_skip = True\n",
    "            else:\n",
    "                summary, summary_md = llama3_generate(prompt_writeup_and_desc)\n",
    "\n",
    "            # Store or process the 'summary' as needed\n",
    "            #print(f\"Competition: {comp_name}\")\n",
    "            #print(f\"Writeup Title: {writeup_title}\")\n",
    "            #print(f\"Summary: {summary}\")\n",
    "            #print(\"----------------------\")\n",
    "            comp_writeup_summaries.append(summary)\n",
    "            comp_writeup_summaries_md.append(summary_md)\n",
    "            input_ids = model_tokenizer(summary, return_tensors=\"pt\")\n",
    "            summary_len = len(input_ids[\"input_ids\"][0])\n",
    "            comp_summary_lengths.append(summary_len)\n",
    "\n",
    "            input_ids = model_tokenizer(prompt_overall_summary, return_tensors=\"pt\")\n",
    "            prompt_overall_summary_len = len(input_ids[\"input_ids\"][0])\n",
    "\n",
    "            if prompt_overall_summary_len < max_len:\n",
    "                prompt_overall_summary += f\"\\n\\n======\\n\\n writeup summary:\\n {summary}\\n\\n\"\n",
    "            else:\n",
    "                print(f\"skipping adding to overall prompt due to reaching max limit set: {prompt_overall_summary_len} > {max_len}\")\n",
    "\n",
    "        if competition not in processed_titles:\n",
    "            processed_titles.add(competition)\n",
    "            processed_titles_list.append(competition)\n",
    "\n",
    "        prompt_overall_summary += \\\n",
    "            f\"\\n\\n======\\n\\n Focus on the key points of the writeups and how they might have helped achieving better score in the competition.\" \\\n",
    "            f\"Extract specifically used data analysis methods, and summarize how they are related across writeups.\\n\\n\" \\\n",
    "            f\"answer: \"\n",
    "        input_ids = model_tokenizer(prompt_overall_summary, return_tensors=\"pt\")\n",
    "        overall_prompt_len = len(input_ids[\"input_ids\"][0])\n",
    "\n",
    "        if overall_prompt_len > max_len:\n",
    "            print(f\"skipping overall summary for competition {competition} due to too high length {overall_prompt_len}.\")\n",
    "            overall_summary, overall_summary_md = memory_error_msg, memory_error_msg\n",
    "        else:\n",
    "            overall_summary, overall_summary_md = llama3_generate(prompt_overall_summary)\n",
    "\n",
    "        input_ids = model_tokenizer(overall_summary, return_tensors=\"pt\")\n",
    "        overall_summary_len = len(input_ids[\"input_ids\"][0])\n",
    "        \n",
    "        #print(overall_summary)\n",
    "        print(f\"     prompt lengths={comp_prompt_lengths}\")\n",
    "        print(f\"    writeup lengths={comp_writeup_lengths}\")\n",
    "        print(f\"    summary lengths={comp_summary_lengths}\")\n",
    "        print(f\"    total writeups length:{sum(comp_writeup_lengths)}, overall prompt length: {overall_prompt_len}, overall summary length: {overall_summary_len}\")\n",
    "        overall_summaries.append(overall_summary_md)\n",
    "        overall_summary_prompts.append(prompt_overall_summary)\n",
    "    print(f\"total of {len(prompts)} competitions processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above method, the following notebook cells will create overall summaries of competition writeups. This approach first uses Gemma to summarize each writeup for a competition separately, takes these summaries together, and finally uses Gemma to summarize the key points from all these writeup summaries as one. It prints out the following information:\n",
    "\n",
    "- writeup count: how many writeups are there for the competition in the dataset.\n",
    "- prompt lengths: how long is the separate writeup summary prompt used as counted in Gemma tokens. this prompt includes the writeup.\n",
    "- writeup lengths: length of a separate writeup alone, without the rest of the prompt.\n",
    "- summary lengths: length of the Gemma built summaries (list of key points) for each writeup\n",
    "- total writeup length: length of all writeups for the competition, in Gemma tokens. if we concatenate the raw writeups in full\n",
    "- overall prompt length: the summary prompt length using summaries of each writeup as input and not full writeups.\n",
    "- overall summary length: length of the final overall summary generated by Gemma for overall prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33916ec36824b92887cf7e7dbf20d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: competition Chess ratings - Elo versus the Rest of the World, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6793b9e06154ccdbe4c64c3f10f9e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[312, 1331, 604, 666, 2443]\n",
      "    writeup lengths=[115, 1134, 407, 468, 2246]\n",
      "    summary lengths=[417, 526, 402, 445, 430]\n",
      "    total writeups length:4370, overall prompt length: 2440, overall summary length: 503\n",
      "1: competition RTA Freeway Travel Time Prediction, writeups 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53228d3430c94b1eb317d28899b0d709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[190]\n",
      "    writeup lengths=[12]\n",
      "    summary lengths=[513]\n",
      "    total writeups length:12, overall prompt length: 687, overall summary length: 463\n",
      "2: competition Predict Grant Applications, writeups 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d113b23c284a919fd11d4318ec8b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[193, 735]\n",
      "    writeup lengths=[18, 560]\n",
      "    summary lengths=[287, 426]\n",
      "    total writeups length:578, overall prompt length: 891, overall summary length: 290\n",
      "3: competition IJCNN Social Network Challenge, writeups 2\n",
      "competition metadata not found, skipping\n",
      "3: competition Stay Alert! The Ford Challenge, writeups 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d8dcc0b72f47a5973cf223a1a312c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[760]\n",
      "    writeup lengths=[606]\n",
      "    summary lengths=[371]\n",
      "    total writeups length:606, overall prompt length: 520, overall summary length: 437\n",
      "4: competition Don't Overfit!, writeups 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b03b5e4f31b40e49250309c4938dd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[443]\n",
      "    writeup lengths=[265]\n",
      "    summary lengths=[281]\n",
      "    total writeups length:265, overall prompt length: 455, overall summary length: 319\n",
      "total of 5 competitions processed\n",
      "CPU times: user 4min 7s, sys: 1.42 s, total: 4min 8s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summarize_competition_writeups(competitions[:6], df_writeups, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, most of these competitions actually just have one writeup in this dataset. Many of them are also very short, with the shortest being only 15 tokens. A few competitions had more than one writeup, and some had longer writeups. So lets take a look at some of these different types in a bit more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall summary, competition 1\n",
    "\n",
    "The first competition has the most writeups in this set, 5 writeups. Lets see how all of them get summarized together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summaries, here are the key points that can be applied to similar datascience problems:\n",
       "\n",
       "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly.\n",
       "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches.\n",
       "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach.\n",
       "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions.\n",
       "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve.\n",
       "6. **Engage with the community**: Engage with the community to share knowledge and learn from others.\n",
       "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings.\n",
       "8. **Use historical data**: Use historical data to inform predictions and make informed decisions.\n",
       "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games.\n",
       "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances.\n",
       "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions.\n",
       "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them.\n",
       "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions.\n",
       "14. **Iterative refinement**: Refine predictions through multiple iterations.\n",
       "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions.\n",
       "\n",
       "The data analysis methods used across the writeups include:\n",
       "\n",
       "* Weighting and decay\n",
       "* Padding and normalization\n",
       "* Iterative calculation\n",
       "* Incorporating future results\n",
       "* Simple modifications\n",
       "* Exploration of established methods\n",
       "* Customization of the rating formula\n",
       "* Use of iterative rating formula\n",
       "* Weighting and normalization\n",
       "* Use of additional parameters\n",
       "* Prediction formula\n",
       "* Code implementation\n",
       "\n",
       "These methods are related across the writeups in that they all involve using different techniques to develop a robust and accurate rating system. The methods are used to handle missing data, refine predictions, and account for changing circumstances. The use of iterative calculation, weighting and normalization, and incorporating future results are common across the writeups, indicating that these methods are effective in developing a robust rating system.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above overall summary seems to make sense, although much of it focuses on very generic advice. \n",
    "\n",
    "Perhaps with some more prompt tuning it could be tuned to summarize the more specific solutions from the writeup. Although even in this case the \"Data Analysis Methods\" part does include some reference to those specific solutions. And the general advice is not bad in itself. So I leave further prompt tuning for the future. \n",
    "\n",
    "This summary is also back to providing Gemmas opinions in the end, likely because in my prompt I used the term \"summarize\" again. However, for me it is fine this time since this would be the final output of the overall summarization.\n",
    "\n",
    "I will still have to look at the individual writeup details vs overall summary in a future update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall summary, competition 2\n",
    "\n",
    "As seen in the above processing, competition 2 had a single writeup, that had the shortest set of 15 tokens. Lets see what Gemma has to say about that. \n",
    "\n",
    "But first, lets check what is such as super-short writeup anyway:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"For anybody interest, here's the actual solution.\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeups[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks even a bit suspicious, as if something is left out of the writeup. Let's see if the problem is in what I picked from the dataframe, in the collection method of the writeups, or maybe the writeup is just this :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competition Launch Date</th>\n",
       "      <th>Title of Competition</th>\n",
       "      <th>Competition URL</th>\n",
       "      <th>Date of Writeup</th>\n",
       "      <th>Title of Writeup</th>\n",
       "      <th>writeup</th>\n",
       "      <th>Writeup URL</th>\n",
       "      <th>writeup_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/23/2010 00:00:00</td>\n",
       "      <td>RTA Freeway Travel Time Prediction</td>\n",
       "      <td>https://www.kaggle.com/c/2467</td>\n",
       "      <td>02/16/2011 06:22:07</td>\n",
       "      <td>Solution</td>\n",
       "      <td>For anybody interest, here's the actual solution.</td>\n",
       "      <td>https://www.kaggle.com/c/2467/discussion/294</td>\n",
       "      <td>For anybody interest, here's the actual solution.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Competition Launch Date                Title of Competition  \\\n",
       "5     11/23/2010 00:00:00  RTA Freeway Travel Time Prediction   \n",
       "\n",
       "                 Competition URL      Date of Writeup Title of Writeup  \\\n",
       "5  https://www.kaggle.com/c/2467  02/16/2011 06:22:07         Solution   \n",
       "\n",
       "                                             writeup  \\\n",
       "5  For anybody interest, here's the actual solution.   \n",
       "\n",
       "                                    Writeup URL  \\\n",
       "5  https://www.kaggle.com/c/2467/discussion/294   \n",
       "\n",
       "                                       writeup_clean  \n",
       "5  For anybody interest, here's the actual solution.  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_writeups[df_writeups[\"Title of Competition\"] == \"RTA Freeway Travel Time Prediction\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    For anybody interest, here's the actual solution.\n",
       "Name: writeup, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_writeups[df_writeups[\"Title of Competition\"] == \"RTA Freeway Travel Time Prediction\"][\"writeup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least it seems that this is the actual writeup in the data I am using. \n",
    "\n",
    "So what does Gemma say when it tries to summarize this writeup that does not actually say much of anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup, I've identified the key points from a datascience application viewpoint that can be applied to similar problem-solving:\n",
       "\n",
       "1. **Understanding the problem**: The competition's goal is to predict travel times on the M4 freeway, which requires a deep understanding of the problem and its context. This includes identifying the key factors that affect travel times, such as traffic volume, road conditions, and time of day.\n",
       "2. **Data preparation**: The solution likely involved preparing the historical data for analysis, which may have included handling missing values, data cleaning, and feature engineering. This step is crucial in ensuring that the data is accurate and reliable.\n",
       "3. **Feature selection**: The solution likely involved selecting the most relevant features that can help predict travel times. This may have included features such as traffic volume, road conditions, time of day, and weather.\n",
       "4. **Model selection**: The solution likely involved selecting a suitable machine learning model that can accurately predict travel times. This may have included models such as linear regression, decision trees, random forests, or neural networks.\n",
       "5. **Hyperparameter tuning**: The solution likely involved tuning the hyperparameters of the selected model to optimize its performance. This may have included techniques such as grid search, random search, or Bayesian optimization.\n",
       "6. **Model evaluation**: The solution likely involved evaluating the performance of the selected model using metrics such as mean absolute error (MAE), mean squared error (MSE), or mean absolute percentage error (MAPE). This step is crucial in ensuring that the model is accurate and reliable.\n",
       "7. **Ensemble methods**: The solution may have involved using ensemble methods such as bagging, boosting, or stacking to combine the predictions of multiple models and improve the overall performance.\n",
       "8. **Handling temporal dependencies**: The solution likely involved handling temporal dependencies in the data, such as using techniques like ARIMA or LSTM to capture the temporal patterns in the data.\n",
       "9. **Handling spatial dependencies**: The solution may have involved handling spatial dependencies in the data, such as using techniques like spatial autoregressive models or spatially-aware neural networks to capture the spatial patterns in the data.\n",
       "10. **Interpretability**: The solution likely involved providing interpretability for the model's predictions, such as using techniques like partial dependence plots or SHAP values to understand how the model's predictions are influenced by the input features.\n",
       "\n",
       "By applying these key points, similar problem-solving can be approached with a structured and systematic approach, increasing the chances of success in predicting travel times or solving similar problems.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(writeup_summaries[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual input I used for Gemma is the competition description summary + competition title + writeup title + the writeup, so the actual prompt was this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are Gemma, a helpful assistant for Kaggle competitors to understand their datascience problems and propose approaches to solve them. Your points should have enough details to be useful for similar problem solving, but not excessively focused on the specific approach in writeup. More in the sense of overall application lessons for similar problems. Here is a short summary of the competition now being analyzed:\n",
       "\n",
       " description:\n",
       " The competition aims to predict travel times on Sydney's M4 freeway using historical data to improve road safety, efficiency, and inform commuters' decisions. Participants must forecast travel times for various time intervals ahead, with the goal of optimizing the road transport system and increasing functionality on the government's live traffic website.<|eot_id|>\n",
       "\n",
       "Following will be a writeup of someone who participated in this competition. List the key points of this from the datascience application viewpoint for similar problem solving.\n",
       "Writeup:\n",
       " Solution:\n",
       " For anybody interest, here's the actual solution.\n",
       "\n",
       "Answer: \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompts[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the writeup summary, Gemma seems to have again picked up parts of the competition description, and invented some possible solutions. So hallucinating, perhaps due to limited (or non-existent) writeup content. \n",
    "\n",
    "The general timeseries problem description is correct as Gemma seems to have deduced that from the competition description. The invented solutions, such as using ARIMA, seem to be halluciations. Probably from general approaches in its training data to these types of problems. Such insights might actually be useful, especially when the writeup is non-existent. But it is not what I asked for. So not entirely wrong perhaps, but misleading if we take is as is for a solution summary.\n",
    "\n",
    "So how does Gemma summarize this summary itself? Remember, the approach I trial here is to first summarize all the writeups for a competition, and from these a single overall summary. Since there is just one writeup in this competition, Gemma just tries to re-summarize its own summary now. \n",
    "\n",
    "Let's see what it says:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summary, here are the key points that can be applied to similar problem-solving:\n",
       "\n",
       "**Understanding the problem**: Identify the key factors that affect the outcome, such as traffic volume, road conditions, and time of day.\n",
       "\n",
       "**Data preparation**: Handle missing values, clean the data, and perform feature engineering to ensure accurate and reliable data.\n",
       "\n",
       "**Feature selection**: Select the most relevant features that can help predict the outcome, such as traffic volume, road conditions, time of day, and weather.\n",
       "\n",
       "**Model selection**: Choose a suitable machine learning model, such as linear regression, decision trees, random forests, or neural networks.\n",
       "\n",
       "**Hyperparameter tuning**: Optimize the model's performance using techniques like grid search, random search, or Bayesian optimization.\n",
       "\n",
       "**Model evaluation**: Use metrics like MAE, MSE, or MAPE to evaluate the model's performance and ensure accuracy and reliability.\n",
       "\n",
       "**Ensemble methods**: Combine the predictions of multiple models to improve overall performance.\n",
       "\n",
       "**Handling temporal dependencies**: Use techniques like ARIMA or LSTM to capture temporal patterns in the data.\n",
       "\n",
       "**Handling spatial dependencies**: Use techniques like spatial autoregressive models or spatially-aware neural networks to capture spatial patterns in the data.\n",
       "\n",
       "**Interpretability**: Provide interpretability for the model's predictions using techniques like partial dependence plots or SHAP values.\n",
       "\n",
       "The data analysis methods used across the writeups are:\n",
       "\n",
       "1. **Data preparation**: Handling missing values, data cleaning, and feature engineering.\n",
       "2. **Feature selection**: Selecting the most relevant features.\n",
       "3. **Model selection**: Choosing a suitable machine learning model.\n",
       "4. **Hyperparameter tuning**: Optimizing the model's performance.\n",
       "5. **Model evaluation**: Evaluating the model's performance using metrics.\n",
       "6. **Ensemble methods**: Combining the predictions of multiple models.\n",
       "7. **Handling temporal dependencies**: Capturing temporal patterns in the data.\n",
       "8. **Handling spatial dependencies**: Capturing spatial patterns in the data.\n",
       "9. **Interpretability**: Providing interpretability for the model's predictions.\n",
       "\n",
       "These methods are related across writeups in that they are all part of the data science process, from understanding the problem to evaluating the model's performance. By applying these methods, data scientists can increase the chances of success in predicting travel times or solving similar problems.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my trials, I made small typo corrections and wording changes into the overall summary prompt, and got a few different responses here due to these small changes affecting the text generation. \n",
    "\n",
    "Previously, Gemma identified the summary as general descriptions and said it was unable to give good overall summary of specific solutions, since there was no such information given. Now it seems to get more into the halluciations in the input. \n",
    "\n",
    "However, at least it has not invented things that are not in the input summary. In the previous attempt (when Gemma identified it as useless input), the input summary was much more generic. So I guess in this case I cannot blame Gemma since all this information it now gives is in the input after all. \n",
    "\n",
    "The part where it previously seemed to identify its own generic hallucinations was quite interesting though. But this input is different, so cannot say how common that result would be in such a case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall summary, competition 3\n",
    "\n",
    "This 3rd competition in the dataset has 2 writeups. One very short (20 tokens), and one longer (561 tokens). \n",
    "\n",
    "Lets see what these two writeups are, and how Gemma handles them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The solution file is attached to this post.Thanks all for participating,Anthony\\t'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeups[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Because I have recently started employment with Kaggle, I am not eligible to win any prizes. Which means the prize-winner for this comp is Quan Sun (team 'student1')! Congratulations!My approach to this competition was to first analyze the data in Excel pivottables. I looked for groups which had high or low application success rates. In this way, I found a large number of strong predictors - including by date (new years day is a strong predictor, as are applications processed on a Sunday), and for many fields a null value was highly predictive.I then used C# to normalize the data into Grants and Persons objects, and constructed a dataset for modeling including these features: CatCode, NumPerPerson, PersonId, NumOnDate, AnyHasPhd, Country, Dept, DayOfWeek, HasPhd, IsNY, Month, NoClass, NoSpons, RFCD, Role, SEO, Sponsor, ValueBand, HasID, AnyHasID, AnyHasSucc, HasSucc, People.Count, AStarPapers, APapers, BPapers, CPapers, Papers, MaxAStarPapers, MaxCPapers, MaxPapers, NumSucc, NumUnsucc, MinNumSucc, MinNumUnsucc, PctRFCD, PctSEO, MaxYearBirth, MinYearUni, YearBirth, YearUni .Most of these are fairly obvious as to what they mean. Field names starting with 'Any' are true if any person attached to the grant has that feature (e.g. 'AnyHasPhd'). For most fields I had one predictor that just looks at person 1 (e.g. 'APapers' is number of A papers from person 1), and one for the maximum of all people in the application (e.g. 'MaxAPapers').Once I had created these features, I used a generalization of the random forest algorithm to build a model. I'll try to write some detail about how this algorithm works when I have more time, but really, the difference between it and a regular random forest is not that great.I pre-processed the data before running it through the model by grouping up small groups in categorical variables, and replacing continuous columns with null values with 2 columns (one containing a binary predictor that is true only where the continuous column is null, the other containing the original column, with nulls replaced by the median). Other than the Excel pivottables at the start, all the pre-processing and modelling was done in C#, using libraries I developed during this competition. I hope to document and release these libraries at some point - perhaps after tuning them in future comps."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(writeups[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the first writeup seems to just refer to some attachment. I did now know people could do that on Kaggle. \n",
    "\n",
    "The second one has some content. So lets see how Gemma handles this combination.\n",
    "\n",
    "First the separate summary for the first writeup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup, here are the key points from a datascience application viewpoint for similar problem solving:\n",
       "\n",
       "1. **Clear goal definition**: The goal of the competition is well-defined, which is to predict the success of grant applications. This clarity helps in focusing the approach and evaluation of the solution.\n",
       "2. **Dataset availability**: The availability of a dataset (11,883 applications) provides a solid foundation for building and testing a predictive model.\n",
       "3. **Simple solution submission**: The solution file is attached to the post, indicating that the participant's approach is straightforward and easy to understand, which is important for reproducibility and collaboration.\n",
       "4. **Lack of additional information**: The writeup does not provide any additional insights or details about the solution, such as the specific algorithms used, feature engineering techniques, or hyperparameter tuning. This might be due to the simplicity of the solution or the brevity of the writeup.\n",
       "\n",
       "For similar problem solving, these key points can be applied:\n",
       "\n",
       "* Clearly define the goal and scope of the problem to focus the approach.\n",
       "* Ensure the availability of a suitable dataset for building and testing the model.\n",
       "* Keep the solution submission simple and easy to understand for reproducibility and collaboration.\n",
       "* Be prepared to provide additional details and insights about the solution, such as the algorithms used, feature engineering techniques, and hyperparameter tuning, to facilitate a deeper understanding of the approach.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(writeup_summaries[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, Gemma obviously fared better in identifying that there was no solution provided. Perhaps how the competition description was summarized leads to less likely hallucinations? This is what the prompt with the competition description summary and the writeup looked like in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are Gemma, a helpful assistant for Kaggle competitors to understand their datascience problems and propose approaches to solve them. Your points should have enough details to be useful for similar problem solving, but not excessively focused on the specific approach in writeup. More in the sense of overall application lessons for similar problems. Here is a short summary of the competition now being analyzed:\n",
       "\n",
       " description:\n",
       " The University of Melbourne is hosting a competition to predict the success of grant applications, using a dataset of 11,883 applications. The goal is to identify factors that determine success and develop a model that can accurately predict which applications are likely to succeed, reducing time wasted on unsuccessful applications.<|eot_id|>\n",
       "\n",
       "Following will be a writeup of someone who participated in this competition. List the key points of this from the datascience application viewpoint for similar problem solving.\n",
       "Writeup:\n",
       " Solution:\n",
       " The solution file is attached to this post.Thanks all for participating,Anthony\t\n",
       "\n",
       "Answer: \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompts[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the above prompt does not give any proposed solutions in the description summary, so perhaps that indeed helped Gemma avoid hallucinating the solutions.\n",
    "\n",
    "Here is the summary for the second, longer writeup, in this competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As a helpful assistant, I've extracted the key points from the writeup for similar problem-solving:\n",
       "\n",
       "1. **Initial Data Exploration**: The author started by analyzing the data in Excel pivot tables to identify groups with high or low application success rates. This step is crucial in understanding the distribution of the data and identifying potential patterns.\n",
       "2. **Feature Engineering**: The author created a large number of features by combining existing variables, such as:\n",
       "\t* Date-based features (e.g., New Year's Day, Sunday)\n",
       "\t* Field-specific features (e.g., null values, maximum values)\n",
       "\t* Person-specific features (e.g., number of papers, PhD status)\n",
       "\t* Grouping categorical variables into smaller groups\n",
       "\t* Replacing continuous columns with null values and creating binary predictors\n",
       "3. **Data Normalization**: The author used C# to normalize the data into objects (Grants and Persons) and constructed a dataset for modeling.\n",
       "4. **Modeling**: The author used a generalized random forest algorithm to build a model. The key takeaway is that the difference between this algorithm and a regular random forest is not significant.\n",
       "5. **Pre-processing**: The author pre-processed the data by grouping small groups in categorical variables and replacing continuous columns with null values with two columns (binary predictor and original column with nulls replaced by the median).\n",
       "6. **Custom Libraries**: The author developed custom libraries in C# during the competition and plans to document and release them in the future.\n",
       "\n",
       "Overall, the key takeaways for similar problem-solving are:\n",
       "\n",
       "* Perform initial data exploration to understand the distribution of the data and identify potential patterns.\n",
       "* Engage in feature engineering to create meaningful features that capture the relationships between variables.\n",
       "* Normalize the data into a suitable format for modeling.\n",
       "* Use pre-processing techniques to handle missing values, categorical variables, and other data quality issues.\n",
       "* Consider using custom libraries or developing your own algorithms to tackle specific challenges in the problem.\n",
       "\n",
       "These lessons can be applied to various data science problems, including predicting the success of grant applications, and can help you develop a robust approach to tackling similar challenges.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(writeup_summaries[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the overall summary from the combination of these two writeup summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeups, here are the key points that can be applied to similar problem-solving:\n",
       "\n",
       "**Initial Data Exploration**: Perform data exploration to understand the distribution of the data and identify potential patterns.\n",
       "\n",
       "**Feature Engineering**: Engage in feature engineering to create meaningful features that capture the relationships between variables.\n",
       "\n",
       "**Data Normalization**: Normalize the data into a suitable format for modeling.\n",
       "\n",
       "**Pre-processing**: Use pre-processing techniques to handle missing values, categorical variables, and other data quality issues.\n",
       "\n",
       "**Modeling**: Use a suitable algorithm for modeling, such as generalized random forest.\n",
       "\n",
       "**Custom Libraries**: Consider using custom libraries or developing your own algorithms to tackle specific challenges in the problem.\n",
       "\n",
       "These key points can be applied to various data science problems, including predicting the success of grant applications.\n",
       "\n",
       "The data analysis methods used across the writeups include:\n",
       "\n",
       "* Initial data exploration using Excel pivot tables\n",
       "* Feature engineering using combinations of existing variables\n",
       "* Data normalization using C# to construct a dataset for modeling\n",
       "* Pre-processing using techniques such as grouping categorical variables, replacing continuous columns with null values, and creating binary predictors\n",
       "* Modeling using a generalized random forest algorithm\n",
       "\n",
       "These methods are related across the writeups in that they all contribute to the development of a robust approach to tackling the problem. By performing initial data exploration, feature engineering, data normalization, pre-processing, and modeling, the authors were able to develop a solution that accurately predicted the success of grant applications.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This overall summary seems to be quite accurate. At least it is not picking up any hallucinations from the very short one. Probably the accuracy and lack of hallucination in the short summary helps too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summaries for Competitions with Longer and Larger Set of Writeups\n",
    "\n",
    "Most of the writeups in the above set are quite similar to the three I checked above. Most have only one writeup, and at most there are three writeups, some of which are usually quite short as well. \n",
    "\n",
    "Besides these few and short writeups, an interesting combination to check is longer writeups, and competitions with a larger set of writeups.\n",
    "\n",
    "The writeups in this dataset appear to be in chronological ordering, so the older ones (starting from year 2010) are first in the list/dataframe. The newest ones (seems to be around 2022) are last. In general it seems that over time there are more writeups for the later competitions, and often with more text. Perhaps more people on Kaggle, more writing on them, or people gaming the discussion badges more. \n",
    "\n",
    "Whatever the reason, here are the summaries for the last 20 competitions in the dataset, similar to the above first ones from the dataset (with few and shorter writeups):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf601c5493344b28f8ca7d6ed1dec4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competition Feedback Prize - Predicting Effective Arguments, writeups 19\n",
      "competition American Express - Default Prediction, writeups 31\n",
      "competition HuBMAP + HPA - Hacking the Human Body, writeups 11\n",
      "competition Mayo Clinic - STRIP AI, writeups 10\n",
      "competition Google Universal Image Embedding, writeups 16\n",
      "competition RSNA 2022 Cervical Spine Fracture Detection, writeups 18\n",
      "competition DFL - Bundesliga Data Shootout, writeups 8, no metadata\n",
      "competition AI Village Capture the Flag @ DEFCON, writeups 14\n",
      "competition Open Problems - Multimodal Single-Cell Integration, writeups 20, no metadata\n",
      "competition Feedback Prize - English Language Learning, writeups 45, no metadata\n",
      "competition Novozymes Enzyme Stability Prediction, writeups 9, no metadata\n",
      "competition G2Net Detecting Continuous Gravitational Waves, writeups 14, no metadata\n",
      "competition OTTO – Multi-Objective Recommender System, writeups 27, no metadata\n",
      "competition RSNA Screening Mammography Breast Cancer Detection, writeups 19, no metadata\n",
      "competition Santa 2022 - The Christmas Card Conundrum, writeups 5, no metadata\n",
      "competition 1st and Future - Player Contact Detection, writeups 12, no metadata\n",
      "competition Learning Equality - Curriculum Recommendations, writeups 14, no metadata\n",
      "competition IceCube - Neutrinos in Deep Ice, writeups 15, no metadata\n",
      "competition March Machine Learning Mania 2023, writeups 9, no metadata\n",
      "competition Google - Isolated Sign Language Recognition, writeups 20, no metadata\n"
     ]
    }
   ],
   "source": [
    "for competition in tqdm(competitions[-20:]):\n",
    "    df_comp = df_writeups[df_writeups[\"Title of Competition\"] == competition]\n",
    "    comp_name = df_comp[\"Title of Competition\"].iloc[0]\n",
    "    comp_meta = df_comp_meta[df_comp_meta[\"comp_name\"] == comp_name]\n",
    "    found = comp_meta.shape[0] > 0\n",
    "    if found:\n",
    "        print(f\"competition {comp_name}, writeups {df_comp.shape[0]}\")\n",
    "    else:\n",
    "        print(f\"competition {comp_name}, writeups {df_comp.shape[0]}, no metadata\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the amount of writeups these have, it takes a bit of a long time to run them all. Especially on Kaggle with the slower GPU's and limited GPU memory. So I selected a few to run here after initially trying all the 20 listed above:\n",
    "- Feedback prize: 19 writeups, the second highest in the list that has metadata\n",
    "- America Express: 31 writeups, the most writeups in list with metadata\n",
    "- Mayo Clinit: 10 writeups, least in the set with metadata\n",
    "- AI Village: 18 writeups, but with many very short ones\n",
    "\n",
    "It seems to be a decent set to compliment the earlier one with few writeups and many short ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_competitions = [\n",
    "                         \"Feedback Prize - Predicting Effective Arguments\",\n",
    "                         \"American Express - Default Prediction\",\n",
    "                         \"Mayo Clinic - STRIP AI\",\n",
    "                         \"AI Village Capture the Flag @ DEFCON\",\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: following have capped context on Kaggle due to GPU memory limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10bfb0359024fc9aee719dccd2bdce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: competition Feedback Prize - Predicting Effective Arguments, writeups 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57441f7371c04c3886b77c8d3a6f8ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping adding to overall prompt due to reaching max limit set: 7405 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7405 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7405 > 7191\n",
      "skipping overall summary for competition Feedback Prize - Predicting Effective Arguments due to too high length 7449.\n",
      "     prompt lengths=[754, 1330, 759, 789, 735, 598, 896, 2117, 1091, 2349, 705, 840, 659, 2223, 516, 737, 599, 806, 614]\n",
      "    writeup lengths=[543, 1118, 548, 576, 523, 386, 684, 1906, 879, 2137, 493, 628, 448, 2010, 305, 525, 387, 593, 402]\n",
      "    summary lengths=[445, 564, 411, 458, 442, 422, 356, 525, 425, 682, 456, 386, 396, 537, 336, 296, 485, 351, 472]\n",
      "    total writeups length:15091, overall prompt length: 7449, overall summary length: 18\n",
      "6: competition American Express - Default Prediction, writeups 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169e7d99927547aaa2f6dec10c589c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping adding to overall prompt due to reaching max limit set: 7630 > 7191\n",
      "skipping overall summary for competition American Express - Default Prediction due to too high length 7674.\n",
      "     prompt lengths=[1036, 1693, 5210, 1842, 1362, 311, 1112, 1116, 282, 298, 841, 266, 559, 1082, 995, 599, 515, 467, 683, 328, 2054, 2095, 578, 3133, 838, 990, 640, 266, 982, 608, 842]\n",
      "    writeup lengths=[841, 1498, 5015, 1646, 1167, 116, 917, 920, 88, 104, 646, 72, 364, 887, 800, 405, 321, 271, 487, 133, 1859, 1899, 383, 2938, 643, 796, 444, 72, 787, 414, 647]\n",
      "    summary lengths=[508, 389, 475, 528, 303, 307, 384, 365, 331, 432, 502, 429, 529, 520, 499, 402, 469, 357, 459, 383, 524, 494, 392, 488, 414, 508, 438, 306, 575, 441, 431]\n",
      "    total writeups length:27580, overall prompt length: 7674, overall summary length: 18\n",
      "7: competition Mayo Clinic - STRIP AI, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8170021bde4c418181c8dcefc4598bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2749, 453, 1254, 370, 724, 313, 603, 1284, 672, 465]\n",
      "    writeup lengths=[2584, 288, 1089, 205, 559, 148, 438, 1118, 507, 300]\n",
      "    summary lengths=[516, 460, 513, 472, 354, 347, 484, 408, 452, 484]\n",
      "    total writeups length:7236, overall prompt length: 4713, overall summary length: 512\n",
      "8: competition AI Village Capture the Flag @ DEFCON, writeups 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e5f5436aff4b4794304f974ece5855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[268, 304, 414, 584, 292, 1588, 388, 2192, 299, 366, 813, 426, 251, 289]\n",
      "    writeup lengths=[35, 70, 182, 351, 60, 1354, 155, 1959, 67, 134, 581, 194, 18, 57]\n",
      "    summary lengths=[397, 525, 400, 372, 369, 418, 390, 466, 426, 422, 461, 360, 551, 410]\n",
      "    total writeups length:5217, overall prompt length: 6286, overall summary length: 387\n",
      "total of 9 competitions processed\n"
     ]
    }
   ],
   "source": [
    "#summarize_competition_writeups(competitions[-20:])\n",
    "summarize_competition_writeups(selected_competitions, df_writeups, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the competition metadata I use does not have metadata for all the latest competition writeups. Its not a big deal since I can still explore the writeups with Gemma just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall about Overall Summarization\n",
    "\n",
    "As I noted, it seems the number of writeups and their length increases quite a lot over time. Here there are 10-31 writeups for the ones that I had also the metadata for. \n",
    "\n",
    "The longest combination of the writeups I checked above (American Express Default Prediction, 31 writeups) is 30k Gemma tokens in length, meaning it would not fit into Gemma's 8k window.\n",
    "\n",
    "While the 30k tokens would be too much for Gemma context window of 8k, as shown above, the combined summaries of those writeups fit in 8k (just had to cap it on Kaggle to 4k). The longest (American Express) going from 30k too 7.1k tokens with using the combined write summaries as input vs the raw writeups. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a look at the first of the resulting overall summaries. This one had 19 writeups (or their summaries) as input as seen above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skipped due to token limit (on Kaggle need shorter due to GPU memory limit)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by the longest one (American Express), which had 31 writeups, with the writeup summaries together amounting to over 7k tokens (it not capped as I had to do on Kaggle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skipped due to token limit (on Kaggle need shorter due to GPU memory limit)'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one more for the road, this time the one with fewest writeups, meaning 10 in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summaries, here are the key points that can be applied to similar problem-solving scenarios:\n",
       "\n",
       "**Common themes:**\n",
       "\n",
       "1. **Preprocessing and feature engineering**: Many writeups emphasize the importance of proper preprocessing and feature engineering techniques, such as resizing, normalization, and data augmentation.\n",
       "2. **Ensemble methods**: Combining multiple models or using ensemble methods can improve performance and reduce overfitting.\n",
       "3. **Data augmentation**: Data augmentation techniques, such as random flips, color jitter, and pixel dropout, can increase the diversity of the training data and improve model performance.\n",
       "4. **Model selection and tuning**: Selecting the best model and tuning hyperparameters are crucial steps in achieving good performance.\n",
       "5. **Experimentation and iteration**: Experimenting with different approaches and iterating on the solution are essential for finding the best approach.\n",
       "\n",
       "**Specific data analysis methods:**\n",
       "\n",
       "1. **Tile selection**: Selecting the most informative tiles from the whole slide digital pathology images can improve model performance.\n",
       "2. **Pseudo-labeling**: Creating pseudo-labels for the tiles can help in feature extraction and aggregation.\n",
       "3. **Attention pooling**: Replacing average pooling with attention pooling in the classification head can improve model performance.\n",
       "4. **Stratified splitting**: Splitting the data into training and validation sets while stratifying by class can ensure that the class distribution is preserved.\n",
       "5. **Undersampling**: Undersampling the majority class can help balance the class distribution in imbalanced datasets.\n",
       "\n",
       "**Relationship across writeups:**\n",
       "\n",
       "1. **Preprocessing and feature engineering**: Many writeups emphasize the importance of proper preprocessing and feature engineering techniques, which are essential for ensuring the model receives high-quality input data.\n",
       "2. **Ensemble methods**: Combining multiple models or using ensemble methods can improve performance and reduce overfitting, as seen in several writeups.\n",
       "3. **Data augmentation**: Data augmentation techniques, such as random flips, color jitter, and pixel dropout, can increase the diversity of the training data and improve model performance, as seen in several writeups.\n",
       "4. **Model selection and tuning**: Selecting the best model and tuning hyperparameters are crucial steps in achieving good performance, as seen in several writeups.\n",
       "5. **Experimentation and iteration**: Experimenting with different approaches and iterating on the solution are essential for finding the best approach, as seen in several writeups.\n",
       "\n",
       "By applying these key points and data analysis methods, datascientists can develop effective approaches to solve similar problems and improve their model's performance.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I can see one more interesting one in the above set. The \"AI Village Capture the Flag @ DEFCON\" competition has multiple writeups that are very short (under 100 tokens), along with a similar count of longer ones. Let's see how that looks in an overall summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summaries, I've identified the key points that can be applied to similar problem-solving challenges in datascience. Here are the key takeaways:\n",
       "\n",
       "**Common themes:**\n",
       "\n",
       "1. **Challenge-based approach**: Breaking down complex problems into smaller, manageable challenges.\n",
       "2. **Domain knowledge**: Understanding the underlying concepts and terminology of the problem domain.\n",
       "3. **Exploration and experimentation**: Trying different approaches and iterating on solutions.\n",
       "4. **Iterative approach**: Refining models and learning from mistakes.\n",
       "5. **Collaboration and sharing**: Sharing knowledge and insights with others in the datascience community.\n",
       "\n",
       "**Data analysis methods:**\n",
       "\n",
       "1. **Data exploration**: Understanding data distribution, relationships, and patterns.\n",
       "2. **Data preprocessing**: Cleaning, normalizing, and feature engineering data.\n",
       "3. **Model selection and evaluation**: Selecting the most appropriate machine learning model and evaluating its performance.\n",
       "4. **Image processing**: Manipulating and analyzing images using techniques like Fourier Transform.\n",
       "5. **Adversarial AI**: Detecting and mitigating potential attacks on machine learning models.\n",
       "\n",
       "**Relationships across writeups:**\n",
       "\n",
       "1. **Data exploration** is a common theme across writeups, highlighting the importance of understanding data characteristics.\n",
       "2. **Data preprocessing** is mentioned in several writeups, emphasizing the need to ensure data quality and consistency.\n",
       "3. **Model selection and evaluation** is a crucial step in many writeups, demonstrating the importance of evaluating model performance.\n",
       "4. **Image processing** is a key technique in several writeups, showcasing its applications in image manipulation and analysis.\n",
       "5. **Adversarial AI** is a common theme in writeups involving machine learning security challenges, highlighting the need to detect and mitigate potential attacks.\n",
       "\n",
       "By applying these key points and data analysis methods, datascience practitioners can develop effective strategies for tackling a wide range of challenges in machine learning and data analysis.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_summaries[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found this a bit confusing as it seem to discuss topics related to image processing as well as many other topics. But checking the competition description, it seems to have been a security related competition with multiple challenges related to math, natural language, and image challenges. So the overall summary seems to make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of smaller writeups mostly seem to be about referencing solutions in notebooks or otherwise. Without spamming this notebook too much, here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I've updated my solution notebook to run on Kaggle, included some descriptions of the solutions, as well as output. Hope everyone enjoys!\n",
       "Solution Code"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(writeups[8][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the large variation in the number of writeups per competition, and their length/quality, some filtering would also be in order. The ranking would be useful in cases where the number of writeups is very high at least. \n",
    "\n",
    "One interesting point about all the summaries in the first part above (the shorter and fewer writeup competitions), and the last N writeups above is the summary size. There is a broad range of input there, from 1-31 writeups per competition, to 15-30k tokens in all writeups together. Yet the summary from Gemma is almost always around the range of 100-300 tokens. Potentially it has been trained to summarize this way?\n",
    "\n",
    "The accuracy of the initial summaries across writeups of different length, and across multiple writeup summaries is something another open question. Something to investigate more in a future update to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing in Sub-Sets vs All at Once\n",
    "\n",
    "Using the initial results from this notebook, I built a [second one](https://www.kaggle.com/code/donkeys/qa-solutions-from-past-competitions) to experiment a bit with a RAG approach to help a user find interesting competitions related to the one they wish to participate in, get a summary of any writeups for that competition, and ask questions about solutions described in those writeups, using the summaries as a basis for questions and writeups as basis for more detailed answers.\n",
    "\n",
    "In trying that, I realized I wanted to have all writeups summarized regardless of how many and long writeups the competition had. In my above trials, I capped the max context length at 4k for Kaggle, and excluded some writeups if the total became too long. For example, in the above parts of this notebook it shows how the _American Express - Default Prediction_ competition had 31 writeups, and some of the were skipped beceause they did not fit in the 4k token limit I had to use on Kaggle. And even with the full 8k Gemma context, some of the ones with a really large writeup sets still get cut off on my desktop setup with more VRAM.\n",
    "\n",
    "To get even the ones with a large number of writeups summarized, I tried summarizing all writeups in several smaller sets per competition, and from the to a final summary. If this works fine, it should also work for all the writeup counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to Only Competitions with only N Writeups\n",
    "\n",
    "First to find all competitions with at least some writeups, to form a basis for what we are going to summarize all together. Well, it also allows trialing with a minimum set of writeups if wanting the see the effects better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e58ebc385044d23a166b84585e8d42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Selected Writeups: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41385691ff14e2db6b19bc158a1c50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipped (No Writeups): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72cdd67c2264c58b2df2150600c024b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipped (Too Few Writeups): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2487dd9a865b4865a095572825474698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Skipped (No Metadata): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing Chess ratings - Elo versus the Rest of the World, writeups: 5\n",
      "processing RTA Freeway Travel Time Prediction, writeups: 1\n",
      "processing Predict Grant Applications, writeups: 2\n",
      "processing IJCNN Social Network Challenge, writeups: 2\n",
      "skipping IJCNN Social Network Challenge due to no metadata\n",
      "processing Stay Alert! The Ford Challenge, writeups: 1\n",
      "processing Don't Overfit!, writeups: 1\n",
      "processing Heritage Health Prize, writeups: 1\n",
      "processing Mapping Dark Matter, writeups: 1\n",
      "processing dunnhumby's Shopper Challenge, writeups: 2\n",
      "processing Semi-Supervised Feature Learning, writeups: 1\n",
      "processing Eye Movements Verification and Identification Competition, writeups: 1\n",
      "processing Predicting a Biological Response, writeups: 1\n",
      "processing Psychopathy Prediction Based on Twitter Usage, writeups: 1\n",
      "processing Million Song Dataset Challenge, writeups: 1\n",
      "processing Online Product Sales, writeups: 1\n",
      "processing Personality Prediction Based on Twitter Stream, writeups: 1\n",
      "processing EMC Israel Data Science Challenge, writeups: 3\n",
      "processing Practice Fusion Diabetes Classification, writeups: 1\n",
      "processing EMI Music Data Science Hackathon - July 21st - 24 hours, writeups: 1\n",
      "processing Data Mining Hackathon on BIG DATA (7GB) Best Buy mobile web site, writeups: 2\n",
      "processing Raising Money to Fund an Organizational Mission, writeups: 1\n",
      "processing Data Mining Hackathon on (20 mb) Best Buy mobile web site - ACM SF Bay Area Chapter, writeups: 1\n",
      "processing Predict Closed Questions on Stack Overflow, writeups: 1\n",
      "processing Traveling Santa Problem, writeups: 3\n",
      "processing Event Recommendation Engine Challenge, writeups: 1\n",
      "processing Blue Book for Bulldozers, writeups: 1\n",
      "processing KDD Cup 2013 - Author Disambiguation Challenge (Track 2), writeups: 5\n",
      "processing Challenges in Representation Learning: The Black Box Learning Challenge, writeups: 3\n",
      "processing KDD Cup 2013 - Author-Paper Identification Challenge (Track 1), writeups: 1\n",
      "processing The ICML 2013 Whale Challenge - Right Whale Redux, writeups: 2\n",
      "processing Amazon.com - Employee Access Challenge, writeups: 3\n",
      "processing Cause-effect pairs, writeups: 1\n",
      "processing AMS 2013-2014 Solar Energy Prediction Contest, writeups: 1\n",
      "processing MLSP 2013 Bird Classification Challenge, writeups: 1\n",
      "processing Accelerometer Biometric Competition, writeups: 1\n",
      "processing StumbleUpon Evergreen Classification Challenge, writeups: 3\n",
      "processing The Big Data Combine Engineered by BattleFin, writeups: 1\n",
      "processing Personalize Expedia Hotel Searches - ICDM 2013, writeups: 1\n",
      "processing See Click Predict Fix - Hackathon, writeups: 1\n",
      "processing See Click Predict Fix, writeups: 3\n",
      "processing Multi-label Bird Species Classification - NIPS 2013, writeups: 1\n",
      "processing Personalized Web Search Challenge, writeups: 1\n",
      "processing Galaxy Zoo - The Galaxy Challenge, writeups: 1\n",
      "processing Large Scale Hierarchical Text Classification, writeups: 1\n",
      "processing CONNECTOMICS, writeups: 6\n",
      "processing Allstate Purchase Prediction Challenge, writeups: 1\n",
      "processing DecMeg2014 - Decoding the Human Brain, writeups: 1\n",
      "processing Higgs Boson Machine Learning Challenge, writeups: 4\n",
      "processing Acquire Valued Shoppers Challenge, writeups: 1\n",
      "processing KDD Cup 2014 - Predicting Excitement at DonorsChoose.org, writeups: 1\n",
      "processing Greek Media Monitoring Multilabel Classification (WISE 2014), writeups: 2\n",
      "processing MLSP 2014 Schizophrenia Classification Challenge, writeups: 4\n",
      "processing UPenn and Mayo Clinic's Seizure Detection Challenge, writeups: 2\n",
      "processing Liberty Mutual Group - Fire Peril Loss Cost, writeups: 1\n",
      "processing Display Advertising Challenge, writeups: 3\n",
      "processing American Epilepsy Society Seizure Prediction Challenge, writeups: 5\n",
      "processing Africa Soil Property Prediction Challenge, writeups: 5\n",
      "skipping Africa Soil Property Prediction Challenge due to no metadata\n",
      "processing Tradeshift Text Classification, writeups: 1\n",
      "processing Click-Through Rate Prediction, writeups: 1\n",
      "processing BCI Challenge @ NER 2015, writeups: 2\n",
      "processing Helping Santa's Helpers, writeups: 2\n",
      "processing National Data Science Bowl, writeups: 6\n",
      "processing Driver Telematics Analysis, writeups: 1\n",
      "processing Microsoft Malware Classification Challenge (BIG 2015), writeups: 6\n",
      "processing How Much Did It Rain?, writeups: 1\n",
      "processing Otto Group Product Classification Challenge, writeups: 4\n",
      "processing Restaurant Revenue Prediction, writeups: 1\n",
      "processing Diabetic Retinopathy Detection, writeups: 7\n",
      "processing ECML/PKDD 15: Taxi Trajectory Prediction (I), writeups: 2\n",
      "processing West Nile Virus Prediction, writeups: 2\n",
      "processing Crowdflower Search Results Relevance, writeups: 4\n",
      "processing ECML/PKDD 15: Taxi Trip Time Prediction (II), writeups: 2\n",
      "processing ICDM 2015: Drawbridge Cross-Device Connections, writeups: 2\n",
      "processing Machinery Tube Pricing, writeups: 1\n",
      "processing Liberty Mutual Group: Property Inspection Prediction, writeups: 4\n",
      "processing Grasp-and-Lift EEG Detection, writeups: 3\n",
      "processing Avito Context Ad Clicks, writeups: 1\n",
      "processing Flavours of Physics: Finding τ  →  μμμ, writeups: 5\n",
      "processing Springleaf Marketing Response, writeups: 3\n",
      "processing Right Whale Recognition, writeups: 2\n",
      "processing The Allen AI Science Challenge, writeups: 1\n",
      "processing Rossmann Store Sales, writeups: 4\n",
      "processing Santa's Stolen Sleigh, writeups: 4\n",
      "processing Prudential Life Insurance Assessment, writeups: 4\n",
      "processing Second Annual Data Science Bowl, writeups: 11\n",
      "processing BNP Paribas Cardif Claims Management, writeups: 3\n",
      "processing Santander Customer Satisfaction, writeups: 8\n",
      "processing Home Depot Product Search Relevance, writeups: 1\n",
      "processing State Farm Distracted Driver Detection, writeups: 4\n",
      "processing Expedia Hotel Recommendations, writeups: 2\n",
      "processing Avito Duplicate Ads Detection, writeups: 2\n",
      "processing Draper Satellite Image Chronology, writeups: 2\n",
      "processing Ultrasound Nerve Segmentation, writeups: 2\n",
      "processing Grupo Bimbo Inventory Demand, writeups: 5\n",
      "processing TalkingData Mobile User Demographics, writeups: 4\n",
      "processing Predicting Red Hat Business Value, writeups: 5\n",
      "processing Melbourne University AES/MathWorks/NIH Seizure Prediction, writeups: 5\n",
      "processing Bosch Production Line Performance, writeups: 5\n",
      "processing Outbrain Click Prediction, writeups: 5\n",
      "processing Santander Product Recommendation, writeups: 13\n",
      "processing Two Sigma Financial Modeling Challenge, writeups: 3\n",
      "processing Dstl Satellite Imagery Feature Detection, writeups: 9\n",
      "processing Data Science Bowl 2017, writeups: 5\n",
      "processing Google Cloud & YouTube-8M Video Understanding Challenge, writeups: 7\n",
      "processing The Nature Conservancy Fisheries Monitoring, writeups: 1\n",
      "processing Intel & MobileODT Cervical Cancer Screening, writeups: 11\n",
      "processing Quora Question Pairs, writeups: 13\n",
      "processing NOAA Fisheries Steller Sea Lion Population Count, writeups: 11\n",
      "processing Planet: Understanding the Amazon from Space, writeups: 9\n",
      "processing Sberbank Russian Housing Market, writeups: 7\n",
      "processing Instacart Market Basket Analysis, writeups: 14\n",
      "processing Mercedes-Benz Greener Manufacturing, writeups: 7\n",
      "processing iNaturalist Challenge at FGVC 2017, writeups: 1\n",
      "processing NIPS 2017: Non-targeted Adversarial Attack, writeups: 3\n",
      "processing Web Traffic Time Series Forecasting, writeups: 6\n",
      "processing Zillow Prize: Zillow’s Home Value Prediction (Zestimate), writeups: 2\n",
      "processing Carvana Image Masking Challenge, writeups: 7\n",
      "processing Passenger Screening Algorithm Challenge, writeups: 1\n",
      "processing NIPS 2017: Targeted Adversarial Attack, writeups: 1\n",
      "processing NIPS 2017: Defense Against Adversarial Attack, writeups: 1\n",
      "processing Text Normalization Challenge - English Language, writeups: 4\n",
      "processing Text Normalization Challenge - Russian Language, writeups: 4\n",
      "processing Cdiscount’s Image Classification Challenge, writeups: 7\n",
      "processing WSDM - KKBox's Music Recommendation Challenge, writeups: 3\n",
      "processing Porto Seguro’s Safe Driver Prediction, writeups: 17\n",
      "processing Corporación Favorita Grocery Sales Forecasting, writeups: 16\n",
      "processing Statoil/C-CORE Iceberg Classifier Challenge, writeups: 9\n",
      "processing TensorFlow Speech Recognition Challenge, writeups: 10\n",
      "processing Mercari Price Suggestion Challenge, writeups: 12\n",
      "processing WSDM - KKBox's Churn Prediction Challenge, writeups: 1\n",
      "processing Recruit Restaurant Visitor Forecasting, writeups: 11\n",
      "processing Santa Gift Matching Challenge, writeups: 5\n",
      "processing Toxic Comment Classification Challenge, writeups: 13\n",
      "processing Nomad2018 Predicting Transparent Conductors, writeups: 5\n",
      "processing IEEE's Signal Processing Society - Camera Model Identification, writeups: 11\n",
      "processing 2018 Data Science Bowl, writeups: 12\n",
      "skipping 2018 Data Science Bowl due to no metadata\n",
      "processing Google Landmark Recognition Challenge, writeups: 6\n",
      "processing Google Landmark Retrieval Challenge, writeups: 4\n",
      "processing TalkingData AdTracking Fraud Detection Challenge, writeups: 20\n",
      "processing iMaterialist Challenge (Furniture) at FGVC5, writeups: 2\n",
      "processing Google Cloud & NCAA® ML Competition 2018-Women's, writeups: 1\n",
      "processing iMaterialist Challenge (Fashion) at FGVC5, writeups: 3\n",
      "processing CVPR 2018 WAD Video Segmentation Challenge, writeups: 3\n",
      "processing Freesound General-Purpose Audio Tagging Challenge, writeups: 3\n",
      "processing Avito Demand Prediction Challenge, writeups: 22\n",
      "processing TrackML Particle Tracking Challenge, writeups: 12\n",
      "processing Home Credit Default Risk, writeups: 22\n",
      "processing The 2nd YouTube-8M Video Understanding Challenge, writeups: 2\n",
      "processing Santander Value Prediction Challenge, writeups: 15\n",
      "processing Google AI Open Images - Object Detection Track, writeups: 7\n",
      "processing Google AI Open Images - Visual Relationship Track, writeups: 6\n",
      "processing TGS Salt Identification Challenge, writeups: 26\n",
      "processing Airbus Ship Detection Challenge, writeups: 9\n",
      "processing RSNA Pneumonia Detection Challenge, writeups: 13\n",
      "processing Inclusive Images Challenge, writeups: 6\n",
      "processing Google Analytics Customer Revenue Prediction, writeups: 10\n",
      "processing Quick, Draw! Doodle Recognition Challenge, writeups: 11\n",
      "processing PLAsTiCC Astronomical Classification, writeups: 16\n",
      "processing Human Protein Atlas Image Classification, writeups: 20\n",
      "processing Two Sigma: Using News to Predict Stock Movements, writeups: 1\n",
      "processing Quora Insincere Questions Classification, writeups: 22\n",
      "processing Traveling Santa 2018 - Prime Paths, writeups: 5\n",
      "processing Elo Merchant Category Recommendation, writeups: 18\n",
      "processing Humpback Whale Identification, writeups: 18\n",
      "processing Microsoft Malware Prediction, writeups: 13\n",
      "processing VSB Power Line Fault Detection, writeups: 14\n",
      "processing PetFinder.my Adoption Prediction, writeups: 11\n",
      "processing LANL Earthquake Prediction, writeups: 29\n",
      "processing Gendered Pronoun Resolution, writeups: 15\n",
      "processing Santander Customer Transaction Prediction, writeups: 32\n",
      "processing Google Cloud & NCAA® ML Competition 2019-Women's, writeups: 8\n",
      "processing Google Cloud & NCAA® ML Competition 2019-Men's, writeups: 5\n",
      "processing iMet Collection 2019 - FGVC6, writeups: 10\n",
      "processing Jigsaw Unintended Bias in Toxicity Classification, writeups: 24\n",
      "processing Freesound Audio Tagging 2019, writeups: 18\n",
      "processing Google Landmark Retrieval 2019, writeups: 8\n",
      "processing Google Landmark Recognition 2019, writeups: 9\n",
      "processing iMaterialist (Fashion) 2019 at FGVC6, writeups: 5\n",
      "skipping iMaterialist (Fashion) 2019 at FGVC6 due to no metadata\n",
      "processing Instant Gratification, writeups: 19\n",
      "processing Predicting Molecular Properties, writeups: 26\n",
      "processing Open Images 2019 - Object Detection, writeups: 7\n",
      "processing Open Images 2019 - Visual Relationship, writeups: 2\n",
      "processing SIIM-ACR Pneumothorax Segmentation, writeups: 16\n",
      "processing The 3rd YouTube-8M Video Understanding Challenge, writeups: 10\n",
      "processing Recursion Cellular Image Classification, writeups: 19\n",
      "processing APTOS 2019 Blindness Detection, writeups: 33\n",
      "processing Generative Dog Images, writeups: 12\n",
      "processing Open Images 2019 - Instance Segmentation, writeups: 5\n",
      "processing IEEE-CIS Fraud Detection, writeups: 24\n",
      "processing Severstal: Steel Defect Detection, writeups: 20\n",
      "processing Understanding Clouds from Satellite Images, writeups: 22\n",
      "processing Lyft 3D Object Detection for Autonomous Vehicles, writeups: 7\n",
      "processing RSNA Intracranial Hemorrhage Detection, writeups: 17\n",
      "processing NFL Big Data Bowl, writeups: 26\n",
      "processing ASHRAE - Great Energy Predictor III, writeups: 18\n",
      "processing Peking University/Baidu - Autonomous Driving, writeups: 6\n",
      "processing 2019 Data Science Bowl, writeups: 24\n",
      "processing TensorFlow 2.0 Question Answering, writeups: 19\n",
      "processing Google QUEST Q&A Labeling, writeups: 35\n",
      "processing Santa's Workshop Tour 2019, writeups: 5\n",
      "processing Deepfake Detection Challenge, writeups: 17\n",
      "processing Bengali.AI Handwritten Grapheme Classification, writeups: 28\n",
      "processing Abstraction and Reasoning Challenge, writeups: 11\n",
      "processing University of Liverpool - Ion Switching, writeups: 25\n",
      "processing M5 Forecasting - Accuracy, writeups: 36\n",
      "processing M5 Forecasting - Uncertainty, writeups: 11\n",
      "processing Herbarium 2020 - FGVC7, writeups: 6\n",
      "processing Plant Pathology 2020 - FGVC7, writeups: 12\n",
      "processing iWildCam 2020 - FGVC7, writeups: 5\n",
      "processing COVID19 Local US-CA Forecasting (Week 1), writeups: 1\n",
      "processing Jigsaw Multilingual Toxic Comment Classification, writeups: 19\n",
      "processing Tweet Sentiment Extraction, writeups: 21\n",
      "processing iMaterialist (Fashion) 2020 at FGVC7, writeups: 1\n",
      "skipping iMaterialist (Fashion) 2020 at FGVC7 due to no metadata\n",
      "processing COVID19 Global Forecasting (Week 4), writeups: 10\n",
      "processing COVID19 Global Forecasting (Week 5), writeups: 10\n",
      "processing Prostate cANcer graDe Assessment (PANDA) Challenge, writeups: 21\n",
      "processing TReNDS Neuroimaging, writeups: 23\n",
      "processing ALASKA2 Image Steganalysis, writeups: 13\n",
      "processing Global Wheat Detection, writeups: 15\n",
      "skipping Global Wheat Detection due to no metadata\n",
      "processing SIIM-ISIC Melanoma Classification, writeups: 30\n",
      "processing Cornell Birdcall Identification, writeups: 21\n",
      "processing Halite by Two Sigma, writeups: 4\n",
      "processing Google Landmark Retrieval 2020, writeups: 8\n",
      "processing OSIC Pulmonary Fibrosis Progression, writeups: 21\n",
      "processing Google Landmark Recognition 2020, writeups: 10\n",
      "processing Lyft Motion Prediction for Autonomous Vehicles, writeups: 15\n",
      "processing Mechanisms of Action (MoA) Prediction, writeups: 30\n",
      "processing RSNA STR Pulmonary Embolism Detection, writeups: 17\n",
      "processing OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction, writeups: 25\n",
      "processing Google Research Football with Manchester City F.C., writeups: 5\n",
      "processing Riiid Answer Correctness Prediction, writeups: 37\n",
      "processing NFL 1st and Future - Impact Detection, writeups: 16\n",
      "processing HuBMAP - Hacking the Kidney, writeups: 17\n",
      "processing Rainforest Connection Species Audio Detection, writeups: 23\n",
      "processing Cassava Leaf Disease Classification, writeups: 41\n",
      "processing Jane Street Market Prediction, writeups: 10\n",
      "processing Santa 2020 - The Candy Cane Contest, writeups: 4\n",
      "processing RANZCR CLiP - Catheter and Line Position Challenge, writeups: 26\n",
      "processing VinBigData Chest X-ray Abnormalities Detection, writeups: 14\n",
      "processing Human Protein Atlas - Single Cell Classification, writeups: 30\n",
      "processing Indoor Location & Navigation, writeups: 22\n",
      "processing Bristol-Myers Squibb – Molecular Translation, writeups: 18\n",
      "processing Shopee - Price Match Guarantee, writeups: 32\n",
      "processing Hotel-ID to Combat Human Trafficking 2021 - FGVC8, writeups: 3\n",
      "processing Herbarium 2021 - Half-Earth Challenge - FGVC8, writeups: 1\n",
      "processing iWildcam 2021 - FGVC8, writeups: 5\n",
      "processing Plant Pathology 2021 - FGVC8, writeups: 3\n",
      "skipping Plant Pathology 2021 - FGVC8 due to no metadata\n",
      "processing Coleridge Initiative - Show US the Data, writeups: 22\n",
      "skipping Coleridge Initiative - Show US the Data due to no metadata\n",
      "processing BirdCLEF 2021 - Birdcall Identification, writeups: 19\n",
      "processing CommonLit Readability Prize, writeups: 30\n",
      "processing SETI Breakthrough Listen - E.T. Signal Search, writeups: 17\n",
      "processing Google Smartphone Decimeter Challenge, writeups: 12\n",
      "processing SIIM-FISABIO-RSNA COVID-19 Detection, writeups: 19\n",
      "processing MLB Player Digital Engagement Forecasting, writeups: 9\n",
      "processing Optiver Realized Volatility Prediction, writeups: 14\n",
      "processing G2Net Gravitational Wave Detection, writeups: 19\n",
      "processing RSNA-MICCAI Brain Tumor Radiogenomic Classification, writeups: 15\n",
      "processing NFL Health & Safety - Helmet Assignment, writeups: 14\n",
      "processing Google Landmark Retrieval 2021, writeups: 7\n",
      "processing Google Landmark Recognition 2021, writeups: 5\n",
      "processing chaii - Hindi and Tamil Question Answering, writeups: 28\n",
      "processing Lux AI, writeups: 4\n",
      "processing Google Brain - Ventilator Pressure Prediction, writeups: 15\n",
      "processing PetFinder.my - Pawpularity Contest, writeups: 27\n",
      "processing Sartorius - Cell Instance Segmentation, writeups: 11\n",
      "processing G-Research Crypto Forecasting, writeups: 8\n",
      "skipping G-Research Crypto Forecasting due to no metadata\n",
      "processing Jigsaw Rate Severity of Toxic Comments, writeups: 33\n",
      "skipping Jigsaw Rate Severity of Toxic Comments due to no metadata\n",
      "processing Santa 2021 - The Merry Movie Montage, writeups: 16\n",
      "processing TensorFlow - Help Protect the Great Barrier Reef, writeups: 21\n",
      "skipping TensorFlow - Help Protect the Great Barrier Reef due to no metadata\n",
      "processing Feedback Prize - Evaluating Student Writing, writeups: 17\n",
      "processing Ubiquant Market Prediction, writeups: 7\n",
      "processing Happywhale - Whale and Dolphin Identification, writeups: 21\n",
      "processing NBME - Score Clinical Patient Notes, writeups: 22\n",
      "processing H&M Personalized Fashion Recommendations, writeups: 23\n",
      "processing BirdCLEF 2022, writeups: 21\n",
      "processing March Machine Learning Mania 2022 - Women's, writeups: 8\n",
      "processing March Machine Learning Mania 2022 - Men’s, writeups: 8\n",
      "processing GeoLifeCLEF 2022 - LifeCLEF 2022 x FGVC9, writeups: 2\n",
      "processing Hotel-ID to Combat Human Trafficking 2022 - FGVC9, writeups: 3\n",
      "processing Sorghum -100 Cultivar Identification - FGVC 9, writeups: 3\n",
      "processing U.S. Patent Phrase to Phrase Matching, writeups: 17\n",
      "skipping U.S. Patent Phrase to Phrase Matching due to no metadata\n",
      "processing iWildCam 2022 - FGVC9, writeups: 2\n",
      "processing Image Matching Challenge 2022, writeups: 21\n",
      "processing JPX Tokyo Stock Exchange Prediction, writeups: 6\n",
      "processing Kore 2022, writeups: 9\n",
      "processing Foursquare - Location Matching, writeups: 17\n",
      "processing UW-Madison GI Tract Image Segmentation, writeups: 19\n",
      "skipping UW-Madison GI Tract Image Segmentation due to no metadata\n",
      "processing Herbarium 2022 - FGVC9, writeups: 1\n",
      "processing Google Smartphone Decimeter Challenge 2022, writeups: 11\n",
      "processing Google AI4Code – Understand Code in Python Notebooks, writeups: 20\n",
      "skipping Google AI4Code – Understand Code in Python Notebooks due to no metadata\n",
      "processing Feedback Prize - Predicting Effective Arguments, writeups: 19\n",
      "processing American Express - Default Prediction, writeups: 31\n",
      "processing HuBMAP + HPA - Hacking the Human Body, writeups: 11\n",
      "processing Mayo Clinic - STRIP AI, writeups: 10\n",
      "processing Google Universal Image Embedding, writeups: 16\n",
      "processing RSNA 2022 Cervical Spine Fracture Detection, writeups: 18\n",
      "processing DFL - Bundesliga Data Shootout, writeups: 8\n",
      "skipping DFL - Bundesliga Data Shootout due to no metadata\n",
      "processing AI Village Capture the Flag @ DEFCON, writeups: 14\n",
      "processing Open Problems - Multimodal Single-Cell Integration, writeups: 20\n",
      "skipping Open Problems - Multimodal Single-Cell Integration due to no metadata\n",
      "processing Feedback Prize - English Language Learning, writeups: 45\n",
      "skipping Feedback Prize - English Language Learning due to no metadata\n",
      "processing Novozymes Enzyme Stability Prediction, writeups: 9\n",
      "skipping Novozymes Enzyme Stability Prediction due to no metadata\n",
      "processing G2Net Detecting Continuous Gravitational Waves, writeups: 14\n",
      "skipping G2Net Detecting Continuous Gravitational Waves due to no metadata\n",
      "processing OTTO – Multi-Objective Recommender System, writeups: 27\n",
      "skipping OTTO – Multi-Objective Recommender System due to no metadata\n",
      "processing RSNA Screening Mammography Breast Cancer Detection, writeups: 19\n",
      "skipping RSNA Screening Mammography Breast Cancer Detection due to no metadata\n",
      "processing Santa 2022 - The Christmas Card Conundrum, writeups: 5\n",
      "skipping Santa 2022 - The Christmas Card Conundrum due to no metadata\n",
      "processing 1st and Future - Player Contact Detection, writeups: 12\n",
      "skipping 1st and Future - Player Contact Detection due to no metadata\n",
      "processing Learning Equality - Curriculum Recommendations, writeups: 14\n",
      "skipping Learning Equality - Curriculum Recommendations due to no metadata\n",
      "processing IceCube - Neutrinos in Deep Ice, writeups: 15\n",
      "skipping IceCube - Neutrinos in Deep Ice due to no metadata\n",
      "processing March Machine Learning Mania 2023, writeups: 9\n",
      "skipping March Machine Learning Mania 2023 due to no metadata\n",
      "processing Google - Isolated Sign Language Recognition, writeups: 20\n",
      "skipping Google - Isolated Sign Language Recognition due to no metadata\n"
     ]
    }
   ],
   "source": [
    "writeups = []\n",
    "used_names = []\n",
    "skipped_names_empty = []\n",
    "skipped_names_few = []\n",
    "# writeups need metadata to have a description that I use for the summary\n",
    "skipped_names_nometa = []\n",
    "\n",
    "pbar_selected = tqdm(total=0, desc=\"Selected Writeups\")\n",
    "pbar_skipped_empty = tqdm(total=0, desc=\"Skipped (No Writeups)\")\n",
    "pbar_skipped_few = tqdm(total=0, desc=\"Skipped (Too Few Writeups)\")\n",
    "pbar_skipped_nometa = tqdm(total=0, desc=\"Skipped (No Metadata)\")\n",
    "\n",
    "#if on_kaggle:\n",
    "#    comps_to_find = 20\n",
    "#else:\n",
    "#    # should be all\n",
    "#    comps_to_find = 10000\n",
    "\n",
    "for idx, name in enumerate(competitions):\n",
    "    comp_writeups = df_writeups[df_writeups[\"Title of Competition\"] == name]\n",
    "    print(f\"processing {name}, writeups: {comp_writeups.shape[0]}\")\n",
    "    if len(comp_writeups) == 0:\n",
    "        print(f\"skipping {name} due to no writeups\")\n",
    "        skipped_names_empty.append(name)\n",
    "        pbar_skipped_empty.update(1)\n",
    "        continue\n",
    "    comp_meta = df_comp_meta[df_comp_meta[\"comp_name\"] == name]\n",
    "    found = comp_meta.shape[0] > 0\n",
    "    if not found:\n",
    "        print(f\"skipping {name} due to no metadata\")\n",
    "        skipped_names_nometa.append(name)\n",
    "        pbar_skipped_nometa.update(1)\n",
    "        continue\n",
    "        \n",
    "    #if len(comp_writeups) < 5:\n",
    "    #    #print(f\"skipping {name} due to too few writeups\")\n",
    "    #    skipped_names_few.append(name)\n",
    "    #    pbar_skipped_few.update(1)\n",
    "    #    continue    \n",
    "    used_names.append(name)\n",
    "    writeups.append(comp_writeups)\n",
    "    pbar_selected.update(1)\n",
    "#    if len(used_names) >= comps_to_find:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above illustrates also, how the latter competitions have much more writeups.\n",
    "\n",
    "## Split Large Writeup Sets to Smaller Ones\n",
    "\n",
    "Now a helper function to split a large set of writeups into somewhat even size subsets. So we dont end up with subsets with sizes like [10, 10, 10, 1]. Rather in such case [10, 10, 6, 5] so there is enough summarizing for everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(data, max_sublist_size):\n",
    "  sublists = []\n",
    "  current_sublist = []\n",
    "  for idx, item in data.iterrows():\n",
    "    if len(current_sublist) < max_sublist_size:\n",
    "      current_sublist.append(item)\n",
    "    else:\n",
    "      sublists.append(current_sublist)\n",
    "      current_sublist = [item]\n",
    "  # Add the last sublist, even if it's shorter than max_sublist_size\n",
    "  sublists.append(current_sublist)\n",
    "\n",
    "  # Ensure the last sublists are more evenly distributed\n",
    "  last_sublists = sublists[-2:]  # Get the last two sublists\n",
    "  total_length = sum(len(sublist) for sublist in last_sublists)\n",
    "  ideal_length = total_length // len(last_sublists)\n",
    "\n",
    "  # Distribute elements until a balanced state is achieved\n",
    "  while len(last_sublists[0]) > ideal_length and len(last_sublists) > 1:\n",
    "      #print(len(last_sublists[0]))\n",
    "      last_sublists[1].append(last_sublists[0].pop(0))\n",
    "\n",
    "  # If there are still more elements in the second-to-last sublist, distribute to previous ones\n",
    "  if len(last_sublists) > 1 and len(last_sublists[1]) > ideal_length:\n",
    "    for i in range(len(sublists) - 2, 0, -1):\n",
    "      if len(sublists[i]) < max_sublist_size:\n",
    "        sublists[i].append(last_sublists[1].pop(0))\n",
    "        break\n",
    "\n",
    "  return sublists\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the above helper to actually split the writeups into more even size subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeup_dataframes = []\n",
    "\n",
    "#N = 5\n",
    "N = 10\n",
    "#N = \"ALL\"\n",
    "\n",
    "split_size = N\n",
    "\n",
    "# ALL just refers to summarizing all together, so no need for subsets then\n",
    "# it is what I used for the desktop env where I ran full summaries for comparison\n",
    "if N == \"ALL\":\n",
    "    N2 = 10000\n",
    "else:\n",
    "    N2 = N\n",
    "if True:\n",
    "    for comp_writeups in writeups:\n",
    "        writeups_sublists = split_list(comp_writeups, N2)\n",
    "        #print([len(sub) for sub in writeups_sublists])\n",
    "        writeups_subframes = [pd.DataFrame(sub) for sub in writeups_sublists]\n",
    "        #print([subframe.shape[0] for subframe in writeups_subframes])\n",
    "        writeup_dataframes.append(writeups_subframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Writeups for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new list of writeup dataframes filtering out all writeups for competitions in skipped_titles\n",
    "writeup_dataframes_filtered = []\n",
    "names_filtered = []\n",
    "for idx, comp_dataframes in enumerate(writeup_dataframes):\n",
    "    comp_name = comp_dataframes[0][\"Title of Competition\"].iloc[0]\n",
    "    if comp_name in skipped_titles:\n",
    "        continue\n",
    "    names_filtered.append(comp_name)\n",
    "    writeup_dataframes_filtered.append(comp_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dataframes in the writeup_dataframes list into a single dataframe\n",
    "# just useful when summarizing all together for a competition\n",
    "df_writeups_all = pd.concat([df for sublist in writeup_dataframes_filtered for df in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skipped_names_nometa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "(2725, 8)\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "# these are just to check up the filtering is OK. \n",
    "# Previous filtering has given 310-27=283 competitions left, so thats the number needed here\n",
    "print(len(writeup_dataframes_filtered))\n",
    "print(df_writeups_all.shape)\n",
    "print(df_writeups_all[\"Title of Competition\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the Selected Writeups as Input for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have to reset the lists to not pollute with previous experiments in this notebook\n",
    "writeup_summaries = []\n",
    "writeup_summaries_md = []\n",
    "overall_summaries = []\n",
    "processed_titles = set()\n",
    "processed_titles_list = []\n",
    "skipped_titles = set()\n",
    "skipped_titles_list = []\n",
    "overall_summary_prompts = []\n",
    "prompts = []\n",
    "writeups = []\n",
    "prompt_lengths = []\n",
    "writeup_lengths = []\n",
    "summary_lengths = []\n",
    "final_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7c919e7c064f9fb1a7433390530bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f990112d0a41eaae29ff4e197899db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378: competition Google Landmark Retrieval 2021, writeups 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637876c8aa56422bb71b9cd71a265722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1269, 561, 2289, 1052, 2105, 975, 1838]\n",
      "    writeup lengths=[1095, 386, 2114, 878, 1931, 801, 1664]\n",
      "    summary lengths=[454, 436, 482, 431, 519, 433, 760]\n",
      "    total writeups length:8869, overall prompt length: 3726, overall summary length: 563\n",
      "total of 379 competitions processed\n",
      "251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7e0bbf33d14b8c829cb824e549c0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379: competition Google Landmark Recognition 2021, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73919c5121e84637a2cea85cafd503f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[498, 2171, 1423, 1040, 1037]\n",
      "    writeup lengths=[307, 1979, 1231, 849, 846]\n",
      "    summary lengths=[383, 479, 452, 490, 437]\n",
      "    total writeups length:5212, overall prompt length: 2455, overall summary length: 588\n",
      "total of 380 competitions processed\n",
      "252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0452f4b2573458bb6a9e1392ca2f4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380: competition chaii - Hindi and Tamil Question Answering, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b69e9a7d1404dcfb22dcb142e61f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1524, 2403, 1675, 1312, 495, 1271, 954, 1760, 801, 870]\n",
      "    writeup lengths=[1322, 2201, 1474, 1111, 294, 1070, 753, 1561, 599, 669]\n",
      "    summary lengths=[489, 406, 462, 423, 488, 329, 439, 491, 373, 490]\n",
      "    total writeups length:11054, overall prompt length: 4649, overall summary length: 402\n",
      "total of 381 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dbd660752049409918161d274b57f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381: competition chaii - Hindi and Tamil Question Answering, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f795241c8b42c1917c31ef98026f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1115, 1456, 372, 1170, 1030, 658, 1006, 722, 807]\n",
      "    writeup lengths=[913, 1255, 171, 968, 829, 457, 805, 521, 605]\n",
      "    summary lengths=[430, 438, 317, 446, 375, 485, 399, 422, 462]\n",
      "    total writeups length:6524, overall prompt length: 4026, overall summary length: 490\n",
      "total of 382 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3bc66044e64699a952115a328c7c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382: competition chaii - Hindi and Tamil Question Answering, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a81ef0939742d2870eafe6130c0fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[636, 621, 978, 1958, 962, 494, 764, 575, 348]\n",
      "    writeup lengths=[435, 421, 776, 1757, 761, 293, 563, 374, 147]\n",
      "    summary lengths=[445, 420, 347, 475, 430, 455, 389, 401, 405]\n",
      "    total writeups length:5527, overall prompt length: 4019, overall summary length: 518\n",
      "total of 383 competitions processed\n",
      "253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276a634d6ac94756bdcbe37a465bf0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383: competition Lux AI, writeups 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbafbaa98e34e2d833b32a42ffb6c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[4509, 600, 900, 645]\n",
      "    writeup lengths=[4321, 413, 713, 458]\n",
      "    summary lengths=[483, 505, 468, 499]\n",
      "    total writeups length:5905, overall prompt length: 2159, overall summary length: 550\n",
      "total of 384 competitions processed\n",
      "254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaa64c4bc90423fb830c0108d7f2389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384: competition Google Brain - Ventilator Pressure Prediction, writeups 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cdda52076d47839501aabad0d3189d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1865, 994, 459, 3182, 1154, 967, 1360]\n",
      "    writeup lengths=[1664, 791, 257, 2981, 951, 765, 1159]\n",
      "    summary lengths=[529, 445, 385, 607, 453, 460, 391]\n",
      "    total writeups length:8568, overall prompt length: 3509, overall summary length: 781\n",
      "total of 385 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9e937630794b06bc72a0996efb21eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385: competition Google Brain - Ventilator Pressure Prediction, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513ba862140e4e918bd68594dc5ef0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1293, 275, 2935, 1862, 802, 382, 877, 434]\n",
      "    writeup lengths=[1091, 73, 2734, 1660, 601, 180, 676, 233]\n",
      "    summary lengths=[455, 509, 429, 447, 528, 365, 451, 388]\n",
      "    total writeups length:7248, overall prompt length: 3818, overall summary length: 1000\n",
      "total of 386 competitions processed\n",
      "255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34b65aa32ba401b92d2c19429b24e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386: competition PetFinder.my - Pawpularity Contest, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45449ba0c24c48e385057d54cbc832db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[411, 558, 459, 533, 838, 805, 1513, 1272, 593, 631]\n",
      "    writeup lengths=[228, 374, 276, 351, 654, 622, 1329, 1090, 409, 448]\n",
      "    summary lengths=[456, 444, 446, 298, 486, 379, 479, 487, 450, 473]\n",
      "    total writeups length:5781, overall prompt length: 4639, overall summary length: 501\n",
      "total of 387 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cf95efc9ef4a9cbf233a9b55697cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387: competition PetFinder.my - Pawpularity Contest, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88edbc74594b459d96d03db2ace1c364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[558, 248, 1551, 570, 604, 423, 282, 400, 433]\n",
      "    writeup lengths=[374, 66, 1369, 387, 419, 242, 99, 217, 251]\n",
      "    summary lengths=[445, 374, 523, 343, 528, 405, 389, 480, 391]\n",
      "    total writeups length:3424, overall prompt length: 4112, overall summary length: 477\n",
      "total of 388 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a6902215274c0f98fc3b545f446124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388: competition PetFinder.my - Pawpularity Contest, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f08511a66543ad85188f95be3fc37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[940, 1690, 1294, 553, 853, 980, 793, 979]\n",
      "    writeup lengths=[757, 1508, 1113, 369, 669, 797, 610, 796]\n",
      "    summary lengths=[616, 511, 368, 515, 436, 475, 524, 423]\n",
      "    total writeups length:6619, overall prompt length: 4095, overall summary length: 553\n",
      "total of 389 competitions processed\n",
      "256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca42a5fd77a4a80a5b75c7f4a63297e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389: competition Sartorius - Cell Instance Segmentation, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211d1c7645414265b2dec5e50d862668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[508, 415, 2120, 475, 661]\n",
      "    writeup lengths=[347, 254, 1959, 314, 500]\n",
      "    summary lengths=[511, 468, 377, 458, 533]\n",
      "    total writeups length:3374, overall prompt length: 2531, overall summary length: 1000\n",
      "total of 390 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5704f6157f4d79939ddd069a9d6960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390: competition Sartorius - Cell Instance Segmentation, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2aac32a0a44e27be64e89a29482a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[505, 1256, 1350, 901, 536, 979]\n",
      "    writeup lengths=[344, 1095, 1190, 740, 374, 817]\n",
      "    summary lengths=[451, 425, 434, 450, 413, 677]\n",
      "    total writeups length:4560, overall prompt length: 3041, overall summary length: 388\n",
      "total of 391 competitions processed\n",
      "257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a3647b384e438d83f647185967724a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391: competition Santa 2021 - The Merry Movie Montage, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2d038189c64cc282c83bc7405235ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2987, 1510, 535, 736, 711, 887, 1193, 1501]\n",
      "    writeup lengths=[2770, 1293, 319, 520, 494, 670, 977, 1284]\n",
      "    summary lengths=[546, 390, 384, 436, 444, 401, 465, 500]\n",
      "    total writeups length:8327, overall prompt length: 3827, overall summary length: 434\n",
      "total of 392 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0414c6db95c4113a511b51b6f8ae1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392: competition Santa 2021 - The Merry Movie Montage, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debcc7254d934c609370fc58ca758605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1712, 324, 411, 1112, 1410, 744, 1687, 728]\n",
      "    writeup lengths=[1496, 108, 195, 896, 1194, 528, 1471, 511]\n",
      "    summary lengths=[434, 379, 390, 367, 351, 519, 405, 406]\n",
      "    total writeups length:6399, overall prompt length: 3512, overall summary length: 493\n",
      "total of 393 competitions processed\n",
      "258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aefd7988834476d9e1590c30ec7b10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393: competition Feedback Prize - Evaluating Student Writing, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008760ad659c434a9bc939eaa33f8e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2207, 1425, 823, 2008, 1342, 1196, 1071, 1966]\n",
      "    writeup lengths=[2015, 1232, 630, 1816, 1149, 1003, 879, 1773]\n",
      "    summary lengths=[474, 463, 446, 443, 304, 784, 399, 596]\n",
      "    total writeups length:10497, overall prompt length: 4145, overall summary length: 627\n",
      "total of 394 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9c213191f4d4f95bd3a0149ba2f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394: competition Feedback Prize - Evaluating Student Writing, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e22f3aac5ec41b2b9a32e284bc4920b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1243, 454, 1046, 1102, 880, 833, 816, 1145, 841]\n",
      "    writeup lengths=[1050, 262, 854, 910, 689, 641, 624, 953, 649]\n",
      "    summary lengths=[372, 427, 439, 528, 558, 466, 589, 591, 417]\n",
      "    total writeups length:6632, overall prompt length: 4630, overall summary length: 609\n",
      "total of 395 competitions processed\n",
      "259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b46a6eeac5479a8a61bcd598912e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395: competition Ubiquant Market Prediction, writeups 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a5baf9d21245a59df7526918508561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[404, 1732, 749, 448, 392, 523, 1306]\n",
      "    writeup lengths=[235, 1564, 580, 279, 223, 354, 1137]\n",
      "    summary lengths=[442, 527, 527, 395, 458, 437, 547]\n",
      "    total writeups length:4372, overall prompt length: 3539, overall summary length: 526\n",
      "total of 396 competitions processed\n",
      "260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bb3bdf3c92412c967e2f6201f126f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396: competition Happywhale - Whale and Dolphin Identification, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0749eabaa49447cd9d2a87b5adff452d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[718, 1127, 1056, 578, 639, 1121, 785, 869, 925, 2040]\n",
      "    writeup lengths=[531, 940, 870, 391, 452, 934, 598, 682, 739, 1852]\n",
      "    summary lengths=[544, 360, 357, 567, 433, 566, 483, 516, 477, 511]\n",
      "    total writeups length:7989, overall prompt length: 5059, overall summary length: 1000\n",
      "total of 397 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbd16741d2946f39d561eeaca3aed2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397: competition Happywhale - Whale and Dolphin Identification, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdc223007e24d52aad9fe8434e9efbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[713, 791, 687, 897, 1117, 828]\n",
      "    writeup lengths=[526, 604, 501, 709, 930, 641]\n",
      "    summary lengths=[485, 436, 455, 439, 359, 544]\n",
      "    total writeups length:3911, overall prompt length: 2935, overall summary length: 330\n",
      "total of 398 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85a1256b4a54ec6be3a34c4a7464a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398: competition Happywhale - Whale and Dolphin Identification, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412740e85ed547bdb9d6777be3ef80d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[569, 723, 771, 712, 495]\n",
      "    writeup lengths=[382, 536, 584, 525, 308]\n",
      "    summary lengths=[499, 469, 394, 455, 367]\n",
      "    total writeups length:2335, overall prompt length: 2394, overall summary length: 503\n",
      "total of 399 competitions processed\n",
      "261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9096d82141c34554a856c953a04535a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399: competition NBME - Score Clinical Patient Notes, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2069b5939da3450c90df9785bc2a6d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1744, 950, 899, 1123, 845, 1823, 709, 2719, 1770, 1285]\n",
      "    writeup lengths=[1549, 757, 704, 928, 650, 1628, 513, 2525, 1575, 1090]\n",
      "    summary lengths=[540, 438, 458, 488, 449, 431, 431, 459, 389, 360]\n",
      "    total writeups length:11919, overall prompt length: 4696, overall summary length: 686\n",
      "total of 400 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe5923125df4a54ad7fdfd550c713f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: competition NBME - Score Clinical Patient Notes, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a52727a44b14afe97f736e07a460a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1813, 1246, 1028, 1093, 886, 766]\n",
      "    writeup lengths=[1617, 1051, 833, 897, 690, 569]\n",
      "    summary lengths=[505, 407, 598, 441, 427, 481]\n",
      "    total writeups length:5657, overall prompt length: 3084, overall summary length: 609\n",
      "total of 401 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7826c5f0683b48ef81fe89131c776a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401: competition NBME - Score Clinical Patient Notes, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d86d2384afa4c8882dbfc519bc05e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[854, 753, 859, 1814, 957, 1071]\n",
      "    writeup lengths=[659, 559, 664, 1618, 763, 876]\n",
      "    summary lengths=[427, 404, 432, 498, 346, 324]\n",
      "    total writeups length:5139, overall prompt length: 2656, overall summary length: 705\n",
      "total of 402 competitions processed\n",
      "262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2f55b7c7884dc8975cbe532faa820f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402: competition H&M Personalized Fashion Recommendations, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69725d29ce04944a3c2518c0f6a53b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[598, 681, 1495, 1280, 749, 1064, 852, 1020, 696, 2043]\n",
      "    writeup lengths=[416, 499, 1311, 1098, 566, 882, 670, 837, 513, 1860]\n",
      "    summary lengths=[484, 475, 380, 351, 431, 537, 394, 451, 531, 517]\n",
      "    total writeups length:8652, overall prompt length: 4791, overall summary length: 672\n",
      "total of 403 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ff8672869d434c834d6f87de56e0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403: competition H&M Personalized Fashion Recommendations, writeups 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a0e297d561488d8cbfe42426f0a45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[639, 1151, 654, 763, 755, 690, 1183]\n",
      "    writeup lengths=[457, 969, 472, 581, 573, 509, 1001]\n",
      "    summary lengths=[481, 526, 380, 474, 411, 504, 515]\n",
      "    total writeups length:4562, overall prompt length: 3510, overall summary length: 669\n",
      "total of 404 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cded98dd6654b88a1bf6ccb19bc6f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404: competition H&M Personalized Fashion Recommendations, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7816925a15304b38a448de0876a2f561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1171, 531, 554, 1601, 1087, 1319]\n",
      "    writeup lengths=[989, 349, 371, 1418, 905, 1137]\n",
      "    summary lengths=[499, 476, 405, 601, 459, 559]\n",
      "    total writeups length:5169, overall prompt length: 3211, overall summary length: 827\n",
      "total of 405 competitions processed\n",
      "263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f335418711b54f85b8229cf174864d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405: competition BirdCLEF 2022, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d962b28e510f41809b3c00d02ad9637b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[996, 764, 886, 1846, 320, 748, 1151, 1154, 826, 1071]\n",
      "    writeup lengths=[816, 585, 708, 1667, 140, 568, 973, 975, 647, 892]\n",
      "    summary lengths=[397, 445, 471, 607, 422, 541, 513, 356, 435, 610]\n",
      "    total writeups length:7971, overall prompt length: 5034, overall summary length: 504\n",
      "total of 406 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75bd21603834beb861c394ab898486a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406: competition BirdCLEF 2022, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbea4ec829c49a98c50de5e2c642ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2520, 1622, 1620, 1023, 1100, 483]\n",
      "    writeup lengths=[2340, 1443, 1441, 844, 921, 304]\n",
      "    summary lengths=[427, 596, 452, 371, 394, 371]\n",
      "    total writeups length:7293, overall prompt length: 2820, overall summary length: 424\n",
      "total of 407 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e169d918c8ad462c9a3bdd9b549017f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407: competition BirdCLEF 2022, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e893765ef04b5b9f7bf58b5978008a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1791, 1011, 675, 1395, 1162]\n",
      "    writeup lengths=[1612, 832, 496, 1216, 983]\n",
      "    summary lengths=[438, 440, 462, 406, 523]\n",
      "    total writeups length:5139, overall prompt length: 2471, overall summary length: 496\n",
      "total of 408 competitions processed\n",
      "264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4365ef685c4e9ba780634d48876004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408: competition March Machine Learning Mania 2022 - Women's, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279bd8a889e84eecbf174f2b5d8ae045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[914, 717, 581, 250, 689, 959, 1076, 562]\n",
      "    writeup lengths=[739, 543, 407, 77, 515, 784, 902, 388]\n",
      "    summary lengths=[362, 407, 394, 300, 366, 412, 397, 504]\n",
      "    total writeups length:4355, overall prompt length: 3360, overall summary length: 604\n",
      "total of 409 competitions processed\n",
      "265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc73a73ce574345888b0ff9f2b872c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409: competition March Machine Learning Mania 2022 - Men’s, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97a12562f6d4c0790e48053e3e7e1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[604, 679, 409, 724, 407, 561, 228, 442]\n",
      "    writeup lengths=[432, 505, 234, 551, 235, 387, 55, 268]\n",
      "    summary lengths=[480, 436, 465, 439, 380, 453, 313, 375]\n",
      "    total writeups length:2667, overall prompt length: 3559, overall summary length: 716\n",
      "total of 410 competitions processed\n",
      "266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3610b9a30e544028e96ba0c7ae693d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410: competition GeoLifeCLEF 2022 - LifeCLEF 2022 x FGVC9, writeups 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c30462e369149169f8adecd634f3898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1370, 2392]\n",
      "    writeup lengths=[1186, 2208]\n",
      "    summary lengths=[453, 486]\n",
      "    total writeups length:3394, overall prompt length: 1125, overall summary length: 672\n",
      "total of 411 competitions processed\n",
      "267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e669be9821c49c2a5e04f8e998fed10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411: competition Hotel-ID to Combat Human Trafficking 2022 - FGVC9, writeups 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d178f08fd646678a664ffe663c2a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[819, 622, 492]\n",
      "    writeup lengths=[652, 456, 324]\n",
      "    summary lengths=[432, 448, 378]\n",
      "    total writeups length:1432, overall prompt length: 1434, overall summary length: 560\n",
      "total of 412 competitions processed\n",
      "268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c5bb1d148744e683ca19f1c98b38c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412: competition Sorghum -100 Cultivar Identification - FGVC 9, writeups 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1df767be7b460c9c0f7129cb34b5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[445, 387, 1348]\n",
      "    writeup lengths=[251, 193, 1153]\n",
      "    summary lengths=[428, 406, 535]\n",
      "    total writeups length:1597, overall prompt length: 1572, overall summary length: 370\n",
      "total of 413 competitions processed\n",
      "269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802e00367b4b4771a246426ed30821cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413: competition iWildCam 2022 - FGVC9, writeups 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42577a116ab144daabe79be85904acbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[909, 634]\n",
      "    writeup lengths=[716, 441]\n",
      "    summary lengths=[584, 426]\n",
      "    total writeups length:1157, overall prompt length: 1205, overall summary length: 427\n",
      "total of 414 competitions processed\n",
      "270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0614290fc0624626aa7990335f4cdf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414: competition Image Matching Challenge 2022, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33758f6bb394a4fb23d0532a53ff3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1656, 996, 1512, 564, 1347, 965, 1009, 1553, 1062, 1819]\n",
      "    writeup lengths=[1472, 810, 1327, 378, 1162, 780, 824, 1368, 877, 1633]\n",
      "    summary lengths=[381, 376, 482, 479, 406, 471, 477, 338, 581, 450]\n",
      "    total writeups length:10631, overall prompt length: 4684, overall summary length: 435\n",
      "total of 415 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f26ef1b9d5406d807f0c16019a1626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415: competition Image Matching Challenge 2022, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b73bb37dec24937abf340566d057e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1251, 776, 2517, 892, 1680, 519]\n",
      "    writeup lengths=[1065, 591, 2332, 707, 1495, 334]\n",
      "    summary lengths=[365, 429, 416, 499, 423, 357]\n",
      "    total writeups length:6524, overall prompt length: 2704, overall summary length: 574\n",
      "total of 416 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e4fb5b88744df3bf691ac67a0813b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416: competition Image Matching Challenge 2022, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2ed23b7e5640baaf4f8563f2df03c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1529, 984, 596, 840, 3165]\n",
      "    writeup lengths=[1344, 799, 411, 656, 2980]\n",
      "    summary lengths=[539, 415, 437, 349, 526]\n",
      "    total writeups length:6190, overall prompt length: 2474, overall summary length: 421\n",
      "total of 417 competitions processed\n",
      "271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defc0626b4b0436d94a5ba45973e66cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417: competition JPX Tokyo Stock Exchange Prediction, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e14d0abdad4421938af79859f25767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[330, 854, 770, 400, 470, 581]\n",
      "    writeup lengths=[140, 664, 580, 211, 280, 391]\n",
      "    summary lengths=[326, 437, 414, 339, 424, 512]\n",
      "    total writeups length:2266, overall prompt length: 2672, overall summary length: 449\n",
      "total of 418 competitions processed\n",
      "272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81f78635a49430abec54488cc32ece1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418: competition Kore 2022, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf7439ee84b4443af709a044e56b69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2978, 1893, 1245, 1715, 239, 3704, 1678, 1899, 1426]\n",
      "    writeup lengths=[2817, 1731, 1084, 1553, 77, 3542, 1516, 1737, 1264]\n",
      "    summary lengths=[474, 413, 446, 483, 369, 505, 496, 445, 464]\n",
      "    total writeups length:15321, overall prompt length: 4308, overall summary length: 550\n",
      "total of 419 competitions processed\n",
      "273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc08d514d6043c59413626f6eccad5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419: competition Foursquare - Location Matching, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0429e18a2b4448d8b7aef1d6a1e784fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1216, 1255, 1380, 713, 1609, 824, 1377, 628]\n",
      "    writeup lengths=[1049, 1088, 1213, 547, 1442, 657, 1210, 461]\n",
      "    summary lengths=[562, 377, 637, 477, 475, 520, 537, 670]\n",
      "    total writeups length:7667, overall prompt length: 4466, overall summary length: 452\n",
      "total of 420 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2c7814a42148a5a0005b77d6b18514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420: competition Foursquare - Location Matching, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0ed03ee3634d8a99384e80517bd5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[292, 1597, 1598, 1971, 1694, 841, 521, 653, 1725]\n",
      "    writeup lengths=[126, 1429, 1431, 1804, 1528, 674, 354, 486, 1558]\n",
      "    summary lengths=[408, 439, 381, 420, 460, 405, 528, 487, 471]\n",
      "    total writeups length:9390, overall prompt length: 4217, overall summary length: 627\n",
      "total of 421 competitions processed\n",
      "274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4978d75ecae64383bba14448c33d311d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421: competition Herbarium 2022 - FGVC9, writeups 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2865fdacc1cb404f92262a186897ad48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[930]\n",
      "    writeup lengths=[734]\n",
      "    summary lengths=[494]\n",
      "    total writeups length:734, overall prompt length: 684, overall summary length: 481\n",
      "total of 422 competitions processed\n",
      "275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0d1ca075fe43a59d490554bdf2544e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422: competition Google Smartphone Decimeter Challenge 2022, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b6a9c62c0840c990e0cd0b0dfa456d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[808, 1120, 2395, 699, 1218]\n",
      "    writeup lengths=[613, 925, 2201, 504, 1023]\n",
      "    summary lengths=[443, 399, 401, 425, 530]\n",
      "    total writeups length:5266, overall prompt length: 2416, overall summary length: 466\n",
      "total of 423 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4520915224a24bb4b97b91075eef75df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423: competition Google Smartphone Decimeter Challenge 2022, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22082fb0d8024a45b162581a985f85c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[491, 1824, 954, 936, 615, 1704]\n",
      "    writeup lengths=[296, 1629, 759, 741, 419, 1509]\n",
      "    summary lengths=[356, 518, 407, 382, 393, 438]\n",
      "    total writeups length:5353, overall prompt length: 2719, overall summary length: 661\n",
      "total of 424 competitions processed\n",
      "276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22bcb6aeced498e9d42742ed98a444c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424: competition Feedback Prize - Predicting Effective Arguments, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbf67adeb2b4020880d9e2abae6a235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1330, 759, 789, 735, 598, 896, 2117, 1091, 2349]\n",
      "    writeup lengths=[1118, 548, 576, 523, 386, 684, 1906, 879, 2137]\n",
      "    summary lengths=[564, 411, 458, 442, 422, 356, 525, 425, 682]\n",
      "    total writeups length:8757, overall prompt length: 4548, overall summary length: 599\n",
      "total of 425 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d1098b262445858370f01fcfaed1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425: competition Feedback Prize - Predicting Effective Arguments, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c63a37b47a49309c336f2bf9357773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[705, 840, 659, 2223, 516, 737, 599, 806, 614, 754]\n",
      "    writeup lengths=[493, 628, 448, 2010, 305, 525, 387, 593, 402, 543]\n",
      "    summary lengths=[456, 386, 396, 537, 336, 296, 485, 351, 472, 445]\n",
      "    total writeups length:6334, overall prompt length: 4430, overall summary length: 797\n",
      "total of 426 competitions processed\n",
      "277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8c8a457e144923aa6dec921ada57a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426: competition American Express - Default Prediction, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303b1416d8544bbbb5cac0953433d748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1036, 1693, 5210, 1842, 1362, 311, 1112, 1116, 282, 298]\n",
      "    writeup lengths=[841, 1498, 5015, 1646, 1167, 116, 917, 920, 88, 104]\n",
      "    summary lengths=[508, 389, 475, 528, 303, 307, 384, 365, 331, 432]\n",
      "    total writeups length:12312, overall prompt length: 4275, overall summary length: 559\n",
      "total of 427 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2936ccdfa25b45bc9f57dcf98aaf98e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427: competition American Express - Default Prediction, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e775efc97b104b93bc377166314ca129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[841, 266, 559, 1082, 995, 599, 515, 467, 683, 328]\n",
      "    writeup lengths=[646, 72, 364, 887, 800, 405, 321, 271, 487, 133]\n",
      "    summary lengths=[502, 429, 529, 520, 499, 402, 469, 357, 459, 383]\n",
      "    total writeups length:4386, overall prompt length: 4802, overall summary length: 570\n",
      "total of 428 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab81453e32f493098dd5c88560eee97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428: competition American Express - Default Prediction, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c10ec5954f34ac2b8d176190224425b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[990, 640, 266, 982, 608, 842]\n",
      "    writeup lengths=[796, 444, 72, 787, 414, 647]\n",
      "    summary lengths=[508, 438, 306, 575, 441, 431]\n",
      "    total writeups length:3160, overall prompt length: 2924, overall summary length: 648\n",
      "total of 429 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299af71528384ed9a4cbc906ffc50ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429: competition American Express - Default Prediction, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73599740f7449be96a0c835313cdca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2054, 2095, 578, 3133, 838]\n",
      "    writeup lengths=[1859, 1899, 383, 2938, 643]\n",
      "    summary lengths=[524, 494, 392, 488, 414]\n",
      "    total writeups length:7722, overall prompt length: 2530, overall summary length: 564\n",
      "total of 430 competitions processed\n",
      "278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baa0720578f4475929222c13d3cc7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430: competition HuBMAP + HPA - Hacking the Human Body, writeups 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97380a88399545db9fa63d1d9d3b2f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1755, 936, 736, 845, 667]\n",
      "    writeup lengths=[1580, 760, 560, 668, 491]\n",
      "    summary lengths=[519, 373, 467, 409, 410]\n",
      "    total writeups length:4059, overall prompt length: 2377, overall summary length: 537\n",
      "total of 431 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5c1844ac15440d8ad44b8a1df2c9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431: competition HuBMAP + HPA - Hacking the Human Body, writeups 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86772fbaf1904253a1dc9cc7a396a59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[713, 604, 1341, 725, 638, 2067]\n",
      "    writeup lengths=[537, 427, 1165, 550, 462, 1890]\n",
      "    summary lengths=[443, 462, 333, 503, 426, 421]\n",
      "    total writeups length:5031, overall prompt length: 2794, overall summary length: 560\n",
      "total of 432 competitions processed\n",
      "279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd5ec26979e4fe691d8209315e8c46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432: competition Mayo Clinic - STRIP AI, writeups 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1794aeebdc443b49c0a21813e8a99d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[2749, 453, 1254, 370, 724, 313, 603, 1284, 672, 465]\n",
      "    writeup lengths=[2584, 288, 1089, 205, 559, 148, 438, 1118, 507, 300]\n",
      "    summary lengths=[516, 460, 513, 472, 354, 347, 484, 408, 452, 484]\n",
      "    total writeups length:7236, overall prompt length: 4713, overall summary length: 512\n",
      "total of 433 competitions processed\n",
      "280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d978670d5f941eebdb88d3376cff285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433: competition Google Universal Image Embedding, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ce9039958a4e9eb08056c57f0c249b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1760, 372, 3010, 631, 1017, 739, 439, 565]\n",
      "    writeup lengths=[1573, 186, 2822, 444, 831, 553, 252, 378]\n",
      "    summary lengths=[467, 358, 491, 501, 504, 377, 456, 575]\n",
      "    total writeups length:7039, overall prompt length: 3960, overall summary length: 522\n",
      "total of 434 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1a0739bc074a25891fa0aa92f3d366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434: competition Google Universal Image Embedding, writeups 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf19512895a44b7d8b36387cf5272600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[856, 1951, 482, 1394, 497, 638, 710, 788]\n",
      "    writeup lengths=[669, 1765, 295, 1207, 310, 450, 523, 601]\n",
      "    summary lengths=[470, 417, 316, 414, 391, 496, 409, 408]\n",
      "    total writeups length:5820, overall prompt length: 3552, overall summary length: 622\n",
      "total of 435 competitions processed\n",
      "281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201610d7a0594199adcbb3174b9f73b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435: competition RSNA 2022 Cervical Spine Fracture Detection, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631f1a47362242e085c0b8a95fb2fdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1384, 1380, 1314, 1264, 523, 1513, 1232, 716, 523]\n",
      "    writeup lengths=[1200, 1195, 1130, 1080, 338, 1329, 1047, 533, 338]\n",
      "    summary lengths=[365, 570, 560, 460, 415, 546, 412, 595, 444]\n",
      "    total writeups length:8190, overall prompt length: 4602, overall summary length: 698\n",
      "total of 436 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403aa1e6f6e5480190f019fe10bc0592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436: competition RSNA 2022 Cervical Spine Fracture Detection, writeups 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653f2905a75e4987b34a943d0996e207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[1583, 1419, 1028, 1254, 906, 1322, 553, 917, 1426]\n",
      "    writeup lengths=[1399, 1235, 844, 1069, 722, 1137, 369, 733, 1242]\n",
      "    summary lengths=[470, 515, 585, 454, 528, 455, 497, 531, 517]\n",
      "    total writeups length:8750, overall prompt length: 4787, overall summary length: 424\n",
      "total of 437 competitions processed\n",
      "282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56587372441948ec90188ed366f70e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437: competition AI Village Capture the Flag @ DEFCON, writeups 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6db9d0c42b9492f83eeead506eac527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[584, 292, 1588, 388, 2192, 299, 366]\n",
      "    writeup lengths=[351, 60, 1354, 155, 1959, 67, 134]\n",
      "    summary lengths=[372, 369, 418, 390, 466, 426, 422]\n",
      "    total writeups length:4080, overall prompt length: 3133, overall summary length: 677\n",
      "total of 438 competitions processed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4d66332d4c47479677c111c92a16ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438: competition AI Village Capture the Flag @ DEFCON, writeups 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d350a0da9b54a8a938aadf446e6fe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prompt lengths=[813, 426, 251, 289, 268, 304, 414]\n",
      "    writeup lengths=[581, 194, 18, 57, 35, 70, 182]\n",
      "    summary lengths=[461, 360, 551, 410, 397, 525, 400]\n",
      "    total writeups length:1137, overall prompt length: 3374, overall summary length: 460\n",
      "total of 439 competitions processed\n"
     ]
    }
   ],
   "source": [
    "# subset is how many competitions are used here, limiting it on Kaggle for GPU time\n",
    "if on_kaggle:\n",
    "    subset = 5\n",
    "else:\n",
    "    subset = len(used_names)\n",
    "\n",
    "if N != \"ALL\":\n",
    "    print(f\"N = {N}\")\n",
    "    # taking the latest competitions subset to have competitions with more writeups\n",
    "    subset = 33\n",
    "    start_idx = 250\n",
    "#    start_idx = len(used_names) - subset\n",
    "#    start_idx = len(used_names) - subset\n",
    "    for x in tqdm(range(start_idx, start_idx+subset)):\n",
    "        print(x)\n",
    "        name = used_names[x]\n",
    "        final_names.append(name)\n",
    "        # writeup_dataframes holds the writeups for the competition name at same index\n",
    "        for df_subframe in writeup_dataframes_filtered[x]:\n",
    "            summarize_competition_writeups([name], df_subframe, tokenizer)\n",
    "else:\n",
    "    print(f\"ALL = {N}\")\n",
    "    # this was on local desktop with more resources and GPU time\n",
    "    # in this case there are splits or subsets, all comp writeup summaries are summarized as one\n",
    "    summarize_competition_writeups(used_names, df_writeups_all, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n",
      "439\n",
      "439\n"
     ]
    }
   ],
   "source": [
    "subset_count = 0\n",
    "#for idx in range(0, start_idx+subset):\n",
    "for idx in range(0, len(writeup_dataframes_filtered)):\n",
    "    wdfs = writeup_dataframes_filtered[idx]\n",
    "    subset_count += len(wdfs)\n",
    "#    for wdf in wdfs:\n",
    "#        subset_count += wdf.shape[0]\n",
    "        \n",
    "print(subset_count)\n",
    "print(len(writeup_summaries))\n",
    "print(len(overall_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What a fascinating competition! As a helpful assistant, I'll extract the key points from a datascience application viewpoint for similar problem solving. Here are the key takeaways:\\n\\n1. **Domain knowledge**: The competition involves various machine learning security challenges, which requires a good understanding of the underlying concepts and techniques. This highlights the importance of domain knowledge in tackling complex problems.\\n2. **Adversarial attacks**: The writeup showcases the use of adversarial attacks, such as gradient attacks, to manipulate machine learning models. This demonstrates the need to consider potential attacks when designing and deploying machine learning systems.\\n3. **Transfer learning**: The use of pre-trained models, such as InceptionV3 and MobileNet, as proxies for gradient attacks shows the value of transfer learning in certain situations.\\n4. **Exploration and experimentation**: The writeup highlights the importance of exploring different approaches and experimenting with various techniques to find the most effective solutions.\\n5. **Clustering and dimensionality reduction**: The use of DBSCAN and PCA to find clusters and reduce dimensions is a common technique in many datascience applications, including this competition.\\n6. **Iterative approach**: The writeup shows how the author iteratively refined their solutions, often by trying different approaches and adjusting their strategies based on the results.\\n7. **Code reuse and sharing**: The author shares their code and notebooks, which is a great practice in datascience competitions. This encourages collaboration and helps others learn from the author's experiences.\\n8. **Error handling and debugging**: The writeup mentions the author's struggles with certain challenges, such as Sloth, which highlights the importance of error handling and debugging in datascience applications.\\n9. **Creative problem-solving**: The competition's unique challenges require creative problem-solving, which is a valuable skill in datascience. The writeup showcases the author's ability to think outside the box and come up with innovative solutions.\\n10. **Documentation and communication**: The author's writeup serves as a great example of how to document and communicate the solutions and approaches taken during a competition. This helps others understand the thought process and techniques used to solve the challenges.\\n\\nThese key points can be applied to similar datascience problems, where creativity, experimentation, and domain knowledge are essential for success.<|eot_id|>\",\n",
       " \"What a fascinating competition! As a helpful assistant, I'll extract the key points from a datascience application viewpoint for similar problem solving:\\n\\n1. **Domain knowledge**: The competition involves machine learning security challenges, which highlights the importance of understanding the domain and its specific requirements. In similar competitions, it's crucial to grasp the underlying concepts and terminology.\\n2. **Adversarial AI**: The writeup mentions adversarial AI, which is a critical aspect of this competition. In similar challenges, be prepared to encounter adversarial techniques and develop strategies to counter them.\\n3. **Data poisoning**: The writeup also mentions data poisoning, which is a common threat in machine learning competitions. Be aware of potential data poisoning attacks and develop techniques to detect and mitigate them.\\n4. **Image processing**: The competition involves image manipulation, which requires a good understanding of image processing techniques. In similar challenges, be prepared to work with images and develop skills in image processing.\\n5. **Exploration and experimentation**: The writeup mentions the author's initial success with adding an emoji to the video, which highlights the importance of exploration and experimentation in competitions. Be prepared to try different approaches and iterate on your solutions.\\n6. **Surprise and adaptability**: The writeup mentions the author's surprise at the outcome and the need to adapt to new challenges. In similar competitions, be prepared for unexpected twists and be willing to adjust your approach accordingly.\\n7. **Collaboration and community**: The writeup thanks other participants and organizers, which emphasizes the importance of collaboration and community in competitions. Engage with other competitors, share knowledge, and learn from each other's experiences.\\n\\nBy keeping these key points in mind, you'll be better equipped to tackle similar competitions and challenges in the datascience domain.<|eot_id|>\",\n",
       " \"Based on the writeup, here are the key points from a datascience application viewpoint for similar problem solving:\\n\\n1. **Challenge understanding**: The writeup highlights the importance of thoroughly understanding the challenge requirements and constraints. This is crucial in any CTF or machine learning competition, as it helps competitors identify the most effective approaches and avoid common pitfalls.\\n\\nLesson: Take the time to carefully read and understand the challenge description, and ask clarifying questions if needed.\\n\\n2. **Exploratory data analysis**: The writeup mentions the need to perform exploratory data analysis (EDA) to gain insights into the data distribution, relationships, and patterns. This is a fundamental step in any datascience project, as it helps identify potential issues, opportunities, and areas for improvement.\\n\\nLesson: Always perform EDA to understand the data and its characteristics, and use this information to inform your approach.\\n\\n3. **Data preprocessing**: The writeup highlights the importance of data preprocessing, including data cleaning, normalization, and feature engineering. This is a critical step in many datascience projects, as it helps ensure that the data is in a suitable format for analysis and modeling.\\n\\nLesson: Always perform thorough data preprocessing to ensure that the data is clean, consistent, and ready for analysis.\\n\\n4. **Model selection and evaluation**: The writeup mentions the need to select the most appropriate machine learning model for the problem and evaluate its performance using relevant metrics. This is a crucial step in any datascience project, as it helps identify the most effective approach and avoid overfitting or underfitting.\\n\\nLesson: Always evaluate multiple models and select the one that performs best on the target metric, and use techniques like cross-validation to avoid overfitting.\\n\\n5. **Iterative approach**: The writeup highlights the importance of an iterative approach, where competitors refine their solutions based on feedback and insights gained from previous attempts. This is a common approach in many datascience projects, as it helps identify areas for improvement and optimize the solution.\\n\\nLesson: Be prepared to iterate and refine your approach based on feedback and insights gained from previous attempts, and don't be afraid to try new ideas and approaches.\\n\\n6. **Code organization and documentation**: The writeup mentions the importance of organizing code and documenting the solution, including comments, logs, and version control. This is a good practice in any datascience project, as it helps others understand the code and makes it easier to maintain and update.\\n\\nLesson: Always organize your code and document your solution, including comments, logs, and version control, to make it easier for others to understand and maintain.\\n\\nThese key points can be applied to similar problem-solving challenges, such as other CTF competitions or machine learning challenges.<|eot_id|>\",\n",
       " \"Based on the writeup, here are the key points from a datascience application viewpoint for similar problem solving:\\n\\n1. **Challenge-based approach**: The competition is structured around 22 challenges, each with its own unique goal. This approach can be applied to other competitions or projects where you need to tackle multiple tasks or problems. It's essential to break down the overall problem into smaller, manageable challenges.\\n2. **Variety of topics and techniques**: The challenges cover a range of topics, including dimensionality, image manipulation, sentiment analysis, and more. This diversity can be beneficial in developing a broad range of skills and expertise. When approaching similar competitions or projects, be prepared to adapt to different topics and techniques.\\n3. **Notebook-based approach**: The participant published their solutions in a notebook, which is a common practice in Kaggle competitions. This approach allows for easy sharing and collaboration. When working on similar projects, consider using a notebook or similar documentation tool to keep track of your progress and share your findings with others.\\n4. **Iterative approach**: The participant's notebook likely reflects an iterative approach, where they worked through each challenge, refined their solutions, and learned from their mistakes. This iterative approach is essential in datascience, as it allows you to refine your models, test new ideas, and adapt to changing requirements.\\n5. **Collaboration and sharing**: The participant thanked the sponsors and acknowledged the fun they had during the competition. This highlights the importance of collaboration and sharing in the datascience community. When working on similar projects, consider sharing your findings, collaborating with others, and learning from their experiences.\\n\\nThese key points can be applied to similar problem-solving approaches, such as:\\n\\n* Breaking down complex problems into smaller, manageable challenges\\n* Adapting to different topics and techniques\\n* Using notebooks or similar documentation tools to track progress and share findings\\n* Embracing an iterative approach to refine models and learn from mistakes\\n* Collaborating and sharing with others in the datascience community.<|eot_id|>\",\n",
       " \"Based on the writeup, I've identified the key points from a datascience application viewpoint for similar problem solving:\\n\\n1. **Challenge-based approach**: The competitor broke down the competition into smaller, manageable challenges, which allowed them to focus on one problem at a time. This approach can be applied to other competitions or projects where the problem is too large to tackle all at once.\\n2. **Domain knowledge**: The competitor mentions working through various machine learning security challenges, which implies that they had to develop domain-specific knowledge to tackle these problems. In similar competitions or projects, it's essential to understand the underlying concepts and terminology to effectively solve the challenges.\\n3. **Diversification of techniques**: The writeup doesn't specify the exact techniques used, but it mentions working through different challenges, which suggests that the competitor employed a range of techniques to solve the problems. This is an important lesson for similar problem solving, as it's often necessary to adapt and combine different techniques to tackle complex problems.\\n4. **Iterative approach**: The competitor mentions updating their solution notebook, which implies that they iterated on their solutions to improve them. This iterative approach is crucial in datascience, as it allows for refinement and improvement of solutions over time.\\n5. **Output and visualization**: The writeup mentions including output and descriptions of the solutions, which is essential for understanding and communicating the results. In similar competitions or projects, it's vital to include clear and concise output and visualizations to demonstrate the effectiveness of the solutions.\\n6. **Collaboration and sharing**: The writeup is a walkthrough, which suggests that the competitor is willing to share their knowledge and insights with others. This is an important aspect of datascience, as collaboration and sharing can lead to new ideas and approaches, and help to build a community around the problem-solving process.\\n\\nBy applying these key points, competitors and datascience practitioners can develop a more effective approach to tackling complex problems and competitions.<|eot_id|>\",\n",
       " \"Based on the writeup, here are the key points from a datascience application viewpoint for similar problem solving:\\n\\n1. **Challenge-based approach**: The competitor broke down the competition into individual challenges, focusing on one challenge at a time. This approach can be effective when dealing with a large number of tasks or problems, allowing for a more structured and manageable workflow.\\n2. **Code organization and sharing**: The competitor organized their code into separate notebooks or files for each challenge, making it easy to share and reuse code. This is a good practice for keeping track of code and making it accessible to others.\\n3. **Adaptability and flexibility**: The competitor's code was not limited to a single approach or algorithm, but rather adapted to each challenge's specific requirements. This flexibility is essential when dealing with diverse problems, as it allows for creative problem-solving and experimentation.\\n4. **Error handling and debugging**: The competitor's code included error handling and debugging mechanisms, which is crucial when working with complex problems or large datasets. This ensures that the code can handle unexpected errors and provides a way to identify and fix issues.\\n5. **Code reuse and modularity**: The competitor's code was designed to be modular, with reusable components for tasks such as data preprocessing, feature engineering, and model training. This modularity can simplify the development process and make it easier to maintain and update code.\\n6. **Documentation and commenting**: The competitor included comments and documentation in their code, making it easier for others to understand and modify the code. This is an essential practice for maintaining code readability and making it accessible to others.\\n7. **Experimentation and iteration**: The competitor's code included experimentation and iteration, which is a key aspect of the datascience process. This allows for testing different approaches, refining models, and improving results.\\n8. **Focus on specific problem-solving skills**: The competitor's code demonstrated a focus on specific problem-solving skills, such as image manipulation, sentiment analysis, and dimensionality reduction. This focus can help develop expertise in specific areas and improve overall problem-solving abilities.\\n\\nThese key points can be applied to similar problem-solving scenarios, such as:\\n\\n* Breaking down complex problems into smaller, manageable tasks\\n* Organizing and sharing code for collaboration and reuse\\n* Adapting to changing requirements and experimenting with different approaches\\n* Implementing error handling and debugging mechanisms\\n* Designing modular and reusable code components\\n* Documenting and commenting code for readability and maintainability\\n* Iterating and refining solutions through experimentation and testing\\n* Focusing on specific problem-solving skills and developing expertise in those areas.<|eot_id|>\",\n",
       " \"A new competition to analyze! As Gemma, I'll extract the key points from the writeup that are relevant to datascience application and problem-solving. Here are the key takeaways:\\n\\n1. **Code organization and cleanliness**: The writer mentions cleaning up their messy code, which is an essential step in any data science project. This highlights the importance of maintaining organized and readable code, especially when working on complex problems.\\n2. **Domain knowledge and exploration**: The writer mentions learning a lot from the competition, which suggests that they explored and learned about various machine learning concepts and techniques. This is crucial in any data science project, where understanding the problem domain and exploring different approaches is essential.\\n3. **Adaptability and flexibility**: The writer mentions getting good at back-propagation and modifying the input instead of the network, which shows their ability to adapt to new techniques and approaches. This flexibility is essential in data science, where problems often require creative solutions.\\n4. **Inspection and manipulation of model components**: The writer mentions inspecting and manipulating weights, biases, activations, and gradients for different layers of a network. This highlights the importance of understanding how models work and being able to manipulate their components to achieve desired results.\\n5. **Persistence and learning from failure**: The writer mentions not finishing crop2, but still learning from the experience. This shows that they persisted despite not achieving their goal and learned from their failure, which is an essential aspect of data science.\\n\\nThese key points can be applied to similar problem-solving scenarios in datascience, such as:\\n\\n* When working on a complex problem, maintain organized and readable code to ensure clarity and efficiency.\\n* Explore and learn about different techniques and concepts to adapt to new problems.\\n* Be flexible and willing to try new approaches when faced with a challenging problem.\\n* Understand how models work and be able to manipulate their components to achieve desired results.\\n* Persist despite setbacks and learn from failures to improve and grow as a data scientist.<|eot_id|>\"]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeup_summaries[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T07:13:42.007830Z",
     "iopub.status.busy": "2024-04-13T07:13:42.006962Z",
     "iopub.status.idle": "2024-04-13T07:13:42.011354Z",
     "shell.execute_reply": "2024-04-13T07:13:42.010480Z",
     "shell.execute_reply.started": "2024-04-13T07:13:42.007799Z"
    }
   },
   "source": [
    "## Build the Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we come here, we have writeup summaries in a single flat list. Now need to re-group then so that each subset is its own list of writeup summaries for that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['summary1_1', 'summary1_2'], ['summary2_1', 'summary2_2'], ['summary3_1']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recombine_summaries(summaries, sublist_lengths):\n",
    "    result = []\n",
    "    start_index = 0\n",
    "    for idx, length in enumerate(sublist_lengths):\n",
    "        end_index = start_index + length\n",
    "        sublist = summaries[start_index:end_index]\n",
    "        if len(sublist) == 0:\n",
    "            print(f\"stopping recombo due to end of list at idx {idx}\")\n",
    "            break\n",
    "        result.append(sublist)\n",
    "        start_index = end_index\n",
    "\n",
    "    return result \n",
    "\n",
    "# Example usage\n",
    "summaries = [\"summary1_1\", \"summary1_2\", \"summary2_1\", \"summary2_2\", \"summary3_1\"]\n",
    "sublist_lengths = [2, 2, 1]\n",
    "\n",
    "recombine_summaries(summaries, sublist_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should produce 5 lists of subsets, since I capped it at 5 for Kaggle above\n",
    "#sublist_lengths = [len(sub) for sub in writeup_dataframes_filtered[-subset:]]\n",
    "sublist_lengths = [len(sub) for sub in writeup_dataframes_filtered]\n",
    "len(sublist_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N != \"ALL\":\n",
    "    combined = recombine_summaries(overall_summaries, sublist_lengths)\n",
    "else:\n",
    "    combined = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the Subsets Separately\n",
    "\n",
    "For the summarizing large numbers of writeups in parts experiment, I first need summaries of the subsets. This is where that happens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_subsummaries(sublist, print_prompt=False, prompt_style=\"simple\"):\n",
    "    #print(f\"summarizing: {sublist}\")\n",
    "    writeup_summaries = [summary.data for summary in sublist]\n",
    "    if prompt_style == \"simple\":\n",
    "        points = \"\\n\\n\".join(writeup_summaries)\n",
    "    elif prompt_style == \"subtitle writeup\":\n",
    "        points = \"\"\n",
    "        for idx, writeup_summary in enumerate(writeup_summaries):\n",
    "            points += \"\\n\\n\"\n",
    "            points += f\"writeup {idx}\\n\"\n",
    "            points += writeup_summary\n",
    "    else:\n",
    "        points = \"\"\n",
    "        for idx, writeup_summary in enumerate(writeup_summaries):\n",
    "            points += \"\\n\\n\"\n",
    "            points += f\"writeups summary {idx}\\n\"\n",
    "            points += writeup_summary\n",
    "    prompt = f\"\"\"collect the key points listed in these writeup summaries into one list of key points.\n",
    "    include the descriptions given for these key points.\n",
    "    writeup summaries:\n",
    "    {points}\n",
    "    \"\"\"\n",
    "    # trying to remove <|eot_id|> just in case Llama3 thinks the sequence ends in the middle\n",
    "    prompt = prompt.replace(\"<|eot_id|>\", \"\\n\")\n",
    "    summary, summary_md = llama3_generate(prompt, print_prompt)\n",
    "    if print_prompt:\n",
    "        # this printing is just for debugging, because Gemma is giving some \n",
    "        # rather strange output at times it seems\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        prompt_len = len(input_ids[\"input_ids\"][0])\n",
    "        print(f\"------- PROMPT ------- {prompt_len} tokens ------\")\n",
    "        print(prompt)\n",
    "        input_ids = tokenizer(summary, return_tensors=\"pt\")\n",
    "        summary_len = len(input_ids[\"input_ids\"][0])\n",
    "        print(f\"------ SUMMARY: ------ {summary_len} tokens ------\")\n",
    "        print(summary)\n",
    "    return summary, summary_md\n",
    "\n",
    "#print(type(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Competition Subset Summaries to One Per Competition\n",
    "\n",
    "Competition writeup summaries -> summaries for subsets of those -> one summary per competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N != \"ALL\":\n",
    "    len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7e6fcac22547b09047cee358c1050b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resummarized = None\n",
    "resummarized_md = None\n",
    "resummarized_simple = []\n",
    "resummarized_md_simple = []\n",
    "resummarized_writeup = []\n",
    "resummarized_md_writeup = []\n",
    "resummarized_writeup_summary = []\n",
    "resummarized_md_writeup_summary = []\n",
    "\n",
    "if N != \"ALL\":\n",
    "    for idx, combo in tqdm(enumerate(combined), total=len(combined)):\n",
    "        combo_filtered = [x for x in combo if not isinstance(x, str)]\n",
    "        if len(combo_filtered) == 0:\n",
    "            print(f\"no data, skipping idx: {idx}\")\n",
    "            continue\n",
    "        title = final_names[idx]#comp_dataframes[0][\"Title of Competition\"].iloc[0]\n",
    "        #print(title)\n",
    "        if on_kaggle:\n",
    "            # just to keep the story on kaggle consistent :)\n",
    "            summary, summary_md = summarize_subsummaries(combo_filtered)\n",
    "            resummarized_simple.append(summary)\n",
    "            resummarized_md_simple.append(summary_md)\n",
    "        else: #TODO: here the other summary types\n",
    "            summary, summary_md = summarize_subsummaries(combo_filtered)\n",
    "            resummarized_simple.append(summary)\n",
    "            resummarized_md_simple.append(summary_md)\n",
    "            \n",
    "            summary, summary_md = summarize_subsummaries(combo_filtered, False, \"subtitle writeup\")\n",
    "            resummarized_writeup.append(summary)\n",
    "            resummarized_md_writeup.append(summary_md)\n",
    "            \n",
    "            summary, summary_md = summarize_subsummaries(combo_filtered, False, \"writeup summaries title\")\n",
    "            resummarized_writeup_summary.append(summary)\n",
    "            resummarized_md_writeup_summary.append(summary_md)\n",
    "\n",
    "else:\n",
    "    plain_summaries = []\n",
    "    for idx, summary in enumerate(overall_summaries):\n",
    "        if isinstance(summary, str):\n",
    "            print(f\"string: {idx}:{summary}\")\n",
    "            plain_summaries.append(summary)\n",
    "        else:\n",
    "            plain_summaries.append(summary.data)\n",
    "            \n",
    "    #plain_summaries = [summary.data for summary in overall_summaries]\n",
    "    resummarized_simple.extend(plain_summaries)\n",
    "    resummarized_md_simple.extend(overall_summaries)\n",
    "    resummarized_comps = final_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so that is for the 5 competitions I filtered above for Kaggle. Now lets look at them and what do they say, because these latter ones are ones where Gemma seems to lose the context for some reason:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resummarized_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly. This helps to ensure that everyone involved in the project is on the same page and that the solution is tailored to the specific needs of the problem.\n",
       "\n",
       "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches. This helps to ensure that the best solution is found and that the problem is solved in the most effective way possible.\n",
       "\n",
       "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach. This helps to speed up the development process and to ensure that the solution is robust and accurate.\n",
       "\n",
       "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions. This helps to ensure that the solution is tested thoroughly and that any issues are identified and addressed early on.\n",
       "\n",
       "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve. This helps to ensure that the solution is refined and improved over time, and that any mistakes are learned from.\n",
       "\n",
       "6. **Engage with the community**: Engage with the community to share knowledge and learn from others. This helps to ensure that the solution is the best it can be and that any issues are identified and addressed quickly.\n",
       "\n",
       "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings. This helps to ensure that the solution is accurate and reliable.\n",
       "\n",
       "8. **Use historical data**: Use historical data to inform predictions and make informed decisions. This helps to ensure that the solution is based on real-world data and that any predictions are accurate.\n",
       "\n",
       "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
       "\n",
       "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
       "\n",
       "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions. This helps to ensure that the solution is accurate and reliable, and that any predictions are based on a solid foundation.\n",
       "\n",
       "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them. This helps to ensure that the solution is robust and accurate, even in unusual or unexpected situations.\n",
       "\n",
       "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions. This helps to ensure that the solution is innovative and effective.\n",
       "\n",
       "14. **Iterative refinement**: Refine predictions through multiple iterations. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
       "\n",
       "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions. This helps to ensure that the solution is tailored to the specific needs of the problem and that any predictions are based on a deep understanding of the domain.\n",
       "\n",
       "16. **Use iterative calculation**: Use iterative calculation to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
       "\n",
       "17. **Weighting and normalization**: Use weighting and normalization to handle missing data and improve the accuracy of predictions. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
       "\n",
       "18. **Incorporating future results**: Incorporate future results into the solution to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
       "\n",
       "19. **Simple modifications**: Make simple modifications to the solution to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
       "\n",
       "20. **Customization of the rating formula**: Customize the rating formula to fit the specific needs of the problem. This helps to ensure that the solution is tailored to the specific needs of the problem and that any predictions are based on a deep understanding of the domain.\n",
       "\n",
       "21. **Use of additional parameters**: Use additional parameters to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
       "\n",
       "22. **Prediction formula**: Use a prediction formula to make predictions and inform decisions. This helps to ensure that the solution is accurate and reliable, and that any predictions are based on a solid foundation.\n",
       "\n",
       "23. **Code implementation**: Implement the solution using code to ensure that it is robust and accurate. This"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(resummarized_simple[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It all Looks Rather Lost\n",
    "\n",
    "The above results show how Gemma seems to have lost all the key points its collected before from the writeups, before doing the final summary of all subsets. Lets take a closer look.\n",
    "\n",
    "## Closer look at Selected Competition 1 and its Final Summary vs Parts\n",
    "\n",
    "Lets try to verify that I did not mess it up in giving wrong inputs or misinterpret the output. The first competition from that list of 5 selected above, and its subset summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first check how many subsets and thus subset summaries the selected competition 1 has\n",
    "if N != \"ALL\":\n",
    "    len(combined[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first subset summary for the first competition in the list\n",
    "if N != \"ALL\":\n",
    "    combined[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second subset summary for the first competition in the list\n",
    "#combined[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the third and final subset summary for the first competition in the list\n",
    "#combined[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun the Final Summary for Competition 1 with Debug Info\n",
    "\n",
    "The three subset summaries shown above seem fine. So lets see what the input is actually for the final summarization step, and what the output is. Just to see there is no obvious issue with the input and how it is run.\n",
    "\n",
    "I put the debug/print_prompt flag in my helper functions above to print the prompt and token counts just for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: 545, output tokens: 1000\n",
      "------- PROMPT ------- 536 tokens ------\n",
      "collect the key points listed in these writeup summaries into one list of key points.\n",
      "    include the descriptions given for these key points.\n",
      "    writeup summaries:\n",
      "    Based on the writeup summaries, here are the key points that can be applied to similar datascience problems:\n",
      "\n",
      "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly.\n",
      "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches.\n",
      "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach.\n",
      "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions.\n",
      "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve.\n",
      "6. **Engage with the community**: Engage with the community to share knowledge and learn from others.\n",
      "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings.\n",
      "8. **Use historical data**: Use historical data to inform predictions and make informed decisions.\n",
      "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games.\n",
      "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances.\n",
      "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions.\n",
      "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them.\n",
      "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions.\n",
      "14. **Iterative refinement**: Refine predictions through multiple iterations.\n",
      "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions.\n",
      "\n",
      "The data analysis methods used across the writeups include:\n",
      "\n",
      "* Weighting and decay\n",
      "* Padding and normalization\n",
      "* Iterative calculation\n",
      "* Incorporating future results\n",
      "* Simple modifications\n",
      "* Exploration of established methods\n",
      "* Customization of the rating formula\n",
      "* Use of iterative rating formula\n",
      "* Weighting and normalization\n",
      "* Use of additional parameters\n",
      "* Prediction formula\n",
      "* Code implementation\n",
      "\n",
      "These methods are related across the writeups in that they all involve using different techniques to develop a robust and accurate rating system. The methods are used to handle missing data, refine predictions, and account for changing circumstances. The use of iterative calculation, weighting and normalization, and incorporating future results are common across the writeups, indicating that these methods are effective in developing a robust rating system.\n",
      "\n",
      "    \n",
      "------ SUMMARY: ------ 1000 tokens ------\n",
      "Here is the list of key points with descriptions:\n",
      "\n",
      "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly. This helps to ensure that everyone involved in the project is on the same page and that the solution is tailored to the specific needs of the problem.\n",
      "\n",
      "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches. This helps to ensure that the best solution is found and that the problem is solved in the most effective way possible.\n",
      "\n",
      "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach. This helps to speed up the development process and to ensure that the solution is robust and accurate.\n",
      "\n",
      "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions. This helps to ensure that the solution is tested thoroughly and that any issues are identified and addressed early on.\n",
      "\n",
      "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve. This helps to ensure that the solution is refined and improved over time, and that any mistakes are learned from.\n",
      "\n",
      "6. **Engage with the community**: Engage with the community to share knowledge and learn from others. This helps to ensure that the solution is the best it can be and that any issues are identified and addressed quickly.\n",
      "\n",
      "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings. This helps to ensure that the solution is accurate and reliable.\n",
      "\n",
      "8. **Use historical data**: Use historical data to inform predictions and make informed decisions. This helps to ensure that the solution is based on real-world data and that any predictions are accurate.\n",
      "\n",
      "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions. This helps to ensure that the solution is accurate and reliable, and that any predictions are based on a solid foundation.\n",
      "\n",
      "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them. This helps to ensure that the solution is robust and accurate, even in unusual or unexpected situations.\n",
      "\n",
      "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions. This helps to ensure that the solution is innovative and effective.\n",
      "\n",
      "14. **Iterative refinement**: Refine predictions through multiple iterations. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions. This helps to ensure that the solution is tailored to the specific needs of the problem and that any predictions are based on a deep understanding of the domain.\n",
      "\n",
      "16. **Use iterative calculation**: Use iterative calculation to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "17. **Weighting and normalization**: Use weighting and normalization to handle missing data and improve the accuracy of predictions. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "18. **Incorporating future results**: Incorporate future results into the solution to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "19. **Simple modifications**: Make simple modifications to the solution to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "20. **Customization of the rating formula**: Customize the rating formula to fit the specific needs of the problem. This helps to ensure that the solution is tailored to the specific needs of the problem and that any predictions are based on a deep understanding of the domain.\n",
      "\n",
      "21. **Use of additional parameters**: Use additional parameters to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "22. **Prediction formula**: Use a prediction formula to make predictions and inform decisions. This helps to ensure that the solution is accurate and reliable, and that any predictions are based on a solid foundation.\n",
      "\n",
      "23. **Code implementation**: Implement the solution using code to ensure that it is robust and accurate. This\n"
     ]
    }
   ],
   "source": [
    "if N!=\"ALL\":\n",
    "    summary, summary_md = summarize_subsummaries(combined[0], True, \"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Comp 1 Prompt and Output\n",
    "\n",
    "Here, Gemma seems to say it has summarized the prompt key points and their descriptions. Yet it provides no key points as final output, and no descriptions. It also claims there are no data analysis methods mentioned, even if just above it there is one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T07:58:45.719314Z",
     "iopub.status.busy": "2024-04-13T07:58:45.718647Z",
     "iopub.status.idle": "2024-04-13T07:58:45.726182Z",
     "shell.execute_reply": "2024-04-13T07:58:45.725032Z",
     "shell.execute_reply.started": "2024-04-13T07:58:45.719283Z"
    }
   },
   "source": [
    "## Rerun the Final Summary for Competition 2 with Debug Info\n",
    "\n",
    "Now lets check similarly, the second competition in the selected set of 5. It has 2 subsets, which the debug info will also print with the prompt below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# number of subset summaries for this competition\n",
    "if N != \"ALL\":\n",
    "    print(len(combined[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: 505, output tokens: 396\n",
      "------- PROMPT ------- 496 tokens ------\n",
      "collect the key points listed in these writeup summaries into one list of key points.\n",
      "    include the descriptions given for these key points.\n",
      "    writeup summaries:\n",
      "    Based on the writeup summary, here are the key points that can be applied to similar problem-solving:\n",
      "\n",
      "**Understanding the problem**: Identify the key factors that affect the outcome, such as traffic volume, road conditions, and time of day.\n",
      "\n",
      "**Data preparation**: Handle missing values, clean the data, and perform feature engineering to ensure accurate and reliable data.\n",
      "\n",
      "**Feature selection**: Select the most relevant features that can help predict the outcome, such as traffic volume, road conditions, time of day, and weather.\n",
      "\n",
      "**Model selection**: Choose a suitable machine learning model, such as linear regression, decision trees, random forests, or neural networks.\n",
      "\n",
      "**Hyperparameter tuning**: Optimize the model's performance using techniques like grid search, random search, or Bayesian optimization.\n",
      "\n",
      "**Model evaluation**: Use metrics like MAE, MSE, or MAPE to evaluate the model's performance and ensure accuracy and reliability.\n",
      "\n",
      "**Ensemble methods**: Combine the predictions of multiple models to improve overall performance.\n",
      "\n",
      "**Handling temporal dependencies**: Use techniques like ARIMA or LSTM to capture temporal patterns in the data.\n",
      "\n",
      "**Handling spatial dependencies**: Use techniques like spatial autoregressive models or spatially-aware neural networks to capture spatial patterns in the data.\n",
      "\n",
      "**Interpretability**: Provide interpretability for the model's predictions using techniques like partial dependence plots or SHAP values.\n",
      "\n",
      "The data analysis methods used across the writeups are:\n",
      "\n",
      "1. **Data preparation**: Handling missing values, data cleaning, and feature engineering.\n",
      "2. **Feature selection**: Selecting the most relevant features.\n",
      "3. **Model selection**: Choosing a suitable machine learning model.\n",
      "4. **Hyperparameter tuning**: Optimizing the model's performance.\n",
      "5. **Model evaluation**: Evaluating the model's performance using metrics.\n",
      "6. **Ensemble methods**: Combining the predictions of multiple models.\n",
      "7. **Handling temporal dependencies**: Capturing temporal patterns in the data.\n",
      "8. **Handling spatial dependencies**: Capturing spatial patterns in the data.\n",
      "9. **Interpretability**: Providing interpretability for the model's predictions.\n",
      "\n",
      "These methods are related across writeups in that they are all part of the data science process, from understanding the problem to evaluating the model's performance. By applying these methods, data scientists can increase the chances of success in predicting travel times or solving similar problems.\n",
      "\n",
      "    \n",
      "------ SUMMARY: ------ 396 tokens ------\n",
      "Here is the list of key points with descriptions:\n",
      "\n",
      "1. **Understanding the problem**: Identify the key factors that affect the outcome, such as traffic volume, road conditions, and time of day. (Understanding the problem and its factors)\n",
      "2. **Data preparation**: Handle missing values, clean the data, and perform feature engineering to ensure accurate and reliable data. (Preparing the data for analysis)\n",
      "3. **Feature selection**: Select the most relevant features that can help predict the outcome, such as traffic volume, road conditions, time of day, and weather. (Choosing the most important data points)\n",
      "4. **Model selection**: Choose a suitable machine learning model, such as linear regression, decision trees, random forests, or neural networks. (Selecting the best algorithm for the problem)\n",
      "5. **Hyperparameter tuning**: Optimize the model's performance using techniques like grid search, random search, or Bayesian optimization. (Adjusting the model's parameters for best results)\n",
      "6. **Model evaluation**: Use metrics like MAE, MSE, or MAPE to evaluate the model's performance and ensure accuracy and reliability. (Assessing the model's performance)\n",
      "7. **Ensemble methods**: Combine the predictions of multiple models to improve overall performance. (Combining multiple models for better results)\n",
      "8. **Handling temporal dependencies**: Use techniques like ARIMA or LSTM to capture temporal patterns in the data. (Accounting for changes over time)\n",
      "9. **Handling spatial dependencies**: Use techniques like spatial autoregressive models or spatially-aware neural networks to capture spatial patterns in the data. (Accounting for relationships between locations)\n",
      "10. **Interpretability**: Provide interpretability for the model's predictions using techniques like partial dependence plots or SHAP values. (Explaining the model's decisions)\n",
      "\n",
      "These key points cover the various stages of the data science process, from understanding the problem to evaluating the model's performance, and provide a comprehensive framework for solving similar problems.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "if N != \"ALL\":\n",
    "    summary, summary_md = summarize_subsummaries(combined[1], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Comp 2 Prompt and Output\n",
    "\n",
    "This time Gemma seems to have lost it even better here, the answer mentions not finding any information about datasets, which is true but not related to the prompt in any way. The word dataset is not mentioned in the given input context at all, just a request to summarize the key points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Prompt\n",
    "\n",
    "In the above debug prints, we see that my prompting might confuse Gemma a bit in asking to summarize multiple writeup summaries, but just concatenating them all together. So lets try giving it a clue where the next writeup summary starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: 550, output tokens: 1000\n",
      "------- PROMPT ------- 541 tokens ------\n",
      "collect the key points listed in these writeup summaries into one list of key points.\n",
      "    include the descriptions given for these key points.\n",
      "    writeup summaries:\n",
      "    \n",
      "\n",
      "writeup 0\n",
      "Based on the writeup summaries, here are the key points that can be applied to similar datascience problems:\n",
      "\n",
      "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly.\n",
      "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches.\n",
      "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach.\n",
      "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions.\n",
      "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve.\n",
      "6. **Engage with the community**: Engage with the community to share knowledge and learn from others.\n",
      "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings.\n",
      "8. **Use historical data**: Use historical data to inform predictions and make informed decisions.\n",
      "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games.\n",
      "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances.\n",
      "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions.\n",
      "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them.\n",
      "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions.\n",
      "14. **Iterative refinement**: Refine predictions through multiple iterations.\n",
      "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions.\n",
      "\n",
      "The data analysis methods used across the writeups include:\n",
      "\n",
      "* Weighting and decay\n",
      "* Padding and normalization\n",
      "* Iterative calculation\n",
      "* Incorporating future results\n",
      "* Simple modifications\n",
      "* Exploration of established methods\n",
      "* Customization of the rating formula\n",
      "* Use of iterative rating formula\n",
      "* Weighting and normalization\n",
      "* Use of additional parameters\n",
      "* Prediction formula\n",
      "* Code implementation\n",
      "\n",
      "These methods are related across the writeups in that they all involve using different techniques to develop a robust and accurate rating system. The methods are used to handle missing data, refine predictions, and account for changing circumstances. The use of iterative calculation, weighting and normalization, and incorporating future results are common across the writeups, indicating that these methods are effective in developing a robust rating system.\n",
      "\n",
      "    \n",
      "------ SUMMARY: ------ 1000 tokens ------\n",
      "Here is the list of key points with descriptions:\n",
      "\n",
      "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly. This helps to ensure that everyone involved in the project is on the same page and that the solution is tailored to the specific needs of the problem.\n",
      "\n",
      "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches. This helps to ensure that the best solution is found and that the problem is solved in the most effective way possible.\n",
      "\n",
      "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach. This helps to speed up the development process and to ensure that the solution is robust and accurate.\n",
      "\n",
      "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions. This helps to ensure that the solution is tested thoroughly and that any issues are identified and addressed early on.\n",
      "\n",
      "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve. This helps to ensure that the solution is refined and improved over time, and that any mistakes are learned from.\n",
      "\n",
      "6. **Engage with the community**: Engage with the community to share knowledge and learn from others. This helps to ensure that the solution is the best it can be and that any issues are identified and addressed quickly.\n",
      "\n",
      "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings. This helps to ensure that the solution is accurate and reliable.\n",
      "\n",
      "8. **Use historical data**: Use historical data to inform predictions and make informed decisions. This helps to ensure that the solution is based on real-world data and that any predictions are accurate.\n",
      "\n",
      "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions. This helps to ensure that the solution is accurate and reliable, and that any predictions are based on a solid foundation.\n",
      "\n",
      "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them. This helps to ensure that the solution is robust and accurate, even in unusual or unexpected situations.\n",
      "\n",
      "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions. This helps to ensure that the solution is innovative and effective.\n",
      "\n",
      "14. **Iterative refinement**: Refine predictions through multiple iterations. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions. This helps to ensure that the solution is tailored to the specific needs of the problem and that any predictions are based on a deep understanding of the domain.\n",
      "\n",
      "16. **Use weighting and decay**: Use weighting and decay to handle missing data and refine predictions. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "17. **Use padding and normalization**: Use padding and normalization to handle missing data and refine predictions. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "18. **Use iterative calculation**: Use iterative calculation to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "19. **Use incorporating future results**: Use incorporating future results to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "20. **Use simple modifications**: Use simple modifications to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "21. **Use exploration of established methods**: Use exploration of established methods to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "22. **Use customization of the rating formula**: Use customization of the rating formula to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "23. **Use use of iterative rating formula**: Use use of iterative rating formula to refine predictions and account for changing circumstances. This helps to ensure that the\n"
     ]
    }
   ],
   "source": [
    "if N != \"ALL\":\n",
    "    summary, summary_md = summarize_subsummaries(combined[0], True, \"subtitle writeup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did it Help?\n",
    "\n",
    "Well, giving Gemma subtitles in the input actually seems to have helped it do a good job. So lets see with a bit better formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N != \"ALL\":\n",
    "    summary_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And Again a Slightly Different prompt\n",
    "\n",
    "Instead of subtitling the subset summaries as \"writeup X\", lets try a more correct \"writeups summary X\" and see if it has any effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: 551, output tokens: 1000\n",
      "------- PROMPT ------- 542 tokens ------\n",
      "collect the key points listed in these writeup summaries into one list of key points.\n",
      "    include the descriptions given for these key points.\n",
      "    writeup summaries:\n",
      "    \n",
      "\n",
      "writeups summary 0\n",
      "Based on the writeup summaries, here are the key points that can be applied to similar datascience problems:\n",
      "\n",
      "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly.\n",
      "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches.\n",
      "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach.\n",
      "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions.\n",
      "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve.\n",
      "6. **Engage with the community**: Engage with the community to share knowledge and learn from others.\n",
      "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings.\n",
      "8. **Use historical data**: Use historical data to inform predictions and make informed decisions.\n",
      "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games.\n",
      "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances.\n",
      "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions.\n",
      "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them.\n",
      "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions.\n",
      "14. **Iterative refinement**: Refine predictions through multiple iterations.\n",
      "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions.\n",
      "\n",
      "The data analysis methods used across the writeups include:\n",
      "\n",
      "* Weighting and decay\n",
      "* Padding and normalization\n",
      "* Iterative calculation\n",
      "* Incorporating future results\n",
      "* Simple modifications\n",
      "* Exploration of established methods\n",
      "* Customization of the rating formula\n",
      "* Use of iterative rating formula\n",
      "* Weighting and normalization\n",
      "* Use of additional parameters\n",
      "* Prediction formula\n",
      "* Code implementation\n",
      "\n",
      "These methods are related across the writeups in that they all involve using different techniques to develop a robust and accurate rating system. The methods are used to handle missing data, refine predictions, and account for changing circumstances. The use of iterative calculation, weighting and normalization, and incorporating future results are common across the writeups, indicating that these methods are effective in developing a robust rating system.\n",
      "\n",
      "    \n",
      "------ SUMMARY: ------ 1000 tokens ------\n",
      "Here is the list of key points with descriptions:\n",
      "\n",
      "1. **Clearly define the problem and its requirements**: Understand the problem and its requirements, and define them clearly. This helps to ensure that everyone involved in the project is on the same page and that the solution is tailored to the specific needs of the problem.\n",
      "\n",
      "2. **Explore different approaches**: Don't be afraid to try new things and explore different approaches. This helps to ensure that the best solution is found and that the problem is solved in the most effective way possible.\n",
      "\n",
      "3. **Code sharing and collaboration**: Share code and collaborate with others to learn from their experiences and improve your approach. This helps to speed up the development process and to ensure that the solution is robust and accurate.\n",
      "\n",
      "4. **Develop an experimentation framework**: Develop a framework for experimentation to rapidly prototype and refine your solutions. This helps to ensure that the solution is tested thoroughly and that any issues are identified and addressed early on.\n",
      "\n",
      "5. **View failure as an opportunity to learn**: View failure as an opportunity to learn and improve. This helps to ensure that the solution is refined and improved over time, and that any mistakes are learned from.\n",
      "\n",
      "6. **Engage with the community**: Engage with the community to share knowledge and learn from others. This helps to ensure that the solution is the best it can be and that any issues are identified and addressed quickly.\n",
      "\n",
      "7. **Design a robust rating system**: Design a robust rating system that takes into account various factors, such as player performance and opponent ratings. This helps to ensure that the solution is accurate and reliable.\n",
      "\n",
      "8. **Use historical data**: Use historical data to inform predictions and make informed decisions. This helps to ensure that the solution is based on real-world data and that any predictions are accurate.\n",
      "\n",
      "9. **Handle missing data**: Handle missing data using techniques such as using faked opponents and reducing ratings for players with less than 15 weighted games. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "10. **Iterative approach**: Use an iterative approach to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "11. **Use well-defined metrics and formulas**: Use well-defined metrics and formulas to make predictions and inform decisions. This helps to ensure that the solution is accurate and reliable, and that any predictions are based on a solid foundation.\n",
      "\n",
      "12. **Handle edge cases**: Consider edge cases and develop strategies to handle them. This helps to ensure that the solution is robust and accurate, even in unusual or unexpected situations.\n",
      "\n",
      "13. **Use creative solutions**: Use creative solutions to handle missing data and improve the accuracy of predictions. This helps to ensure that the solution is innovative and effective.\n",
      "\n",
      "14. **Iterative refinement**: Refine predictions through multiple iterations. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "15. **Use domain-specific knowledge**: Use domain-specific knowledge to inform predictions and make informed decisions. This helps to ensure that the solution is tailored to the specific needs of the problem and that any predictions are based on a deep understanding of the domain.\n",
      "\n",
      "16. **Use weighting and decay**: Use weighting and decay to handle missing data and refine predictions. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "17. **Use padding and normalization**: Use padding and normalization to handle missing data and refine predictions. This helps to ensure that the solution is robust and accurate, even in the presence of missing data.\n",
      "\n",
      "18. **Use iterative calculation**: Use iterative calculation to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "19. **Use incorporating future results**: Use incorporating future results to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "20. **Use simple modifications**: Use simple modifications to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "21. **Use exploration of established methods**: Use exploration of established methods to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "22. **Use customization of the rating formula**: Use customization of the rating formula to refine predictions and account for changing circumstances. This helps to ensure that the solution is refined and improved over time, and that any issues are identified and addressed early on.\n",
      "\n",
      "23. **Use use of iterative rating formula**: Use use of iterative rating formula to refine predictions and account for changing circumstances. This helps to ensure that the\n"
     ]
    }
   ],
   "source": [
    "if N != \"ALL\":\n",
    "    summary, summary_md = summarize_subsummaries(combined[0], True, \"writeup summaries title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any Difference?\n",
    "\n",
    "Again, the results seem to be much better than just concatenating the summaries as input for final summarization. And it actually seems almost identical. So just subtitling the input sections seem to be needed, otherwise Gemma gets all confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N != \"ALL\":\n",
    "    summary_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Summarization Conclusions So Far\n",
    "\n",
    "You need to subtitle your subsets in the input context. What more can I say.. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# List of all your lists and their corresponding file names\n",
    "data = {\n",
    "    \"writeup_summaries\": writeup_summaries,\n",
    "    \"writeup_summaries_md\": writeup_summaries_md,\n",
    "    \"overall_summaries\": overall_summaries,\n",
    "    \"processed_titles\": processed_titles,\n",
    "    \"processed_titles_list\": processed_titles_list,\n",
    "    \"skipped_titles\": skipped_titles,\n",
    "#    \"skipped_titles_list\": skipped_titles_list,\n",
    "    \"overall_summary_prompts\": overall_summary_prompts,\n",
    "    \"prompts\": prompts,\n",
    "    \"writeups\": writeups,\n",
    "    \"prompt_lengths\": prompt_lengths,\n",
    "    \"writeup_lengths\": writeup_lengths,\n",
    "    \"summary_lengths\": summary_lengths,\n",
    "    \"resummarized_simple\": resummarized_simple,\n",
    "    \"resummarized_md_simple\": resummarized_md_simple,\n",
    "    \"resummarized_writeup\": resummarized_writeup,\n",
    "    \"resummarized_md_writeup\": resummarized_md_writeup,\n",
    "    \"resummarized_writeup_summary\": resummarized_writeup_summary,\n",
    "    \"resummarized_md_writeup_summary\": resummarized_md_writeup_summary,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'data' is your dictionary\n",
    "with open(f'data_{split_size}.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data back in\n",
    "with open(f'data_{split_size}.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the number of writeups per competition\n",
    "writeup_counts = df_writeups.groupby(\"Title of Competition\").size()\n",
    "\n",
    "# Create a DataFrame for writeup counts\n",
    "df_writeup_counts = pd.DataFrame({\n",
    "    'Competition': writeup_counts.index,\n",
    "    'Number of Writeups': writeup_counts.values\n",
    "})\n",
    "\n",
    "# Rename the 'comp_name' column in df_comp_meta to 'Competition' for the merge\n",
    "df_comp_meta_renamed = df_comp_meta.rename(columns={'comp_name': 'Competition'})\n",
    "\n",
    "# Merge the two DataFrames on the 'Competition' column\n",
    "df_summary = pd.merge(df_writeup_counts, df_comp_meta_renamed, on='Competition', how='outer')\n",
    "\n",
    "# Replace NaN values in 'Number of Writeups' with 0\n",
    "df_summary['Number of Writeups'] = df_summary['Number of Writeups'].fillna(0)\n",
    "\n",
    "# Create a new column 'Metadata Available' that is True if 'desc' is not NaN\n",
    "df_summary['Metadata Available'] = ~df_summary['desc'].isna()\n",
    "\n",
    "# Reset the index\n",
    "df_summary.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number of Writeups', 'teams', 'competitors', 'Entries', 'start_date',\n",
       "       'start_year', 'final_date', 'final_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all column names in df_summary that are type float\n",
    "float_cols = df_summary.select_dtypes(include=['float']).columns\n",
    "float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with -1 for columns in float_cols\n",
    "df_summary[float_cols] = df_summary[float_cols].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competition</th>\n",
       "      <th>Number of Writeups</th>\n",
       "      <th>comp_Reward</th>\n",
       "      <th>comp_link</th>\n",
       "      <th>teams</th>\n",
       "      <th>competitors</th>\n",
       "      <th>Entries</th>\n",
       "      <th>Tag</th>\n",
       "      <th>desc</th>\n",
       "      <th>code_link</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_year</th>\n",
       "      <th>final_date</th>\n",
       "      <th>final_month</th>\n",
       "      <th>final_year</th>\n",
       "      <th>Metadata Available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iNaturalist Challenge at FGVC5</td>\n",
       "      <td>0</td>\n",
       "      <td>Kudos</td>\n",
       "      <td>https://www.kaggle.com/competitions/inaturalis...</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>759</td>\n",
       "      <td>meanbesterroratk</td>\n",
       "      <td>\\nAs part of the FGVC5 workshop at CVPR 2018 w...</td>\n",
       "      <td>https://www.kaggle.com/competitions/inaturalis...</td>\n",
       "      <td>23</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>May</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.071x - The Analytics Edge (Spring 2015)</td>\n",
       "      <td>0</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>2920</td>\n",
       "      <td>2920</td>\n",
       "      <td>41624</td>\n",
       "      <td>auc</td>\n",
       "      <td>IMPORTANT NOTE: This competition is only open ...</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>13</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>May</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.071x - The Analytics Edge (Spring 2015)</td>\n",
       "      <td>0</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>2920</td>\n",
       "      <td>2920</td>\n",
       "      <td>41624</td>\n",
       "      <td>auc</td>\n",
       "      <td>IMPORTANT NOTE: This competition is only open ...</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>4</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st and Future - Player Contact Detection</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 Newsgroups Ciphertext Challenge</td>\n",
       "      <td>0</td>\n",
       "      <td>Swag</td>\n",
       "      <td>https://www.kaggle.com/competitions/20-newsgro...</td>\n",
       "      <td>142</td>\n",
       "      <td>145</td>\n",
       "      <td>1139</td>\n",
       "      <td>text data</td>\n",
       "      <td>\\nThis isn't your classic decoder ring puzzle ...</td>\n",
       "      <td>https://www.kaggle.com/code/n0rm41/let-s-have-fun</td>\n",
       "      <td>14</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Competition  Number of Writeups comp_Reward  \\\n",
       "0              iNaturalist Challenge at FGVC5                   0       Kudos   \n",
       "1  15.071x - The Analytics Edge (Spring 2015)                   0   Knowledge   \n",
       "2  15.071x - The Analytics Edge (Spring 2015)                   0   Knowledge   \n",
       "3   1st and Future - Player Contact Detection                  12         NaN   \n",
       "4          20 Newsgroups Ciphertext Challenge                   0        Swag   \n",
       "\n",
       "                                           comp_link  teams  competitors  \\\n",
       "0  https://www.kaggle.com/competitions/inaturalis...     59           71   \n",
       "1  https://www.kaggle.com/competitions/15-071x-th...   2920         2920   \n",
       "2  https://www.kaggle.com/competitions/15-071x-th...   2920         2920   \n",
       "3                                                NaN     -1           -1   \n",
       "4  https://www.kaggle.com/competitions/20-newsgro...    142          145   \n",
       "\n",
       "   Entries               Tag  \\\n",
       "0      759  meanbesterroratk   \n",
       "1    41624               auc   \n",
       "2    41624               auc   \n",
       "3       -1               NaN   \n",
       "4     1139         text data   \n",
       "\n",
       "                                                desc  \\\n",
       "0  \\nAs part of the FGVC5 workshop at CVPR 2018 w...   \n",
       "1  IMPORTANT NOTE: This competition is only open ...   \n",
       "2  IMPORTANT NOTE: This competition is only open ...   \n",
       "3                                                NaN   \n",
       "4  \\nThis isn't your classic decoder ring puzzle ...   \n",
       "\n",
       "                                           code_link  start_date start_month  \\\n",
       "0  https://www.kaggle.com/competitions/inaturalis...          23        Feb    \n",
       "1  https://www.kaggle.com/competitions/15-071x-th...          13        Apr    \n",
       "2  https://www.kaggle.com/competitions/15-071x-th...           4        Apr    \n",
       "3                                                NaN          -1         NaN   \n",
       "4  https://www.kaggle.com/code/n0rm41/let-s-have-fun          14        Dec    \n",
       "\n",
       "   start_year  final_date final_month  final_year  Metadata Available  \n",
       "0        2018          29        May         2018                True  \n",
       "1        2015           5        May         2015                True  \n",
       "2        2015           4        Apr         2015                True  \n",
       "3          -1          -1         NaN          -1               False  \n",
       "4        2018          17        Jan         2019                True  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all columns in float_cols to integer type\n",
    "df_summary[float_cols] = df_summary[float_cols].astype(int)\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "too_long_indices = []\n",
    "overall_summaries_raw = []\n",
    "\n",
    "for idx, sum in enumerate(overall_summaries):\n",
    "    # check if sum is string\n",
    "    if isinstance(sum, str):\n",
    "        overall_summaries_raw.append(sum)\n",
    "        too_long_indices.append(idx)\n",
    "    else:\n",
    "        overall_summaries_raw.append(sum.data)\n",
    "\n",
    "too_long_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competition</th>\n",
       "      <th>Resummarized Summary Simple</th>\n",
       "      <th>Resummarized Summary Writeup</th>\n",
       "      <th>Resummarized Summary Writeup Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chess ratings - Elo versus the Rest of the World</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RTA Freeway Travel Time Prediction</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predict Grant Applications</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay Alert! The Ford Challenge</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Overfit!</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "      <td>Here is the list of key points with descriptio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Competition  \\\n",
       "0  Chess ratings - Elo versus the Rest of the World   \n",
       "1                RTA Freeway Travel Time Prediction   \n",
       "2                        Predict Grant Applications   \n",
       "3                    Stay Alert! The Ford Challenge   \n",
       "4                                    Don't Overfit!   \n",
       "\n",
       "                         Resummarized Summary Simple  \\\n",
       "0  Here is the list of key points with descriptio...   \n",
       "1  Here is the list of key points with descriptio...   \n",
       "2  Here is the list of key points with descriptio...   \n",
       "3  Here is the list of key points with descriptio...   \n",
       "4  Here is the list of key points with descriptio...   \n",
       "\n",
       "                        Resummarized Summary Writeup  \\\n",
       "0  Here is the list of key points with descriptio...   \n",
       "1  Here is the list of key points with descriptio...   \n",
       "2  Here is the list of key points with descriptio...   \n",
       "3  Here is the list of key points with descriptio...   \n",
       "4  Here is the list of key points with descriptio...   \n",
       "\n",
       "                Resummarized Summary Writeup Summary  \n",
       "0  Here is the list of key points with descriptio...  \n",
       "1  Here is the list of key points with descriptio...  \n",
       "2  Here is the list of key points with descriptio...  \n",
       "3  Here is the list of key points with descriptio...  \n",
       "4  Here is the list of key points with descriptio...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine compatition names and resummarized summaries into a dataframe\n",
    "if N != \"ALL\":\n",
    "    df_resummarized = pd.DataFrame({\n",
    "        'Competition': processed_titles_list,\n",
    "    #    'Resummarized Summary': overall_summaries_raw\n",
    "        'Resummarized Summary Simple': data[\"resummarized_simple\"],\n",
    "        'Resummarized Summary Writeup': data[\"resummarized_writeup\"],\n",
    "        'Resummarized Summary Writeup Summary': data[\"resummarized_writeup_summary\"]\n",
    "    })\n",
    "else:\n",
    "    df_resummarized = pd.DataFrame({\n",
    "        'Competition': processed_titles_list,\n",
    "        'Overall Summary': data[\"resummarized_simple\"],\n",
    "    })\n",
    "\n",
    "df_resummarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Competition</th>\n",
       "      <th>Number of Writeups</th>\n",
       "      <th>comp_Reward</th>\n",
       "      <th>comp_link</th>\n",
       "      <th>teams</th>\n",
       "      <th>competitors</th>\n",
       "      <th>Entries</th>\n",
       "      <th>Tag</th>\n",
       "      <th>desc</th>\n",
       "      <th>code_link</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_year</th>\n",
       "      <th>final_date</th>\n",
       "      <th>final_month</th>\n",
       "      <th>final_year</th>\n",
       "      <th>Metadata Available</th>\n",
       "      <th>Resummarized Summary Simple</th>\n",
       "      <th>Resummarized Summary Writeup</th>\n",
       "      <th>Resummarized Summary Writeup Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iNaturalist Challenge at FGVC5</td>\n",
       "      <td>0</td>\n",
       "      <td>Kudos</td>\n",
       "      <td>https://www.kaggle.com/competitions/inaturalis...</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>759</td>\n",
       "      <td>meanbesterroratk</td>\n",
       "      <td>\\nAs part of the FGVC5 workshop at CVPR 2018 w...</td>\n",
       "      <td>https://www.kaggle.com/competitions/inaturalis...</td>\n",
       "      <td>23</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>May</td>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.071x - The Analytics Edge (Spring 2015)</td>\n",
       "      <td>0</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>2920</td>\n",
       "      <td>2920</td>\n",
       "      <td>41624</td>\n",
       "      <td>auc</td>\n",
       "      <td>IMPORTANT NOTE: This competition is only open ...</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>13</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>May</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.071x - The Analytics Edge (Spring 2015)</td>\n",
       "      <td>0</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>2920</td>\n",
       "      <td>2920</td>\n",
       "      <td>41624</td>\n",
       "      <td>auc</td>\n",
       "      <td>IMPORTANT NOTE: This competition is only open ...</td>\n",
       "      <td>https://www.kaggle.com/competitions/15-071x-th...</td>\n",
       "      <td>4</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2015</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st and Future - Player Contact Detection</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 Newsgroups Ciphertext Challenge</td>\n",
       "      <td>0</td>\n",
       "      <td>Swag</td>\n",
       "      <td>https://www.kaggle.com/competitions/20-newsgro...</td>\n",
       "      <td>142</td>\n",
       "      <td>145</td>\n",
       "      <td>1139</td>\n",
       "      <td>text data</td>\n",
       "      <td>\\nThis isn't your classic decoder ring puzzle ...</td>\n",
       "      <td>https://www.kaggle.com/code/n0rm41/let-s-have-fun</td>\n",
       "      <td>14</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Competition  Number of Writeups comp_Reward  \\\n",
       "0              iNaturalist Challenge at FGVC5                   0       Kudos   \n",
       "1  15.071x - The Analytics Edge (Spring 2015)                   0   Knowledge   \n",
       "2  15.071x - The Analytics Edge (Spring 2015)                   0   Knowledge   \n",
       "3   1st and Future - Player Contact Detection                  12         NaN   \n",
       "4          20 Newsgroups Ciphertext Challenge                   0        Swag   \n",
       "\n",
       "                                           comp_link  teams  competitors  \\\n",
       "0  https://www.kaggle.com/competitions/inaturalis...     59           71   \n",
       "1  https://www.kaggle.com/competitions/15-071x-th...   2920         2920   \n",
       "2  https://www.kaggle.com/competitions/15-071x-th...   2920         2920   \n",
       "3                                                NaN     -1           -1   \n",
       "4  https://www.kaggle.com/competitions/20-newsgro...    142          145   \n",
       "\n",
       "   Entries               Tag  \\\n",
       "0      759  meanbesterroratk   \n",
       "1    41624               auc   \n",
       "2    41624               auc   \n",
       "3       -1               NaN   \n",
       "4     1139         text data   \n",
       "\n",
       "                                                desc  \\\n",
       "0  \\nAs part of the FGVC5 workshop at CVPR 2018 w...   \n",
       "1  IMPORTANT NOTE: This competition is only open ...   \n",
       "2  IMPORTANT NOTE: This competition is only open ...   \n",
       "3                                                NaN   \n",
       "4  \\nThis isn't your classic decoder ring puzzle ...   \n",
       "\n",
       "                                           code_link  start_date start_month  \\\n",
       "0  https://www.kaggle.com/competitions/inaturalis...          23        Feb    \n",
       "1  https://www.kaggle.com/competitions/15-071x-th...          13        Apr    \n",
       "2  https://www.kaggle.com/competitions/15-071x-th...           4        Apr    \n",
       "3                                                NaN          -1         NaN   \n",
       "4  https://www.kaggle.com/code/n0rm41/let-s-have-fun          14        Dec    \n",
       "\n",
       "   start_year  final_date final_month  final_year  Metadata Available  \\\n",
       "0        2018          29        May         2018                True   \n",
       "1        2015           5        May         2015                True   \n",
       "2        2015           4        Apr         2015                True   \n",
       "3          -1          -1         NaN          -1               False   \n",
       "4        2018          17        Jan         2019                True   \n",
       "\n",
       "  Resummarized Summary Simple Resummarized Summary Writeup  \\\n",
       "0                         NaN                          NaN   \n",
       "1                         NaN                          NaN   \n",
       "2                         NaN                          NaN   \n",
       "3                         NaN                          NaN   \n",
       "4                         NaN                          NaN   \n",
       "\n",
       "  Resummarized Summary Writeup Summary  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge df_resummarized with df_summary\n",
    "df_final = pd.merge(df_summary, df_resummarized, on='Competition', how='outer')\n",
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(f\"combined_df_{split_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary\n",
    "combined_dict = {}\n",
    "\n",
    "idx = 0\n",
    "# Iterate over processed_titles, writeup_dataframes, and combined simultaneously\n",
    "#for title, dataframe, combine in zip(processed_titles_list, writeup_dataframes_filtered, combined):\n",
    "for title, dataframe, combine in zip(processed_titles_list, writeup_dataframes_filtered, overall_summaries):\n",
    "    # For each title, create a new dictionary with keys \"writeup_dataframes\" and \"combined\"\n",
    "    combined_dict[title] = {\"writeup_dataframes\": dataframe, \"combined\": combine}\n",
    "    if title == \"2019 Data Science Bowl\":\n",
    "        print(idx)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the combined_dict to a pickle file\n",
    "with open(f'combined_dict_{split_size}.pickle', 'wb') as f:\n",
    "    pickle.dump(combined_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'combined_dict_{split_size}.pickle', 'rb') as f:\n",
    "    combined_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Subsets vs All-in-One\n",
    "\n",
    "I ran bigger sets of summaries on my local desktop and collected them into a dataset for look here at Kaggle without spending too much GPU time. So lets load that up and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter_df(split_size, more_than=10):\n",
    "    # Load the combined dataframe\n",
    "    if on_kaggle:\n",
    "        df = pd.read_csv(f\"/kaggle/input/gemma-summaries-for-kaggle-writeups/gemma_summaries_{split_size}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"combined_df_{split_size}.csv\")\n",
    "    print(f\"Loaded combined dataframe with shape {df.shape}\")\n",
    "    # Filter the dataframe for competitions with more than 10 writeups (or more_than param)\n",
    "    df_filtered = df[df[\"Number of Writeups\"] > more_than]\n",
    "    print(f\"Filtered dataframe has shape {df_filtered.shape}\")\n",
    "    # drop compos that had no metadata and were thus not processed\n",
    "    df_filtered = df_filtered[df_filtered[\"comp_Reward\"].notna()]\n",
    "    print(f\"Filtered dataframe has shape {df_filtered.shape}\")\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined dataframe with shape (554, 20)\n",
      "Filtered dataframe has shape (311, 20)\n",
      "Filtered dataframe has shape (284, 20)\n",
      "Loaded combined dataframe with shape (554, 20)\n",
      "Filtered dataframe has shape (311, 20)\n",
      "Filtered dataframe has shape (284, 20)\n",
      "Loaded combined dataframe with shape (554, 18)\n",
      "Filtered dataframe has shape (311, 18)\n",
      "Filtered dataframe has shape (284, 18)\n"
     ]
    }
   ],
   "source": [
    "df_5 = load_and_filter_df(5, 0)\n",
    "df_10 = load_and_filter_df(10, 0)\n",
    "df_all = load_and_filter_df(\"ALL\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data_5.pickle', 'rb') as f:\n",
    "    data_5 = pickle.load(f)\n",
    "with open(f'data_10.pickle', 'rb') as f:\n",
    "    data_10 = pickle.load(f)\n",
    "with open(f'data_ALL.pickle', 'rb') as f:\n",
    "    data_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 14, 13,  1, 33, 18, 11,  9,  3,  5, 31, 22,  2, 28, 19, 21,  6,\n",
       "       10,  7, 41, 30, 16,  4, 17, 15, 12,  8, 35, 23, 20, 29, 36, 26, 25,\n",
       "       27, 37, 32])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5[\"Number of Writeups\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition with 1 Writeup\n",
    "\n",
    "This one has only a single writeup, so the summarization should be simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Competition                                 AMS 2013-2014 Solar Energy Prediction Contest\n",
       "Number of Writeups                                                                      1\n",
       "comp_Reward                                                                          1000\n",
       "comp_link                               https://www.kaggle.com/competitions/ams-2014-s...\n",
       "teams                                                                                 160\n",
       "competitors                                                                           199\n",
       "Entries                                                                              2506\n",
       "Tag                                                                                   mae\n",
       "desc                                    Welcome to the American Meteorological Society...\n",
       "code_link                               https://www.kaggle.com/competitions/ams-2014-s...\n",
       "start_date                                                                              9\n",
       "start_month                                                                          Jul \n",
       "start_year                                                                           2013\n",
       "final_date                                                                             16\n",
       "final_month                                                                          Nov \n",
       "final_year                                                                           2013\n",
       "Metadata Available                                                                   True\n",
       "Resummarized Summary Simple             Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup            Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup Summary    Here is the list of key points with descriptio...\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5[df_5[\"Number of Writeups\"]==1].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 5\n",
    "\n",
    "Splitting 1 writeup into subsets of 5 results in just a single subset with the single writeup. So not much to look at, but lets look for having a complete process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Raw Feature Usage**: Consider using raw features when there are many features to consider, as they can be useful in capturing patterns in the data. However, feature engineering can help identify the most important features and reduce dimensionality.\n",
       "\n",
       "2. **Contiguous Validation**: When dealing with temporal data, use contiguous validation folds to capture patterns within each fold, which can help improve model performance.\n",
       "\n",
       "3. **Feature Selection**: When dealing with a large number of features, use feature selection techniques to identify the most important features, which can help reduce dimensionality and improve model performance.\n",
       "\n",
       "4. **Model Averaging**: Use model averaging to combine the predictions of multiple models, which can help reduce the variance of the predictions and improve overall performance.\n",
       "\n",
       "5. **Gradient Boosting**: Consider using Gradient Boosting or other ensemble methods when dealing with complex regression problems, as it is a powerful algorithm that can be effective for regression problems.\n",
       "\n",
       "6. **Data Analysis Methods**: The writeups highlight the importance of using various data analysis methods, including raw feature usage, contiguous validation, feature selection, model averaging, and gradient boosting, to develop a comprehensive approach to tackling a Kaggle data science competition.\n",
       "\n",
       "These key points are interconnected, with raw feature usage and feature selection being used to handle large numbers of features, contiguous validation being used to capture patterns in temporal data, and model averaging and gradient boosting being used to improve model performance.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp1 = df_5[df_5[\"Number of Writeups\"]==1][\"Competition\"].iloc[0]\n",
    "summy = df_5[df_5[\"Competition\"]==comp1][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 10\n",
    "\n",
    "For 1 writeup this is the same as subset 5. But lets see again.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Raw Feature Usage**: Consider using raw features when there are many features to consider, as they can be useful in capturing patterns in the data. However, feature engineering can help identify the most important features and reduce dimensionality.\n",
       "\n",
       "2. **Contiguous Validation**: When dealing with temporal data, use contiguous validation folds to capture patterns within each fold, which can help improve model performance.\n",
       "\n",
       "3. **Feature Selection**: When dealing with a large number of features, use feature selection techniques to identify the most important features, which can help reduce dimensionality and improve model performance.\n",
       "\n",
       "4. **Model Averaging**: Use model averaging to combine the predictions of multiple models, which can help reduce the variance of the predictions and improve overall performance.\n",
       "\n",
       "5. **Gradient Boosting**: Consider using Gradient Boosting or other ensemble methods when dealing with complex regression problems, as it is a powerful algorithm that can be effective for regression problems.\n",
       "\n",
       "6. **Data Analysis Methods**: The writeups highlight the importance of using various data analysis methods, including raw feature usage, contiguous validation, feature selection, model averaging, and gradient boosting, to develop a comprehensive approach to tackling a Kaggle data science competition.\n",
       "\n",
       "These key points are interconnected, with raw feature usage and feature selection being used to handle large numbers of features, contiguous validation being used to capture patterns in temporal data, and model averaging and gradient boosting being used to improve model performance.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_10[df_10[\"Competition\"]==comp1][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in one, no subsets\n",
    "\n",
    "Again, about the same but missing the extra step of re-summarizing the subset summaries. Because it already summarizes all writeup summaries in one step. This is why it has the same points practically but the structuring and wording differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeups, here are some guidelines for approaching a Kaggle data science competition:\n",
       "\n",
       "**Raw Feature Usage**: Consider the trade-offs between feature engineering and raw feature usage. Raw features can be useful when there are many features to consider, but feature engineering can help identify the most important features and reduce dimensionality.\n",
       "\n",
       "**Contiguous Validation**: When dealing with temporal data, consider using contiguous validation folds to capture patterns within each fold.\n",
       "\n",
       "**Feature Selection**: When dealing with a large number of features, consider using feature selection techniques to identify the most important features. This can help reduce dimensionality and improve model performance.\n",
       "\n",
       "**Model Averaging**: Model averaging can be a useful strategy when dealing with multiple models, as it can help reduce the variance of the predictions and improve overall performance.\n",
       "\n",
       "**Gradient Boosting**: Gradient Boosting is a powerful algorithm that can be effective for regression problems. Consider using Gradient Boosting or other ensemble methods when dealing with complex regression problems.\n",
       "\n",
       "**Data Analysis Methods**: The writeups highlight the following data analysis methods:\n",
       "\n",
       "* Raw feature usage\n",
       "* Contiguous validation\n",
       "* Feature selection\n",
       "* Model averaging\n",
       "* Gradient Boosting\n",
       "\n",
       "These methods are related across the writeups in the following ways:\n",
       "\n",
       "* Raw feature usage and feature selection are both used to handle the large number of features in the dataset.\n",
       "* Contiguous validation is used to capture patterns in the temporal data, which is related to the use of gradient boosting and model averaging to improve model performance.\n",
       "* Model averaging is used to combine the predictions of multiple models, which is related to the use of gradient boosting as a powerful algorithm for regression problems.\n",
       "\n",
       "By considering these guidelines and data analysis methods, you can develop a comprehensive approach to tackling a Kaggle data science competition.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_all[df_all[\"Competition\"]==comp1][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odd...\n",
    "\n",
    "The above \"all\" summary talks about \"both\" summaries, when there is only a single writeup. So a quick look at where does this come from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The following gives a summary of a Kaggle competition description, and a set of one or more writeups on solutions used in that competition, separated by ======.\n",
       "\n",
       "Use these to summarize a set of guidelines for ideas on how to approach a given Kaggle data science competition. \n",
       "\n",
       "Competition description summary: Here is a concise summary of the contest topic and goals:\n",
       "\n",
       "The contest aims to develop accurate short-term predictions of solar energy production at 98 Oklahoma Mesonet sites. The goal is to identify the best statistical and machine learning techniques for predicting daily solar energy totals, using numerical weather prediction data as input. The contest will evaluate predictions using training data from 1994-2007, public testing data from 2008-2009, and private testing data for a more recent period.<|eot_id|>\n",
       "\n",
       "\n",
       "\n",
       "======\n",
       "\n",
       " writeup summary:\n",
       " Here are the key points from a datascience application viewpoint for similar problem solving:\n",
       "\n",
       "1. **Raw feature usage**: The approach didn't involve much feature engineering, instead relying on raw features. This can be a good strategy when dealing with a large number of features, but may not always be the most effective approach.\n",
       "\n",
       "Lesson: Consider the trade-offs between feature engineering and raw feature usage. Raw features can be useful when there are many features to consider, but feature engineering can help identify the most important features and reduce dimensionality.\n",
       "\n",
       "2. **Contiguous validation**: The team used 3-fold contiguous validation, where each fold consisted of a contiguous period of years (e.g. 1994-1998). This can be a good strategy when dealing with temporal data, as it allows the model to learn patterns within each fold.\n",
       "\n",
       "Lesson: When dealing with temporal data, consider using contiguous validation folds to capture patterns within each fold.\n",
       "\n",
       "3. **Feature selection**: The team used all features from the forecast files without preprocessing, resulting in a large number of features (approximately 320). They also used features such as month of the year, distance to each used meso, and latitude difference to each meso.\n",
       "\n",
       "Lesson: When dealing with a large number of features, consider using feature selection techniques to identify the most important features. This can help reduce dimensionality and improve model performance.\n",
       "\n",
       "4. **Model averaging**: The team trained 11 models, one for each forecast member, and averaged the predictions to optimize MAE.\n",
       "\n",
       "Lesson: Model averaging can be a useful strategy when dealing with multiple models, as it can help reduce the variance of the predictions and improve overall performance.\n",
       "\n",
       "5. **Gradient Boosting**: The team used Python's GradientBoostedRegressor to optimize MAE.\n",
       "\n",
       "Lesson: Gradient Boosting is a powerful algorithm that can be effective for regression problems. Consider using Gradient Boosting or other ensemble methods when dealing with complex regression problems.\n",
       "\n",
       "Overall, this approach demonstrates a straightforward and effective strategy for dealing with a complex regression problem. By using raw features, contiguous validation, and model averaging, the team was able to achieve good results.<|eot_id|>\n",
       "\n",
       "\n",
       "\n",
       "======\n",
       "\n",
       " Focus on the key points of the writeups and how they might have helped achieving better score in the competition.Extract specifically used data analysis methods, and summarize how they are related across writeups.\n",
       "\n",
       "answer: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp1_idx = data_all[\"processed_titles_list\"].index(comp1)\n",
    "Markdown(data_all[\"overall_summary_prompts\"][comp1_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it seems to get confused by the separator ====== I used. Guess this model at this size has some training to take. Or need to be aware of these limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Writeups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Competition                             American Epilepsy Society Seizure Prediction C...\n",
       "Number of Writeups                                                                      5\n",
       "comp_Reward                                                                         25000\n",
       "comp_link                               https://www.kaggle.com/competitions/seizure-pr...\n",
       "teams                                                                                 504\n",
       "competitors                                                                           653\n",
       "Entries                                                                             17777\n",
       "Tag                                                                                   auc\n",
       "desc                                    Seizure forecasting systems hold promise for i...\n",
       "code_link                               https://www.kaggle.com/code/mpwolke/epilepsy-m...\n",
       "start_date                                                                             25\n",
       "start_month                                                                          Aug \n",
       "start_year                                                                           2014\n",
       "final_date                                                                             11\n",
       "final_month                                                                          Nov \n",
       "final_year                                                                           2014\n",
       "Metadata Available                                                                   True\n",
       "Resummarized Summary Simple             Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup            Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup Summary    Here is the list of key points with descriptio...\n",
       "Name: 30, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5[df_5[\"Number of Writeups\"]==5].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 5\n",
    "\n",
    "It is a single subset, and seems to summarize quite fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Problem understanding**: Take the time to thoroughly understand the goal and requirements of the competition. This involves gaining a deep understanding of the problem and what is expected of the solution.\n",
       "\n",
       "2. **Data exploration**: Perform exploratory data analysis (EDA) to gain insights into the data and identify potential features to extract. This helps to understand the data distribution, identify patterns, and detect anomalies.\n",
       "\n",
       "3. **Feature engineering**: Engineer features that are relevant to the problem and suitable for modeling. This involves developing diverse feature sets and using regularization techniques to prevent overfitting.\n",
       "\n",
       "4. **Model selection**: Select a suitable machine learning algorithm based on the data and problem characteristics. This involves choosing an algorithm that is well-suited to the problem and data type.\n",
       "\n",
       "5. **Model evaluation**: Evaluate your model using techniques such as cross-validation to ensure generalizability. This helps to assess the model's performance and identify areas for improvement.\n",
       "\n",
       "6. **Code organization and documentation**: Organize your code in a way that makes it easy to understand and maintain, and provide clear documentation and reports. This helps to ensure that the code is readable and modifiable.\n",
       "\n",
       "7. **Openness to feedback**: Be open to feedback and willing to improve your solution based on input from others. This involves being receptive to suggestions and willing to make changes to improve the solution.\n",
       "\n",
       "8. **Ensemble approach**: Combine multiple models to improve performance. This involves combining the predictions of multiple models to achieve better results.\n",
       "\n",
       "9. **Domain knowledge integration**: Integrate domain knowledge into the problem-solving process. This involves incorporating expert knowledge and insights into the solution.\n",
       "\n",
       "10. **Iterative improvement**: Continuously learn and improve your solution through experimentation and refinement. This involves refining the solution through repeated testing and iteration.\n",
       "\n",
       "11. **Problem-specific approaches**: Develop problem-specific approaches that take into account the unique characteristics of the problem. This involves developing solutions that are tailored to the specific problem and data.\n",
       "\n",
       "12. **Code sharing**: Share your code and report publicly to collaborate with others and contribute to the datascience community. This involves sharing knowledge and expertise with others to advance the field.\n",
       "\n",
       "13. **Regularization techniques**: Use regularization techniques such as Lasso, elastic net, dropout, and early stopping to prevent overfitting. This helps to prevent the model from becoming too complex and overfitting the training data.\n",
       "\n",
       "14. **Signal processing techniques**: Use signal processing techniques such as time-frequency features and spectral features to extract relevant information from the data. This helps to extract meaningful features from the data.\n",
       "\n",
       "15. **Neural networks**: Use neural networks as a machine learning algorithm. This involves using a neural network to model the relationship between the input and output variables.\n",
       "\n",
       "16. **GLM**: Use Generalized Linear Models (GLM) as a machine learning algorithm. This involves using a GLM to model the relationship between the input and output variables.\n",
       "\n",
       "17. **Random Forest**: Use Random Forest as a machine learning algorithm. This involves using a Random Forest to model the relationship between the input and output variables.\n",
       "\n",
       "18. **Support Vector Machines**: Use Support Vector Machines (SVM) as a machine learning algorithm. This involves using an SVM to model the relationship between the input and output variables.\n",
       "\n",
       "19. **Cross-validation**: Use cross-validation to evaluate the model's performance. This involves splitting the data into training and testing sets and using the testing set to evaluate the model's performance.\n",
       "\n",
       "20. **Early stopping**: Use early stopping to prevent overfitting. This involves stopping the training process early to prevent the model from becoming too complex and overfitting the training data.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp5 = df_5[df_5[\"Number of Writeups\"]==5][\"Competition\"].iloc[0]\n",
    "summy = df_5[df_5[\"Competition\"]==comp5][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 10\n",
    "\n",
    "Practically the same as above subsets of 5. No wonder since the 5 writeups fit into both as a single subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Problem understanding**: Take the time to thoroughly understand the goal and requirements of the competition. This involves gaining a deep understanding of the problem and what is expected of the solution.\n",
       "\n",
       "2. **Data exploration**: Perform exploratory data analysis (EDA) to gain insights into the data and identify potential features to extract. This helps to understand the data distribution, identify patterns, and detect anomalies.\n",
       "\n",
       "3. **Feature engineering**: Engineer features that are relevant to the problem and suitable for modeling. This involves developing diverse feature sets and using regularization techniques to prevent overfitting.\n",
       "\n",
       "4. **Model selection**: Select a suitable machine learning algorithm based on the data and problem characteristics. This involves choosing an algorithm that is well-suited to the problem and data type.\n",
       "\n",
       "5. **Model evaluation**: Evaluate your model using techniques such as cross-validation to ensure generalizability. This helps to assess the model's performance and identify areas for improvement.\n",
       "\n",
       "6. **Code organization and documentation**: Organize your code in a way that makes it easy to understand and maintain, and provide clear documentation and reports. This helps to ensure that the code is readable and modifiable.\n",
       "\n",
       "7. **Openness to feedback**: Be open to feedback and willing to improve your solution based on input from others. This involves being receptive to suggestions and willing to make changes to improve the solution.\n",
       "\n",
       "8. **Ensemble approach**: Combine multiple models to improve performance. This involves combining the predictions of multiple models to achieve better results.\n",
       "\n",
       "9. **Domain knowledge integration**: Integrate domain knowledge into the problem-solving process. This involves incorporating expert knowledge and insights into the solution.\n",
       "\n",
       "10. **Iterative improvement**: Continuously learn and improve your solution through experimentation and refinement. This involves refining the solution through repeated testing and iteration.\n",
       "\n",
       "11. **Problem-specific approaches**: Develop problem-specific approaches that take into account the unique characteristics of the problem. This involves developing solutions that are tailored to the specific problem and data.\n",
       "\n",
       "12. **Code sharing**: Share your code and report publicly to collaborate with others and contribute to the datascience community. This involves sharing knowledge and expertise with others to advance the field.\n",
       "\n",
       "13. **Regularization techniques**: Use regularization techniques such as Lasso, elastic net, dropout, and early stopping to prevent overfitting. This helps to prevent the model from becoming too complex and overfitting the training data.\n",
       "\n",
       "14. **Signal processing techniques**: Use signal processing techniques such as time-frequency features and spectral features to extract relevant information from the data. This helps to extract meaningful features from the data.\n",
       "\n",
       "15. **Neural networks**: Use neural networks as a machine learning algorithm. This involves using a neural network to model the relationship between the input and output variables.\n",
       "\n",
       "16. **GLM**: Use Generalized Linear Models (GLM) as a machine learning algorithm. This involves using a GLM to model the relationship between the input and output variables.\n",
       "\n",
       "17. **Random Forest**: Use Random Forest as a machine learning algorithm. This involves using a Random Forest to model the relationship between the input and output variables.\n",
       "\n",
       "18. **Support Vector Machines**: Use Support Vector Machines (SVM) as a machine learning algorithm. This involves using an SVM to model the relationship between the input and output variables.\n",
       "\n",
       "19. **Cross-validation**: Use cross-validation to evaluate the model's performance. This involves splitting the data into training and testing sets and using the testing set to evaluate the model's performance.\n",
       "\n",
       "20. **Early stopping**: Use early stopping to prevent overfitting. This involves stopping the training process early to prevent the model from becoming too complex and overfitting the training data.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_10[df_10[\"Competition\"]==comp5][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Subsets, All in One\n",
    "\n",
    "The results are about the same but it lacks on step in re-summarization, so the result is a bit more \"raw\" and focused (the \"additional points\" start is not there):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summaries, here are the key points that can be applied to similar problem-solving approaches in datascience:\n",
       "\n",
       "1. **Problem understanding**: Take the time to thoroughly understand the goal and requirements of the competition.\n",
       "2. **Data exploration**: Perform exploratory data analysis (EDA) to gain insights into the data and identify potential features to extract.\n",
       "3. **Feature engineering**: Engineer features that are relevant to the problem and suitable for modeling.\n",
       "4. **Model selection**: Select a suitable machine learning algorithm based on the data and problem characteristics.\n",
       "5. **Model evaluation**: Evaluate your model using techniques such as cross-validation to ensure generalizability.\n",
       "6. **Code organization and documentation**: Organize your code in a way that makes it easy to understand and maintain, and provide clear documentation and reports.\n",
       "7. **Openness to feedback**: Be open to feedback and willing to improve your solution based on input from others.\n",
       "8. **Ensemble approach**: Combine multiple models to improve performance.\n",
       "9. **Domain knowledge integration**: Integrate domain knowledge into the problem-solving process.\n",
       "10. **Feature engineering**: Develop diverse feature sets and use regularization techniques to prevent overfitting.\n",
       "11. **Code sharing**: Share your code and report publicly to collaborate with others and contribute to the datascience community.\n",
       "12. **Iterative improvement**: Continuously learn and improve your solution through experimentation and refinement.\n",
       "13. **Problem-specific approaches**: Develop problem-specific approaches that take into account the unique characteristics of the problem.\n",
       "\n",
       "The data analysis methods used across the writeups include:\n",
       "\n",
       "* Exploratory data analysis (EDA)\n",
       "* Feature engineering (e.g., time-frequency features, spectral features, signal processing techniques)\n",
       "* Model selection (e.g., neural networks, GLM, Random Forest, Support Vector Machines)\n",
       "* Model evaluation (e.g., cross-validation)\n",
       "* Regularization techniques (e.g., Lasso, elastic net, dropout, early stopping)\n",
       "* Ensemble approach\n",
       "* Domain knowledge integration\n",
       "* Code sharing and collaboration\n",
       "\n",
       "These methods are related across the writeups in that they all contribute to developing a robust and effective solution to the competition problem. By combining these methods, teams can improve their chances of achieving a better score in the competition.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_all[df_all[\"Competition\"]==comp5][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Writeups\n",
    "\n",
    "This should be 2 subsets for size of 5, and all in one for size 10 and \"ALL\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Competition                                           COVID19 Global Forecasting (Week 4)\n",
       "Number of Writeups                                                                     10\n",
       "comp_Reward                                                                     Knowledge\n",
       "comp_link                               https://www.kaggle.com/competitions/covid19-gl...\n",
       "teams                                                                                 472\n",
       "competitors                                                                          1290\n",
       "Entries                                                                              1925\n",
       "Tag                                                                          tabular data\n",
       "desc                                    This is week 4 of Kaggle's COVID-19 forecastin...\n",
       "code_link                               https://www.kaggle.com/code/mozattt/automated-...\n",
       "start_date                                                                              9\n",
       "start_month                                                                          Apr \n",
       "start_year                                                                           2020\n",
       "final_date                                                                             16\n",
       "final_month                                                                          Apr \n",
       "final_year                                                                           2020\n",
       "Metadata Available                                                                   True\n",
       "Resummarized Summary Simple             Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup            Here is the combined list of key points with d...\n",
       "Resummarized Summary Writeup Summary    Here is the combined list of key points with d...\n",
       "Name: 59, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5[df_5[\"Number of Writeups\"]==10].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 5\n",
    "\n",
    "This loses the key point details already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Time constraint**: Prioritize tasks, manage time effectively, and adapt to changing circumstances. (Description: Time constraints can impact the development of predictive models, and prioritizing tasks and adapting to changing circumstances can help overcome these limitations.)\n",
       "\n",
       "2. **Data integration**: Combine multiple data sources to gain a more comprehensive understanding of the problem. (Description: Integrating multiple data sources can provide a more complete picture of the problem, allowing for more effective modeling and prediction.)\n",
       "\n",
       "3. **Model selection**: Select the right tool for the task, considering factors such as data complexity, model interpretability, and computational resources. (Description: Choosing the right model for the task is crucial, as different models are better suited for different types of data and problems.)\n",
       "\n",
       "4. **Benchmarking**: Document and share knowledge, allowing others to build upon and learn from previous work. (Description: Benchmarking allows for the sharing of knowledge and the ability to build upon previous work, which can lead to better outcomes.)\n",
       "\n",
       "5. **Collaboration**: Share ideas and expertise with others to lead to better outcomes. (Description: Collaboration can lead to better outcomes by allowing for the sharing of ideas and expertise.)\n",
       "\n",
       "6. **Adaptability**: Be willing to adapt to changing data patterns and re-evaluate model performance. (Description: Adapting to changing data patterns and re-evaluating model performance is essential for developing effective predictive models.)\n",
       "\n",
       "7. **Lack of data**: Understand the limitations of data availability and explore alternative approaches when data is scarce. (Description: When data is scarce, understanding the limitations of data availability and exploring alternative approaches can help overcome these limitations.)\n",
       "\n",
       "8. **Simple models can be effective**: Simple models can be effective in certain situations, especially when there is limited data. (Description: Simple models can be effective in certain situations, especially when there is limited data, and can provide a good starting point for more complex modeling.)\n",
       "\n",
       "9. **Hyperparameter tuning**: Explore different hyperparameters and evaluate their impact on model performance. (Description: Hyperparameter tuning is essential for finding the optimal combination of hyperparameters that result in the best model performance.)\n",
       "\n",
       "10. **Combining multiple models**: Combine multiple models to improve overall performance. (Description: Combining multiple models can improve overall performance by reducing the impact of individual model errors.)\n",
       "\n",
       "11. **Adapting to changing data**: Adapt to changing data patterns and re-evaluate model performance. (Description: Adapting to changing data patterns and re-evaluating model performance is essential for developing effective predictive models.)\n",
       "\n",
       "12. **Subjectivity in modeling**: Consider multiple perspectives and combine multiple models to improve overall performance. (Description: Subjectivity in modeling can be overcome by considering multiple perspectives and combining multiple models.)\n",
       "\n",
       "13. **Importance of domain knowledge**: Consider domain knowledge in understanding the problem and developing effective models. (Description: Domain knowledge is essential for understanding the problem and developing effective models.)\n",
       "\n",
       "14. **Uncertainty and limitations**: Acknowledge the uncertainty and limitations of predicting pandemics and explore alternative approaches when necessary. (Description: Acknowledging the uncertainty and limitations of predicting pandemics is essential for developing effective predictive models.)\n",
       "\n",
       "15. **Complexity of long-term predictions**: Consider multiple scenarios and uncertainties when making long-term predictions. (Description: Long-term predictions require considering multiple scenarios and uncertainties, which can be complex and challenging.)\n",
       "\n",
       "16. **Combining ML and domain expertise**: Combine machine learning with domain expertise to lead to better results. (Description: Combining machine learning with domain expertise can lead to better results by leveraging the strengths of both approaches.)\n",
       "\n",
       "17. **Importance of pre-processing and feature engineering**: Pre-process and engineer features to improve model performance. (Description: Pre-processing and feature engineering are essential for improving model performance by selecting the most relevant features.)\n",
       "\n",
       "18. **Use of ensemble methods**: Combine multiple models to reduce the impact of individual model errors. (Description: Ensemble methods can reduce the impact of individual model errors by combining multiple models.)\n",
       "\n",
       "19. **Post-processing and rule-based adjustments**: Carefully evaluate and refine predictions based on domain knowledge and expert judgment. (Description: Post-processing and rule-based adjustments are essential for refining predictions based on domain knowledge and expert judgment.)\n",
       "\n",
       "20. **Use of domain knowledge and expert judgment**: Consider domain-specific knowledge and expertise when developing predictive models. (Description: Domain knowledge and expert judgment are essential for developing effective predictive models.)\n",
       "\n",
       "21. **Limitations of ML models**: Evaluate the limitations of ML models and consider alternative approaches when necessary. (Description: Evaluating the limitations of ML models is essential for developing effective predictive models.)\n",
       "\n",
       "22. **Importance of data quality and availability**: Evaluate the quality and availability of data when developing predictive models. (Description: Evaluating the quality and availability of data is essential for developing effective predictive models.)\n",
       "\n",
       "23. **Use of visualization and exploration**: Use visualization and exploration to aid decision-making. (Description:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp10 = df_5[df_5[\"Number of Writeups\"]==10][\"Competition\"].iloc[0]\n",
    "summy = df_5[df_5[\"Competition\"]==comp10][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 10\n",
    "\n",
    "This only still has a single subset to summarize, and the result does seem better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Time constraint**: Prioritize tasks, manage time effectively, and adapt to changing circumstances. (Description: Recognize the importance of time constraints and adapt to changing circumstances to achieve better results.)\n",
       "\n",
       "2. **Data integration**: Combine multiple data sources to gain a more comprehensive understanding of the problem. (Description: Combine multiple data sources to gain a deeper understanding of the problem and make more accurate predictions.)\n",
       "\n",
       "3. **Model selection**: Select the right tool for the task, considering factors such as data complexity, model interpretability, and computational resources. (Description: Choose the most suitable model for the task, taking into account the complexity of the data, the need for interpretability, and the availability of computational resources.)\n",
       "\n",
       "4. **Benchmarking**: Document and share knowledge, allowing others to build upon and learn from previous work. (Description: Document and share knowledge to allow others to build upon and learn from previous work, promoting collaboration and improvement.)\n",
       "\n",
       "5. **Collaboration**: Engage in community discussions, share ideas, and learn from others to improve outcomes. (Description: Engage in community discussions, share ideas, and learn from others to improve outcomes and achieve better results.)\n",
       "\n",
       "6. **Adaptability**: Be willing to change approaches and try new things in response to changing data and competition settings. (Description: Be willing to adapt to changing data and competition settings by trying new approaches and refining models.)\n",
       "\n",
       "7. **Feature engineering**: Extract relevant features that capture the underlying patterns in the data. (Description: Extract relevant features that capture the underlying patterns in the data to improve model performance.)\n",
       "\n",
       "8. **Model blending**: Combine the predictions of multiple models to reduce the impact of individual model errors. (Description: Combine the predictions of multiple models to reduce the impact of individual model errors and improve overall performance.)\n",
       "\n",
       "9. **Post-processing**: Adjust predictions to ensure non-negative values, quantile adjustments, and smoothing can improve model output. (Description: Adjust predictions to ensure non-negative values, quantile adjustments, and smoothing can improve model output.)\n",
       "\n",
       "10. **Iterative refinement**: Refine models by trying different approaches and evaluating their performance using cross-validation. (Description: Refine models by trying different approaches and evaluating their performance using cross-validation to achieve better results.)\n",
       "\n",
       "11. **Data quality and availability**: Carefully evaluate the quality and availability of data when developing predictive models. (Description: Carefully evaluate the quality and availability of data when developing predictive models to ensure accurate predictions.)\n",
       "\n",
       "12. **Visualization and exploration**: Use visualization and exploration to aid decision-making and identify patterns in the data. (Description: Use visualization and exploration to aid decision-making and identify patterns in the data to improve model performance.)\n",
       "\n",
       "13. **Continuous learning and improvement**: Continuously refine and improve predictive models based on new data and insights. (Description: Continuously refine and improve predictive models based on new data and insights to achieve better results.)\n",
       "\n",
       "14. **Reusable machine learning solutions**: Develop reusable models that can be applied to future pandemics or similar problems. (Description: Develop reusable models that can be applied to future pandemics or similar problems to promote collaboration and improvement.)\n",
       "\n",
       "15. **Non-recursive predictions**: Avoid recursive predictions and train separate models for each day ahead. (Description: Avoid recursive predictions and train separate models for each day ahead to improve model performance.)\n",
       "\n",
       "16. **Customized loss function**: Use a customized loss function, such as the pinball loss, to train models. (Description: Use a customized loss function to train models and improve performance.)\n",
       "\n",
       "17. **Ensemble methods**: Combine the predictions of multiple models using ensemble methods. (Description: Combine the predictions of multiple models using ensemble methods to improve overall performance.)\n",
       "\n",
       "18. **Smoothing and rounding**: Apply smoothing to predictions to reduce the impact of noise and rounding to integers to ensure discrete and meaningful predictions. (Description: Apply smoothing to predictions to reduce the impact of noise and rounding to integers to ensure discrete and meaningful predictions.)\n",
       "\n",
       "19. **Model architecture**: Use a suitable model architecture, such as a CNN, to capture non-linear relationships in the data. (Description: Use a suitable model architecture to capture non-linear relationships in the data and improve performance.)\n",
       "\n",
       "20. **Hyperparameter tuning**: Experiment with different hyperparameters to find the optimal combination that works well for the model. (Description: Experiment with different hyperparameters to find the optimal combination that works well for the model and improve performance.)\n",
       "\n",
       "21. **Quantile estimation**: Estimate quantiles using techniques such as the Poisson distribution to understand the distribution of outcomes. (Description: Estimate quantiles using techniques such as the Poisson distribution to understand the distribution of outcomes and improve model performance.)\n",
       "\n",
       "22. **Distribution selection**: Choose a distribution that fits the data and understand its underlying assumptions. (Description: Choose a distribution that fits the data and understand its underlying assumptions to improve model performance.)\n",
       "\n",
       "23. **Simple yet effective approach**: Recognize that"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_10[df_10[\"Competition\"]==comp10][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Subsets, All in One\n",
    "\n",
    "About the same as above subsets of 10, just minor variation in wording of the key points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summaries, here are the key points that can be applied to similar problem-solving scenarios:\n",
       "\n",
       "**Time constraint**: Prioritize tasks, manage time effectively, and adapt to changing circumstances.\n",
       "\n",
       "**Data integration**: Combine multiple data sources to gain a more comprehensive understanding of the problem.\n",
       "\n",
       "**Model selection**: Select the right tool for the task, considering factors such as data complexity, model interpretability, and computational resources.\n",
       "\n",
       "**Benchmarking**: Document and share knowledge, allowing others to build upon and learn from previous work.\n",
       "\n",
       "**Collaboration**: Engage in community discussions, share ideas, and learn from others to improve outcomes.\n",
       "\n",
       "**Adaptability**: Be willing to change approaches and try new things in response to changing data and competition settings.\n",
       "\n",
       "**Feature engineering**: Extract relevant features that capture the underlying patterns in the data.\n",
       "\n",
       "**Model blending**: Combine the predictions of multiple models to reduce the impact of individual model errors.\n",
       "\n",
       "**Post-processing**: Adjust predictions to ensure non-negative values, quantile adjustments, and smoothing can improve model output.\n",
       "\n",
       "**Iterative refinement**: Refine models by trying different approaches and evaluating their performance using cross-validation.\n",
       "\n",
       "**Data quality and availability**: Carefully evaluate the quality and availability of data when developing predictive models.\n",
       "\n",
       "**Visualization and exploration**: Use visualization and exploration to aid decision-making and identify patterns in the data.\n",
       "\n",
       "**Continuous learning and improvement**: Continuously refine and improve predictive models based on new data and insights.\n",
       "\n",
       "**Reusable machine learning solutions**: Develop reusable models that can be applied to future pandemics or similar problems.\n",
       "\n",
       "**Non-recursive predictions**: Avoid recursive predictions and train separate models for each day ahead.\n",
       "\n",
       "**Customized loss function**: Use a customized loss function, such as the pinball loss, to train models.\n",
       "\n",
       "**Ensemble methods**: Combine the predictions of multiple models using ensemble methods.\n",
       "\n",
       "**Smoothing and rounding**: Apply smoothing to predictions to reduce the impact of noise and rounding to integers to ensure discrete and meaningful predictions.\n",
       "\n",
       "**Model architecture**: Use a suitable model architecture, such as a CNN, to capture non-linear relationships in the data.\n",
       "\n",
       "**Hyperparameter tuning**: Experiment with different hyperparameters to find the optimal combination that works well for the model.\n",
       "\n",
       "**Quantile estimation**: Estimate quantiles using techniques such as the Poisson distribution to understand the distribution of outcomes.\n",
       "\n",
       "**Distribution selection**: Choose a distribution that fits the data and understand its underlying assumptions.\n",
       "\n",
       "**Simple yet effective approach**: Recognize that sometimes, simplicity can be effective, and build upon existing solutions or baselines.\n",
       "\n",
       "**Focus on understanding the problem**: Focus on understanding the problem and data to identify suitable approaches and distributions.\n",
       "\n",
       "**Ensemble approach**: Train multiple simple models and blend their predictions to improve overall performance.\n",
       "\n",
       "**Feature engineering**: Design input features to capture trends and normalize them by the maximum value for the region.\n",
       "\n",
       "**Time-series forecasting**: Predict the number of cases or fatalities on a future date based on input features.\n",
       "\n",
       "**Weighted training**: Weight training data to give more significance to later days.\n",
       "\n",
       "**Post-processing**: Adjust predictions using linear transformation and deviation factor.\n",
       "\n",
       "**Exploration of different models**: Train multiple models with different combinations of hyperparameters to explore their impact on performance.\n",
       "\n",
       "**Use of validation set**: Use a validation set to evaluate performance and optimize final predictions.\n",
       "\n",
       "**Potential improvements**: Identify potential improvements that were not implemented due to time constraints.\n",
       "\n",
       "The data analysis methods used across writeups include:\n",
       "\n",
       "1. Feature engineering\n",
       "2. Model selection\n",
       "3. Model blending\n",
       "4. Post-processing\n",
       "5. Quantile estimation\n",
       "6. Distribution selection\n",
       "7. Time-series forecasting\n",
       "8. Weighted training\n",
       "9. Hyperparameter tuning\n",
       "10. Ensemble methods\n",
       "\n",
       "These methods are related across writeups in that they are all used to develop and refine predictive models for forecasting COVID-19 cases and fatalities. The writeups demonstrate the importance of combining multiple methods to achieve better performance and the need to adapt to changing data and competition settings.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_all[df_all[\"Competition\"]==comp10][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 Writeups\n",
    "\n",
    "This would be 3 subsets for subset size 5, 2 subsets for size 10, and a single set for the \"all\" version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Competition                                                   Gendered Pronoun Resolution\n",
       "Number of Writeups                                                                     15\n",
       "comp_Reward                                                                         25000\n",
       "comp_link                               https://www.kaggle.com/competitions/gendered-p...\n",
       "teams                                                                                 838\n",
       "competitors                                                                          1615\n",
       "Entries                                                                               617\n",
       "Tag                                                                                   nlp\n",
       "desc                                    \\nCan you help end gender bias in pronoun reso...\n",
       "code_link                               https://www.kaggle.com/code/surajshiwal/visual...\n",
       "start_date                                                                              6\n",
       "start_month                                                                          Feb \n",
       "start_year                                                                           2019\n",
       "final_date                                                                             16\n",
       "final_month                                                                          Apr \n",
       "final_year                                                                           2019\n",
       "Metadata Available                                                                   True\n",
       "Resummarized Summary Simple             Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup            Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup Summary    Here is the combined list of key points with d...\n",
       "Name: 157, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5[df_5[\"Number of Writeups\"]==15].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 5\n",
    "\n",
    "This one starts overly pushing it all together, and seems to have lost a lot of key points and structure already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Preprocessing**: Careful preprocessing is crucial in natural language processing tasks, including steps such as tokenization, stopword removal, and stemming or lemmatization.\n",
       "2. **Feature extraction**: Extracting relevant features from text data is essential, which can be done using pre-trained models like BERT, or by creating hand-crafted features.\n",
       "3. **Model selection**: Selecting the right model architecture and experimenting with different models is important, including using pre-trained models, fine-tuning, and combining multiple models.\n",
       "4. **Hyperparameter tuning**: Hyperparameter tuning is a crucial step in model development, including searching for optimal hyperparameters, using regularization techniques, and experimenting with different hyperparameter settings.\n",
       "5. **Cross-validation**: Using cross-validation to evaluate model performance and avoid overfitting is essential.\n",
       "6. **Ensemble methods**: Combining the predictions of multiple models can improve overall performance.\n",
       "7. **Data augmentation**: Using data augmentation techniques, such as test augmentation, can improve model robustness.\n",
       "8. **Experimentation and iteration**: Iterating on the design of a solution through experimentation and modification is important.\n",
       "9. **Combining multiple models and embeddings**: Combining multiple models and embeddings can capture relevant information.\n",
       "10. **Incorporating domain-specific knowledge and features**: Incorporating domain-specific knowledge and features can improve model performance.\n",
       "11. **Using KFold Cross-Validation**: Using KFold Cross-Validation can help evaluate model performance and avoid overfitting.\n",
       "12. **Leveraging community knowledge and insights**: Leveraging community knowledge and insights can help improve model performance.\n",
       "13. **Adapting pre-trained models to specific problem requirements**: Adapting pre-trained models to specific problem requirements can improve model performance.\n",
       "14. **Handling noisy labels and reducing the risk of overfitting/underfitting**: Handling noisy labels and reducing the risk of overfitting/underfitting is important.\n",
       "15. **Experimenting with different models and combining them**: Experimenting with different models and combining them can improve model performance.\n",
       "16. **Hyperparameter tuning and careful model selection**: Hyperparameter tuning and careful model selection are important steps in model development.\n",
       "17. **Using sufficient folds in cross-validation**: Using sufficient folds in cross-validation is important to evaluate model performance and avoid overfitting.\n",
       "18. **Ensemble methods and combining multiple models**: Ensemble methods and combining multiple models can improve overall performance.\n",
       "19. **Iterative experimentation and refinement**: Iterative experimentation and refinement are important steps in model development.\n",
       "20. **Feature engineering and exploring different architectures**: Feature engineering and exploring different architectures can improve model performance.\n",
       "21. **Considering limitations and future directions in datascience projects**: Considering limitations and future directions in datascience projects is important.\n",
       "22. **Combining multiple approaches**: Combining multiple approaches, including using pre-trained models, data blending, and data augmentation, can improve model performance.\n",
       "23. **Model stacking**: Building a second layer model, such as LGBM, can help improve performance by leveraging the strengths of each individual model.\n",
       "24. **BERT fine-tuning**: Fine-tuning BERT can be a useful technique, but it may not always improve performance.\n",
       "25. **Hyperparameter tuning**: Using hyperparameter tuning frameworks, such as Hyperopt, can help find the optimal combination of hyperparameters.\n",
       "26. **Model stacking**: Stacking models can help improve performance by leveraging the strengths of each individual model.\n",
       "27. **Feature engineering**: Using a combination of distance, URL, and statistic features can be effective for pronoun resolution.\n",
       "28. **Encoding pronouns**: Encoding pronouns as numbers can be a simple yet effective way to incorporate pronoun information into the model.\n",
       "29. **Lessons for similar problem-solving**: Experimenting with different model structures and hyperparameters, using a combination of different techniques, paying attention to data quality, and implementing robust training processes can help improve model performance.\n",
       "\n",
       "These key points highlight the importance of experimentation, iteration, and adaptation in datascience, as well as the importance of incorporating domain-specific knowledge and features, and leveraging community knowledge and insights.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp15 = df_5[df_5[\"Number of Writeups\"]==15][\"Competition\"].iloc[0]\n",
    "summy = df_5[df_5[\"Competition\"]==comp15][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 10\n",
    "\n",
    "Here we are still good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "1. **Ensemble methods**: Combining multiple models and embeddings can improve performance.\n",
       "2. **Pre-trained models**: Fine-tuning pre-trained models like BERT can be effective, but careful tuning and adaptation to the specific problem are crucial.\n",
       "3. **Hyperparameter tuning**: Careful tuning of model parameters can significantly impact performance.\n",
       "4. **Experimentation and iteration**: Iterative experimentation and refinement are essential in the datascience process.\n",
       "5. **Feature engineering**: Extracting relevant features and incorporating domain-specific knowledge can improve performance.\n",
       "6. **Model selection and combination**: Exploring different models and combining them can lead to better performance.\n",
       "7. **Data analysis methods**: Techniques like cross-validation, ensemble methods, and hyperparameter tuning are essential in datascience.\n",
       "8. **Cross-validation**: Using sufficient folds in cross-validation to avoid overfitting.\n",
       "9. **Ensemble methods**: Combining multiple models using techniques like concatenation, averaging, and LightGBM.\n",
       "10. **Hyperparameter tuning**: Tuning model parameters using techniques like grid search, random search, and Bayesian optimization.\n",
       "11. **Feature engineering**: Extracting relevant features using techniques like wordpiece tokenization, truncation, and attention-pooling.\n",
       "12. **Model architecture**: Exploring different model architectures, including concatenating uncased and cased BERT models.\n",
       "13. **Data augmentation**: Creating new instances by substituting entities or using test-time augmentation (TTA) to evaluate the model's performance.\n",
       "14. **Pre-trained language models**: Using pre-trained language models like BERT can save time and computational resources compared to training a model from scratch.\n",
       "15. **Feature engineering**: Carefully selecting features that are relevant to the task at hand, including extracting features from BERT embeddings.\n",
       "16. **Ensemble approaches**: Combining multiple models or architectures to improve performance.\n",
       "17. **Cross-validation**: Using stratified 10-fold cross-validation to evaluate the performance of a model and avoid overfitting.\n",
       "18. **Hyperparameter search**: Using hyperparameter search, such as Hyperopt, to find the optimal combination of hyperparameters.\n",
       "19. **Blending models**: Blending the predictions from multiple models across folds to improve overall performance.\n",
       "20. **Test augmentation**: Using test augmentation to improve the robustness of a model's predictions.\n",
       "21. **Pipeline structure**: Combining different feature extraction methods and models to create a pipeline structure.\n",
       "22. **BERT embeddings**: Concatenating embeddings from multiple BERT layers and entities to extract relevant features.\n",
       "23. **Hand-crafted features**: Using hand-crafted features, such as neural coref, Stanford NLP, and e2e-coref model predictions, to improve performance.\n",
       "24. **Model stacking**: Combining multiple models to produce a final prediction.\n",
       "25. **Augmentation**: Using augmentation to create new instances and improve performance.\n",
       "26. **BERT finetuning**: Fine-tuning BERT, especially with larger pronoun-related datasets, to improve performance.\n",
       "27. **Prototyping and iteration**: Prototyping and iterating on different components, including stacking, to improve performance.\n",
       "28. **Focus on \"killer features\"**: Focusing on \"killer features\" that can significantly improve performance.\n",
       "29. **Code availability**: Providing code availability to make it possible for others to reproduce and build upon the work.\n",
       "30. **Domain knowledge and intuition**: Using domain knowledge and intuition to guide the datascience process.\n",
       "\n",
       "These key points can be applied to similar problem-solving in datascience, such as developing a preprocessing pipeline for natural language text data, extracting relevant features from text data using pre-trained models like BERT, selecting the best model for a particular problem, and more.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_10[df_10[\"Competition\"]==comp15][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Subsets, All in One\n",
    "\n",
    "About the same as above subsets of 10, but perhas a bit of differentiation between what seems to be slightly more generic topics, and a list of key points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the writeup summaries, here are the key points that can be applied to similar problem-solving:\n",
       "\n",
       "**Common themes:**\n",
       "\n",
       "1. **Preprocessing and feature engineering**: Many writeups emphasize the importance of careful preprocessing and feature engineering to improve model performance.\n",
       "2. **Model selection and combination**: Several writeups highlight the value of experimenting with different models and combining them to achieve better results.\n",
       "3. **Hyperparameter tuning**: Many writeups stress the importance of thorough hyperparameter tuning to find the optimal combination.\n",
       "4. **Data augmentation and regularization**: Several writeups demonstrate the effectiveness of data augmentation and regularization techniques to prevent overfitting and improve model robustness.\n",
       "5. **Ensemble methods**: Many writeups show the power of combining multiple models using ensemble methods to improve overall performance.\n",
       "\n",
       "**Data analysis methods:**\n",
       "\n",
       "1. **BERT embeddings**: Many writeups use BERT embeddings as a crucial component in their models.\n",
       "2. **Layer selection**: Several writeups experiment with different BERT layers to find the best combination.\n",
       "3. **Data augmentation**: Many writeups apply data augmentation techniques, such as swapping A and B columns, to increase the size and diversity of the training dataset.\n",
       "4. **Feature extraction**: Several writeups extract features from BERT embeddings, linguistic features, and other sources to improve model performance.\n",
       "5. **Model stacking**: Many writeups combine multiple models using model stacking to improve overall performance.\n",
       "\n",
       "**Relationship across writeups:**\n",
       "\n",
       "1. **Preprocessing and feature engineering**: Many writeups emphasize the importance of careful preprocessing and feature engineering to improve model performance.\n",
       "2. **Model selection and combination**: Several writeups highlight the value of experimenting with different models and combining them to achieve better results.\n",
       "3. **Hyperparameter tuning**: Many writeups stress the importance of thorough hyperparameter tuning to find the optimal combination.\n",
       "4. **Data augmentation and regularization**: Several writeups demonstrate the effectiveness of data augmentation and regularization techniques to prevent overfitting and improve model robustness.\n",
       "5. **Ensemble methods**: Many writeups show the power of combining multiple models using ensemble methods to improve overall performance.\n",
       "\n",
       "By applying these key points and data analysis methods, datascience practitioners can develop effective solutions for similar problems and improve their chances of success in competitions like this one.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_all[df_all[\"Competition\"]==comp15][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 36 Writeups\n",
    "\n",
    "Now lets go for one of the biggest sets of writeups we have. First a look at the unique writeup counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35,\n",
       "       36, 37, 41])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df_5[\"Number of Writeups\"].unique()\n",
    "np.sort(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest counts here are 36, 37 and 41. Unfortunately 41 and 37 were too much fit the writeup summaries into Gemma 8k context, so I will go with the 36. This is both non-divisible by 5, and also as close to the top height as possible.\n",
    "\n",
    "The too long lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "skipped due to token limit (on Kaggle need shorter due to GPU memory limit)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp41 = df_all[df_all[\"Number of Writeups\"]==41][\"Competition\"].iloc[0]\n",
    "summy = df_all[df_all[\"Competition\"]==comp41][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "skipped due to token limit (on Kaggle need shorter due to GPU memory limit)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp37 = df_all[df_all[\"Number of Writeups\"]==37][\"Competition\"].iloc[0]\n",
    "summy = df_all[df_all[\"Competition\"]==comp37][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 36 writeup version did fit into the 8k context window, and it also has a number that is not divisible by 5, so a bit more interesting than exact subsets of 5. Lets see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Competition                                                     M5 Forecasting - Accuracy\n",
       "Number of Writeups                                                                     36\n",
       "comp_Reward                                                                         50000\n",
       "comp_link                               https://www.kaggle.com/competitions/m5-forecas...\n",
       "teams                                                                                5558\n",
       "competitors                                                                          7022\n",
       "Entries                                                                             88741\n",
       "Tag                                                                  time series analysis\n",
       "desc                                    Note: This is one of the two complementary com...\n",
       "code_link                               https://www.kaggle.com/code/zwhite/eda-and-bas...\n",
       "start_date                                                                              3\n",
       "start_month                                                                          Mar \n",
       "start_year                                                                           2020\n",
       "final_date                                                                             24\n",
       "final_month                                                                          Jun \n",
       "final_year                                                                           2020\n",
       "Metadata Available                                                                   True\n",
       "Resummarized Summary Simple             Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup            Here is the list of key points with descriptio...\n",
       "Resummarized Summary Writeup Summary    Here is the list of key points with descriptio...\n",
       "Name: 283, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5[df_5[\"Number of Writeups\"]==36].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 5\n",
    "\n",
    "This splitting produces the generic pointless summary that Gemma often seems to produce, losing all of the real information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "**Common Themes**\n",
       "\n",
       "1. **Hierarchical data**: Many writeups emphasize the importance of considering hierarchical relationships in the data.\n",
       "2. **Feature engineering**: Feature engineering is a crucial step in many writeups, with authors experimenting with different features and combinations to find the most informative ones.\n",
       "3. **Model selection and combination**: Authors often select the best-performing model or combine multiple models to improve forecasting accuracy.\n",
       "4. **Cross-validation**: Cross-validation is a common technique used to evaluate model performance and prevent overfitting.\n",
       "5. **Experimentation and iteration**: Authors emphasize the importance of experimentation and iteration in the datascience process, whether it's trying different models, features, or hyperparameters.\n",
       "6. **Metric choice**: The choice of metric is crucial, and authors often express disappointment with the default metric used in the competition.\n",
       "7. **Generalization**: Authors highlight the importance of evaluating model performance on unseen data to ensure generalization.\n",
       "\n",
       "**Specific Data Analysis Methods**\n",
       "\n",
       "1. **Lagged demand**: Calculating lagged demand is a common feature engineering technique used in many writeups.\n",
       "2. **Permutation importance**: Authors use permutation importance to identify the most important features and remove those that don't contribute significantly to the model's performance.\n",
       "3. **Tweedie objective function**: The Tweedie objective function is used in some writeups to model the data.\n",
       "4. **StratifiedFold**: StratifiedFold is used in some writeups for hyperparameter tuning.\n",
       "5. **Weighted average**: Authors use weighted averages to combine predictions from different levels or models.\n",
       "6. **Calendar-based features**: Authors create calendar-based features using target encoding for ids (store, item,...) x [weekday, events, or month] or ids with last 3M, 1Y, 2Y (rolling, no leak).\n",
       "7. **Kurtosis**: Kurtosis is used to detect the effect of outliers in the data.\n",
       "8. **Event detection**: Event detection is used to create binary features that capture the effect of important events on sales.\n",
       "9. **Visualization techniques**: Visualization techniques are used to understand the behavior of the model and the effect of different features on the predictions.\n",
       "\n",
       "**Relationships Across Writeups**\n",
       "\n",
       "1. **Hierarchical data structure**: Many writeups emphasize the importance of considering hierarchical relationships in data when modeling.\n",
       "2. **Feature engineering**: Feature engineering is a crucial step in many writeups, involving the creation of relevant features that capture the underlying patterns in the data.\n",
       "3. **Ensemble methods**: Ensemble methods, such as stacking binary prediction features or combining multiple models, are used to improve forecasting accuracy.\n",
       "4. **Hyperparameter tuning**: Hyperparameter tuning is essential to optimize model performance, and techniques like grid search and walk-forward cross-validation are used.\n",
       "5. **Data splitting and validation**: Data splitting and validation are critical steps to evaluate model performance and prevent overfitting.\n",
       "\n",
       "**General Key Points**\n",
       "\n",
       "1. **Simplification is key**: Balancing complexity with simplicity in model development can be effective.\n",
       "2. **Feature engineering**: Extracting relevant information from the data through feature engineering is crucial.\n",
       "3. **Domain knowledge**: Understanding the problem domain can inform feature selection and model development.\n",
       "4. **Experimentation and iteration**: Trying different approaches and iterating on the model can lead to better results.\n",
       "5. **Self-evaluation and calculation of metrics**: Evaluating model performance using relevant metrics is essential.\n",
       "6. **Lessons from failure**: Failure can be a valuable learning experience, leading to more effective solutions.\n",
       "7. **Choose the right algorithm**: Selecting an algorithm suitable for the problem can be crucial.\n",
       "8. **Joint modeling approach**: Leverage hierarchical structure by using joint modeling approaches.\n",
       "9. **Data preparation and training**: Use a framework that provides built-in notation and data structure to reduce preparation time.\n",
       "10. **Hyperparameter tuning**: Optimize the model by experimenting with different hyperparameters.\n",
       "11. **Runtime**: Consider the runtime of the approach and optimize it to reduce training and evaluation time.\n",
       "12. **Understand the competition's nuances**: Understand the specific problem and its requirements.\n",
       "13. **Don't overcomplicate**: Sometimes, simplicity can be more effective than complexity.\n",
       "14. **Experimentation is key**: Try different approaches and experiment with different parameters.\n",
       "15. **Visualize and analyze**: Analyze and visualize the data to improve the model.\n",
       "16. **Avoid overfitting**: Use the right model and avoid overfitting at the lowest level.\n",
       "17. **Ensemble methods can be effective**: Use averaging over several runs to improve forecasting accuracy.\n",
       "18. **Feature engineering is important**: Extract relevant information from the data through feature engineering.\n",
       "19. **Don't be afraid to try new approaches**: Be open to new approaches and not be afraid to try something different.\n",
       "20. **Simple yet effective approach**: Sometimes, a straightforward approach can"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp36 = df_5[df_5[\"Number of Writeups\"]==36][\"Competition\"].iloc[0]\n",
    "summy = df_5[df_5[\"Competition\"]==comp36][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of 10\n",
    "\n",
    "This one is not quite the shortest one-liner above, but a few points. Unfortunately considering it consists of 36 writeups and summarizing their key points into one final summary, it is very bad. Loses all details, and lists a few generic data science points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of key points with descriptions:\n",
       "\n",
       "**Common Themes:**\n",
       "\n",
       "1. **Hierarchical Modeling**: Consider hierarchical relationships in data when modeling.\n",
       "2. **Feature Engineering**: Create relevant features to capture underlying patterns in data.\n",
       "3. **Ensemble Methods**: Combine multiple models or use a \"mixture of experts\" approach to improve forecasting accuracy.\n",
       "4. **Cross-Validation**: Evaluate model performance and prevent overfitting using cross-validation.\n",
       "5. **Experimentation and Iteration**: Try different approaches and refine them to achieve better results.\n",
       "\n",
       "**Specific Data Analysis Methods:**\n",
       "\n",
       "1. **Time-Series Decomposition**: Identify patterns in data using time-series decomposition techniques.\n",
       "2. **Rolling Mean and Standard Deviation**: Create features that capture underlying patterns in data using rolling mean and standard deviation.\n",
       "3. **Lagged Features**: Capture relationships between different levels of the hierarchy using lagged features.\n",
       "4. **Target Encoding**: Create features that capture relationships between different levels of the hierarchy using target encoding.\n",
       "5. **Kalman Filters**: Model relationships between different levels of the hierarchy using Kalman Filters.\n",
       "\n",
       "**Relationships Across Writeups:**\n",
       "\n",
       "1. **Hierarchical Modeling** and **Feature Engineering**: Often used together to create a robust model.\n",
       "2. **Cross-Validation**: Used to evaluate model performance and prevent overfitting.\n",
       "3. **Loss Function Manipulation** and **Ensemble Methods**: Used to improve model performance and adapt to new information.\n",
       "4. **Iterative Refinement**: A common approach in datascience, where authors refine their approaches until they find a solution that works well.\n",
       "5. **Community Input** and **Collaboration**: Essential in datascience, allowing authors to learn from others and share knowledge.\n",
       "\n",
       "**Common Key Points:**\n",
       "\n",
       "1. **Understand the Competition's Nuances**: Understand the specific problem and its requirements.\n",
       "2. **Don't Overcomplicate**: Simple yet effective approaches can be more successful than complex ones.\n",
       "3. **Experimentation is Key**: Trying different approaches and parameters is essential for finding the right solution.\n",
       "4. **Visualize and Analyze**: Analyzing and visualizing the data can help improve the model.\n",
       "5. **Avoid Overfitting**: Using the right model and avoiding overfitting can be crucial in achieving good results.\n",
       "6. **Ensemble Methods can be Effective**: Combining multiple models can improve forecasting accuracy.\n",
       "7. **Feature Engineering is Important**: Extracting relevant information from the data through feature engineering is crucial.\n",
       "8. **Don't be Afraid to Try New Approaches**: Being open to new approaches can be beneficial in finding the right solution.\n",
       "\n",
       "**Data Analysis Methods:**\n",
       "\n",
       "1. **Feature Engineering**: Creating features that capture relevant patterns and trends in the data.\n",
       "2. **Hierarchical Modeling**: Modeling data at multiple levels of aggregation or grouping.\n",
       "3. **Ensemble Methods**: Combining multiple models to improve forecasting accuracy.\n",
       "4. **Target Encoding**: Converting categorical variables into numerical features.\n",
       "5. **Hyperparameter Tuning**: Optimizing model performance by adjusting hyperparameters.\n",
       "6. **Cross-Validation**: Evaluating model performance using a holdout set.\n",
       "7. **Sensitivity Analysis**: Testing the model's sensitivity to different inputs or parameters.\n",
       "8. **Model Interpretability**: Understanding the model's predictions and identifying biases.\n",
       "\n",
       "**Relationships Across Writeups:**\n",
       "\n",
       "1. **Feature Engineering**: Many writeups emphasize the importance of feature engineering in capturing relevant patterns and trends in the data.\n",
       "2. **Hierarchical Modeling**: Hierarchical modeling is used in several writeups to capture the hierarchical structure of the data.\n",
       "3. **Ensemble Methods**: Ensemble methods are used in several writeups to improve forecasting accuracy by combining multiple models.\n",
       "4. **Target Encoding**: Target encoding is used in several writeups to convert categorical variables into numerical features.\n",
       "5. **Hyperparameter Tuning**: Hyperparameter tuning is used in several writeups to optimize model performance by adjusting hyperparameters.\n",
       "6. **Cross-Validation**: Cross-validation is used in several writeups to evaluate model performance using a holdout set.\n",
       "7. **Sensitivity Analysis**: Sensitivity analysis is used in several writeups to test the model's sensitivity to different inputs or parameters.\n",
       "8. **Model Interpretability**: Model interpretability is emphasized in several writeups to understand the model's predictions and identify biases.<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp36 = df_10[df_10[\"Number of Writeups\"]==36][\"Competition\"].iloc[0]\n",
    "summy = df_10[df_10[\"Competition\"]==comp36][\"Resummarized Summary Simple\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Subsets, All in One\n",
    "\n",
    "This one has the key points collected, as there is no subsplitting before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "skipped due to token limit (on Kaggle need shorter due to GPU memory limit)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summy = df_all[df_all[\"Competition\"]==comp36][\"Overall Summary\"].iloc[0]\n",
    "Markdown(summy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions About Subsets\n",
    "\n",
    "Well, Gemma seems to do quite fine up to a point. But when I start to re-summarize larger number of subsets, it seems to drop it and give a very bland and generic, overly short answer. Without much of real content. So I would say it would be best to trial some more and perhaps think of ways to show the initial summaries for the user as input for further insights. Or other ways to support the user in their task, in this case analyzing Kaggle writeups. Such as in my second notebook, where I tried to use the summaries as input to the user to drive their RAG-based question formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 5741538,
     "sourceId": 50947,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 7669720,
     "sourceId": 64148,
     "sourceType": "competition"
    },
    {
     "datasetId": 2593672,
     "sourceId": 5134565,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4778921,
     "sourceId": 8094205,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8332,
     "sourceId": 11261,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
